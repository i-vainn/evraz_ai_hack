{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dd5133485346ad867b219488849e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc0b8d14a3541e2a862601200e0c397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = pd.read_csv(\"../data/target_train.csv\")\n",
    "sample = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "plavki_train = pd.read_csv(\"../data/plavki_train.csv\")\n",
    "plavki_test = pd.read_csv(\"../data/plavki_test.csv\")\n",
    "\n",
    "gas_train = pd.read_csv(\"../data/gas_train.csv\")\n",
    "gas_test = pd.read_csv(\"../data/gas_test.csv\")\n",
    "\n",
    "chugun_train = pd.read_csv(\"../data/chugun_train.csv\")\n",
    "chugun_test = pd.read_csv(\"../data/chugun_test.csv\")\n",
    "\n",
    "lom_train = pd.read_csv(\"../data/lom_train.csv\")\n",
    "lom_test = pd.read_csv(\"../data/lom_test.csv\")\n",
    "\n",
    "produv_train = pd.read_csv(\"../data/produv_train.csv\")\n",
    "produv_test = pd.read_csv(\"../data/produv_test.csv\")\n",
    "\n",
    "chronom_train = pd.read_csv(\"../data/chronom_train.csv\")\n",
    "chronom_test = pd.read_csv(\"../data/chronom_test.csv\")\n",
    "\n",
    "sip_train = pd.read_csv(\"../data/sip_train.csv\")\n",
    "sip_test = pd.read_csv(\"../data/sip_test.csv\")\n",
    "\n",
    "from pipeline import merge_data\n",
    "\n",
    "params = {\n",
    "    \"chugun\": {},\n",
    "    \"plavki\": {\"bow_count\": 10},\n",
    "    \"vector_size\": 10\n",
    "}\n",
    "\n",
    "train, test, y, num_features, cat_features = merge_data(\n",
    "    sample, target, plavki_train, plavki_test, gas_train, gas_test, chugun_train, chugun_test, \n",
    "    lom_train, lom_test, produv_train, produv_test, chronom_train, chronom_test, \n",
    "    sip_train, sip_test, params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "def metric(c_true, tst_true, c_pred, tst_pred, pwc=None, pwt=None):\n",
    "    \n",
    "    if pwc is not None:\n",
    "        c_pred = pwc.inverse_transform(c_pred.reshape(-1, 1)).reshape(-1)\n",
    "    if pwt is not None:\n",
    "        tst_pred = pwt.inverse_transform(tst_pred.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    delta_c = np.abs(c_true - c_pred)\n",
    "    hit_rate_c = np.int64(delta_c < 0.02)\n",
    "\n",
    "    delta_t = np.abs(tst_true - tst_pred)\n",
    "    hit_rate_t = np.int64(delta_t < 20)\n",
    "\n",
    "    N = c_pred.shape[0]    \n",
    "    return np.sum(hit_rate_c) / N, np.sum(hit_rate_t) / N, np.sum(hit_rate_c + hit_rate_t) / 2 / N\n",
    "\n",
    "def pipeline(model_c, model_tst, train_c, test_c, train_tst, test_tst, y, sample, n_splits=10, pwc=None, pwt=None):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    sample[\"C\"] = 0\n",
    "    sample[\"TST\"] = 0\n",
    "    \n",
    "    res_c, res_t, res = [], [], []\n",
    "    for train_idx, test_idx in tqdm(kf.split(train_c), total=n_splits):\n",
    "        cur_train_c = train_c[train_idx]\n",
    "        cur_eval_c = train_c[test_idx]        \n",
    "\n",
    "        cur_train_tst = train_tst[train_idx]\n",
    "        cur_eval_tst = train_tst[test_idx]\n",
    "\n",
    "        cur_train_y = y.iloc[train_idx]\n",
    "        cur_eval_y = y.iloc[test_idx]\n",
    "        \n",
    "        if pwc is not None:\n",
    "            model_c.fit(cur_train_c, pwc.transform(cur_train_y[\"C\"].values.reshape(-1, 1)).reshape(-1))\n",
    "        else:\n",
    "            model_c.fit(cur_train_c, cur_train_y[\"C\"])\n",
    "            \n",
    "        if pwt is not None:\n",
    "            model_tst.fit(cur_train_tst, pwt.transform(cur_train_y[\"TST\"].values.reshape(-1, 1)).reshape(-1))\n",
    "        else:\n",
    "            model_tst.fit(cur_train_tst, cur_train_y[\"TST\"])\n",
    "        \n",
    "        eval_pred_c = model_c.predict(cur_eval_c)\n",
    "        eval_pred_tst = model_tst.predict(cur_eval_tst)\n",
    "    \n",
    "        sample[\"C\"] += model_c.predict(test_c) / n_splits\n",
    "        sample[\"TST\"] += model_tst.predict(test_tst) / n_splits\n",
    "        \n",
    "        hit_rate_c, hit_rate_t, hit_rate = metric(cur_eval_y[\"C\"], cur_eval_y[\"TST\"], eval_pred_c, eval_pred_tst, pwc, pwt)\n",
    "        res_c.append(hit_rate_c)\n",
    "        res_t.append(hit_rate_t)\n",
    "        res.append(hit_rate)\n",
    "    \n",
    "    res_c = np.array(res_c)\n",
    "    res_t = np.array(res_t)\n",
    "    res = np.array(res)\n",
    "    print(f\"Carbon score: {res_c.mean()} ± {res_c.std()}\")\n",
    "    print(f\"Temperature score: {res_t.mean()} ± {res_t.std()}\")    \n",
    "    print(f\"Overall score: {res.mean()} ± {res.std()}\") \n",
    "    \n",
    "    if pwt is not None:\n",
    "        sample[\"TST\"] = pwt.inverse_transform(sample[\"TST\"].values.reshape(-1, 1)).reshape(-1)\n",
    "    if pwc is not None:\n",
    "        sample[\"C\"] = pwc.inverse_transform(sample[\"C\"].values.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    sample[\"C\"] = sample[\"C\"].clip(0, 1)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import transform_for_linear\n",
    "\n",
    "train_scaled, test_scaled = transform_for_linear(train, num_features, cat_features, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp = train.drop(columns=['truncated_NMZ'])\n",
    "test_exp = test.drop(columns=['truncated_NMZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8525b852443447c4b5ab94b5d71ee077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon score: 0.642891150112024 ± 0.03841876109410508\n",
      "Temperature score: 0.6389749813293502 ± 0.06252279801789368\n",
      "Overall score: 0.6409330657206871 ± 0.03512989631263768\n"
     ]
    }
   ],
   "source": [
    "model_c = XGBRegressor(n_estimators=20, max_depth=7)\n",
    "model_tst = XGBRegressor(n_estimators=20, max_depth=7)\n",
    "\n",
    "res = pipeline(model_c, model_tst, train_exp.values, test_exp.values, train_exp.values, test_exp.values, y, sample, n_splits=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.30263925, 'unique_count'),\n",
       " (0.13923663, 'bow_/Э '),\n",
       " (0.12412604, 'gas_std_volume_AR'),\n",
       " (0.04664408, 'gas_sum_volume_CO2'),\n",
       " (0.045238547, 'bow_т3п'),\n",
       " (0.024579667, 'MN'),\n",
       " (0.019775849, 'max_duration_межпл.прост._1'),\n",
       " (0.017551946, 'gas_mean_CO2'),\n",
       " (0.017241437, 'RAS_mean'),\n",
       " (0.0119070895, 'ves_loma'),\n",
       " (0.010698845, 'gas_std_AR'),\n",
       " (0.009757485, 'total_duration_межпл.прост._1'),\n",
       " (0.0097543895, 'gas_std_volume_N2'),\n",
       " (0.009282209, 'total_operations_межпл.прост._1'),\n",
       " (0.009172838, 'O2_межпл.прост._1'),\n",
       " (0.008292838, 'cr_portion'),\n",
       " (0.008147722, 'O2_опер_0'),\n",
       " (0.008127391, 'gas_std_V'),\n",
       " (0.00660705, 'gas_mean_H2'),\n",
       " (0.0065626656, 'gas_sum_volume_O2')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model_c.feature_importances_, train.columns), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9ca3ca8c12413e839f60106b6ab0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon score: 0.4080517176997759 ± 0.03569376418334986\n",
      "Temperature score: 0.5133121732636295 ± 0.06015986692729851\n",
      "Overall score: 0.4606819454817027 ± 0.03547239587269207\n"
     ]
    }
   ],
   "source": [
    "model_c = RandomForestRegressor(n_estimators=300, max_depth=3, max_features=\"log2\", n_jobs=-1)\n",
    "model_tst = RandomForestRegressor(n_estimators=300, max_depth=3, max_features=\"log2\", n_jobs=-1)\n",
    "\n",
    "res = pipeline(model_c, model_tst, train[top_features].values, test[top_features].values, train[top_features].values, test[top_features].values, y, sample, n_splits=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c = RandomForestRegressor(n_estimators=20, max_depth=5)\n",
    "model_c.fit(train_exp.values, y[\"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp[\"random\"] = np.random.rand(len(train_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [el[1] for el in sorted(zip(model_c.feature_importances_, train.columns), reverse=True)[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"42.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c57437747ec476780a4c52b775b712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:44] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:45] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:46] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:47] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:48] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:49] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:50] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:51] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:52] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:53] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Carbon score: 0.5790238095238095 ± 0.10876116201481019\n",
      "Temperature score: 0.615047619047619 ± 0.12076470253631567\n",
      "Overall score: 0.5970357142857143 ± 0.08533090434866755\n"
     ]
    }
   ],
   "source": [
    "model_c = XGBRegressor(n_jobs=-1, colsample_bytree=0.1, n_estimators=20, objective=\"reg:linear\")\n",
    "model_tst = XGBRegressor(n_jobs=-1, colsample_bytree=0.1, n_estimators=20)\n",
    "\n",
    "res = pipeline(model_c, model_tst, train.values, test.values, train.values, test.values, y, sample, n_splits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24215163, 'bow_3пс'),\n",
       " (0.05486636, 'bow_/ЭТ'),\n",
       " (0.041976433, 'min_duration_вн.пл.прост._0'),\n",
       " (0.037629627, 'dayofmonth'),\n",
       " (0.03418404, 'truncated_NMZ'),\n",
       " (0.03246214, 'gas_mean_AR'),\n",
       " (0.031678926, 'gas_std_AR'),\n",
       " (0.031467497, 'max_duration_опер_0'),\n",
       " (0.026234813, 'gas_std_N2'),\n",
       " (0.024867244, 'gas_mean_O2'),\n",
       " (0.024632696, 'SI'),\n",
       " (0.023688182, 'ves_loma'),\n",
       " (0.023653345, 'unique_count'),\n",
       " (0.02361382, 'RAS_mean'),\n",
       " (0.022975925, 'O2_опер_0'),\n",
       " (0.022136467, 'TI'),\n",
       " (0.019638686, 'gas_mean_T фурмы 1'),\n",
       " (0.018636141, 'gas_sum_volume_CO'),\n",
       " (0.016083574, 'gas_mean_N2'),\n",
       " (0.014335417, 'MN')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model_c.feature_importances_, train.columns), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_duration</th>\n",
       "      <th>gas_mean_V</th>\n",
       "      <th>gas_mean_T</th>\n",
       "      <th>gas_mean_O2</th>\n",
       "      <th>gas_mean_N2</th>\n",
       "      <th>gas_mean_H2</th>\n",
       "      <th>gas_mean_CO2</th>\n",
       "      <th>gas_mean_CO</th>\n",
       "      <th>gas_mean_AR</th>\n",
       "      <th>gas_mean_T фурмы 1</th>\n",
       "      <th>gas_mean_T фурмы 2</th>\n",
       "      <th>gas_mean_O2_pressure</th>\n",
       "      <th>gas_std_V</th>\n",
       "      <th>gas_std_T</th>\n",
       "      <th>gas_std_O2</th>\n",
       "      <th>gas_std_N2</th>\n",
       "      <th>gas_std_H2</th>\n",
       "      <th>gas_std_CO2</th>\n",
       "      <th>gas_std_CO</th>\n",
       "      <th>gas_std_AR</th>\n",
       "      <th>gas_std_T фурмы 1</th>\n",
       "      <th>gas_std_T фурмы 2</th>\n",
       "      <th>gas_std_O2_pressure</th>\n",
       "      <th>gas_sum_volume_O2</th>\n",
       "      <th>gas_sum_volume_N2</th>\n",
       "      <th>gas_sum_volume_H2</th>\n",
       "      <th>gas_sum_volume_CO2</th>\n",
       "      <th>gas_sum_volume_CO</th>\n",
       "      <th>gas_sum_volume_AR</th>\n",
       "      <th>gas_mean_volume_O2</th>\n",
       "      <th>gas_mean_volume_N2</th>\n",
       "      <th>gas_mean_volume_H2</th>\n",
       "      <th>gas_mean_volume_CO2</th>\n",
       "      <th>gas_mean_volume_CO</th>\n",
       "      <th>gas_mean_volume_AR</th>\n",
       "      <th>gas_std_volume_O2</th>\n",
       "      <th>gas_std_volume_N2</th>\n",
       "      <th>gas_std_volume_H2</th>\n",
       "      <th>gas_std_volume_CO2</th>\n",
       "      <th>gas_std_volume_CO</th>\n",
       "      <th>gas_std_volume_AR</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>hour</th>\n",
       "      <th>duration</th>\n",
       "      <th>truncated_NMZ</th>\n",
       "      <th>st_diff_is_zero</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>plavka_TIPE_GOL</th>\n",
       "      <th>plavka_TIPE_FUR</th>\n",
       "      <th>plavka_NAPR_ZAD</th>\n",
       "      <th>bow_.z0</th>\n",
       "      <th>bow_/Э</th>\n",
       "      <th>bow_/ЭТ</th>\n",
       "      <th>bow_3пс</th>\n",
       "      <th>bow_SC2</th>\n",
       "      <th>bow_Ст3</th>\n",
       "      <th>bow_ЭТ</th>\n",
       "      <th>bow_пс/</th>\n",
       "      <th>bow_с/Э</th>\n",
       "      <th>bow_т3п</th>\n",
       "      <th>VES</th>\n",
       "      <th>T</th>\n",
       "      <th>SI</th>\n",
       "      <th>MN</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>CR</th>\n",
       "      <th>NI</th>\n",
       "      <th>CU</th>\n",
       "      <th>V</th>\n",
       "      <th>TI</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>si_portion</th>\n",
       "      <th>mn_portion</th>\n",
       "      <th>s_portion</th>\n",
       "      <th>p_portion</th>\n",
       "      <th>cr_portion</th>\n",
       "      <th>ni_portion</th>\n",
       "      <th>cu_portion</th>\n",
       "      <th>v_portion</th>\n",
       "      <th>ti_portion</th>\n",
       "      <th>ves_loma</th>\n",
       "      <th>ves_loma/ves_chuguna</th>\n",
       "      <th>durationproduv_</th>\n",
       "      <th>RAS_mean</th>\n",
       "      <th>POL_mean</th>\n",
       "      <th>O2_вн.пл.прост._0</th>\n",
       "      <th>O2_межпл.прост._0</th>\n",
       "      <th>O2_межпл.прост._1</th>\n",
       "      <th>O2_опер_0</th>\n",
       "      <th>total_duration_вн.пл.прост._0</th>\n",
       "      <th>total_duration_межпл.прост._0</th>\n",
       "      <th>total_duration_межпл.прост._1</th>\n",
       "      <th>total_duration_опер_0</th>\n",
       "      <th>min_duration_вн.пл.прост._0</th>\n",
       "      <th>min_duration_межпл.прост._0</th>\n",
       "      <th>min_duration_межпл.прост._1</th>\n",
       "      <th>min_duration_опер_0</th>\n",
       "      <th>max_duration_вн.пл.прост._0</th>\n",
       "      <th>max_duration_межпл.прост._0</th>\n",
       "      <th>max_duration_межпл.прост._1</th>\n",
       "      <th>max_duration_опер_0</th>\n",
       "      <th>total_operations_вн.пл.прост._0</th>\n",
       "      <th>total_operations_межпл.прост._0</th>\n",
       "      <th>total_operations_межпл.прост._1</th>\n",
       "      <th>total_operations_опер_0</th>\n",
       "      <th>min_mass</th>\n",
       "      <th>max_mass</th>\n",
       "      <th>total_count</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>min_ratio</th>\n",
       "      <th>max_ratio</th>\n",
       "      <th>unique_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPLV</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510008</th>\n",
       "      <td>2560</td>\n",
       "      <td>216789.292999</td>\n",
       "      <td>506.912198</td>\n",
       "      <td>8.080398</td>\n",
       "      <td>60.971011</td>\n",
       "      <td>0.300348</td>\n",
       "      <td>13.646908</td>\n",
       "      <td>16.236455</td>\n",
       "      <td>0.801776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.356058</td>\n",
       "      <td>5369.811888</td>\n",
       "      <td>273.329244</td>\n",
       "      <td>8.601033</td>\n",
       "      <td>19.843291</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>7.340789</td>\n",
       "      <td>20.627802</td>\n",
       "      <td>0.189599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>4.502321e+07</td>\n",
       "      <td>3.391881e+08</td>\n",
       "      <td>1.624003e+06</td>\n",
       "      <td>7.575220e+07</td>\n",
       "      <td>8.913852e+07</td>\n",
       "      <td>4.458630e+06</td>\n",
       "      <td>17587.192761</td>\n",
       "      <td>132495.366168</td>\n",
       "      <td>634.376020</td>\n",
       "      <td>29590.704477</td>\n",
       "      <td>34819.734247</td>\n",
       "      <td>1741.652526</td>\n",
       "      <td>18701.426346</td>\n",
       "      <td>43818.901201</td>\n",
       "      <td>1655.726824</td>\n",
       "      <td>15946.086198</td>\n",
       "      <td>44086.505490</td>\n",
       "      <td>425.909341</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263700.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.609471e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.342814e-07</td>\n",
       "      <td>8.722033e-08</td>\n",
       "      <td>3.678422e-07</td>\n",
       "      <td>1.137656e-07</td>\n",
       "      <td>3.792188e-08</td>\n",
       "      <td>1.137656e-07</td>\n",
       "      <td>3.905954e-07</td>\n",
       "      <td>3.185438e-07</td>\n",
       "      <td>76200</td>\n",
       "      <td>0.288965</td>\n",
       "      <td>4108.0</td>\n",
       "      <td>408.181995</td>\n",
       "      <td>4.116603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220</td>\n",
       "      <td>7300</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510009</th>\n",
       "      <td>3949</td>\n",
       "      <td>217054.421867</td>\n",
       "      <td>375.840941</td>\n",
       "      <td>10.985339</td>\n",
       "      <td>64.784377</td>\n",
       "      <td>0.163313</td>\n",
       "      <td>11.761720</td>\n",
       "      <td>11.466482</td>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.950163</td>\n",
       "      <td>4250.571350</td>\n",
       "      <td>291.238099</td>\n",
       "      <td>10.616286</td>\n",
       "      <td>16.819827</td>\n",
       "      <td>0.538952</td>\n",
       "      <td>8.095644</td>\n",
       "      <td>18.080320</td>\n",
       "      <td>0.167612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003299</td>\n",
       "      <td>9.485353e+07</td>\n",
       "      <td>5.562788e+08</td>\n",
       "      <td>1.364358e+06</td>\n",
       "      <td>1.004032e+08</td>\n",
       "      <td>9.705018e+07</td>\n",
       "      <td>7.193678e+06</td>\n",
       "      <td>24019.631951</td>\n",
       "      <td>140865.726324</td>\n",
       "      <td>345.494449</td>\n",
       "      <td>25424.967838</td>\n",
       "      <td>24575.886359</td>\n",
       "      <td>1821.645526</td>\n",
       "      <td>23278.991109</td>\n",
       "      <td>37231.830524</td>\n",
       "      <td>1123.023713</td>\n",
       "      <td>17501.298735</td>\n",
       "      <td>38641.706115</td>\n",
       "      <td>373.312144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264500.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.609475e+09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.561437e-07</td>\n",
       "      <td>6.427221e-08</td>\n",
       "      <td>3.289225e-07</td>\n",
       "      <td>7.561437e-08</td>\n",
       "      <td>3.780718e-08</td>\n",
       "      <td>1.134216e-07</td>\n",
       "      <td>3.175803e-07</td>\n",
       "      <td>3.629490e-07</td>\n",
       "      <td>78600</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>437.750429</td>\n",
       "      <td>3.223137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>2987.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9950</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510010</th>\n",
       "      <td>2871</td>\n",
       "      <td>215606.942311</td>\n",
       "      <td>489.881937</td>\n",
       "      <td>8.745518</td>\n",
       "      <td>62.633599</td>\n",
       "      <td>0.312984</td>\n",
       "      <td>12.723079</td>\n",
       "      <td>14.755786</td>\n",
       "      <td>0.828832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.022366</td>\n",
       "      <td>6659.001169</td>\n",
       "      <td>301.143710</td>\n",
       "      <td>9.489587</td>\n",
       "      <td>19.181862</td>\n",
       "      <td>0.797407</td>\n",
       "      <td>8.108025</td>\n",
       "      <td>19.036043</td>\n",
       "      <td>0.167892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330850</td>\n",
       "      <td>5.488448e+07</td>\n",
       "      <td>3.886485e+08</td>\n",
       "      <td>1.874444e+06</td>\n",
       "      <td>7.840161e+07</td>\n",
       "      <td>9.005883e+07</td>\n",
       "      <td>5.138755e+06</td>\n",
       "      <td>19116.849917</td>\n",
       "      <td>135370.437027</td>\n",
       "      <td>652.889050</td>\n",
       "      <td>27308.119240</td>\n",
       "      <td>31368.453349</td>\n",
       "      <td>1789.883300</td>\n",
       "      <td>20947.742464</td>\n",
       "      <td>42260.955051</td>\n",
       "      <td>1623.914332</td>\n",
       "      <td>17333.228492</td>\n",
       "      <td>40336.007001</td>\n",
       "      <td>376.987465</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>263800.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.609478e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.855951e-07</td>\n",
       "      <td>6.444276e-08</td>\n",
       "      <td>3.639121e-07</td>\n",
       "      <td>1.137225e-07</td>\n",
       "      <td>3.790751e-08</td>\n",
       "      <td>1.137225e-07</td>\n",
       "      <td>4.359363e-07</td>\n",
       "      <td>4.169826e-07</td>\n",
       "      <td>76300</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>433.941227</td>\n",
       "      <td>3.188833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>2796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5050</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510011</th>\n",
       "      <td>3261</td>\n",
       "      <td>218908.844905</td>\n",
       "      <td>439.273874</td>\n",
       "      <td>9.016227</td>\n",
       "      <td>62.605303</td>\n",
       "      <td>0.100366</td>\n",
       "      <td>13.566362</td>\n",
       "      <td>13.771099</td>\n",
       "      <td>0.835434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.250926</td>\n",
       "      <td>5341.347771</td>\n",
       "      <td>267.257197</td>\n",
       "      <td>8.395936</td>\n",
       "      <td>17.444834</td>\n",
       "      <td>0.215926</td>\n",
       "      <td>7.790133</td>\n",
       "      <td>18.094440</td>\n",
       "      <td>0.194226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665478</td>\n",
       "      <td>6.478924e+07</td>\n",
       "      <td>4.477267e+08</td>\n",
       "      <td>7.091111e+05</td>\n",
       "      <td>9.674182e+07</td>\n",
       "      <td>9.717645e+07</td>\n",
       "      <td>5.974200e+06</td>\n",
       "      <td>19867.905305</td>\n",
       "      <td>137297.364374</td>\n",
       "      <td>217.452049</td>\n",
       "      <td>29666.305531</td>\n",
       "      <td>29799.586702</td>\n",
       "      <td>1832.014654</td>\n",
       "      <td>18607.672797</td>\n",
       "      <td>38883.156660</td>\n",
       "      <td>468.388798</td>\n",
       "      <td>17089.798747</td>\n",
       "      <td>39012.937295</td>\n",
       "      <td>437.916480</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264000.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.609482e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.022727e-06</td>\n",
       "      <td>6.818182e-08</td>\n",
       "      <td>3.446970e-07</td>\n",
       "      <td>1.136364e-07</td>\n",
       "      <td>3.787879e-08</td>\n",
       "      <td>7.575758e-08</td>\n",
       "      <td>4.242424e-07</td>\n",
       "      <td>4.166667e-07</td>\n",
       "      <td>84100</td>\n",
       "      <td>0.318561</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>392.992501</td>\n",
       "      <td>6.287681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>320</td>\n",
       "      <td>5020</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510012</th>\n",
       "      <td>2860</td>\n",
       "      <td>217981.805452</td>\n",
       "      <td>478.608197</td>\n",
       "      <td>8.470485</td>\n",
       "      <td>62.286450</td>\n",
       "      <td>0.442823</td>\n",
       "      <td>13.643787</td>\n",
       "      <td>14.273926</td>\n",
       "      <td>0.802074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.259779</td>\n",
       "      <td>5757.933597</td>\n",
       "      <td>282.254884</td>\n",
       "      <td>9.054424</td>\n",
       "      <td>18.477454</td>\n",
       "      <td>0.878580</td>\n",
       "      <td>8.633744</td>\n",
       "      <td>18.366216</td>\n",
       "      <td>0.182802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652421</td>\n",
       "      <td>5.328600e+07</td>\n",
       "      <td>3.894694e+08</td>\n",
       "      <td>2.698631e+06</td>\n",
       "      <td>8.476063e+07</td>\n",
       "      <td>8.769451e+07</td>\n",
       "      <td>5.013289e+06</td>\n",
       "      <td>18631.467155</td>\n",
       "      <td>136178.120683</td>\n",
       "      <td>943.577316</td>\n",
       "      <td>29636.583246</td>\n",
       "      <td>30662.417509</td>\n",
       "      <td>1752.898361</td>\n",
       "      <td>19987.724321</td>\n",
       "      <td>41474.251736</td>\n",
       "      <td>1859.532540</td>\n",
       "      <td>18623.947548</td>\n",
       "      <td>39404.426535</td>\n",
       "      <td>419.124607</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263300.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.609486e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.735283e-07</td>\n",
       "      <td>6.836308e-08</td>\n",
       "      <td>3.646031e-07</td>\n",
       "      <td>7.595898e-08</td>\n",
       "      <td>3.797949e-08</td>\n",
       "      <td>1.139385e-07</td>\n",
       "      <td>3.152298e-07</td>\n",
       "      <td>2.658564e-07</td>\n",
       "      <td>76100</td>\n",
       "      <td>0.289024</td>\n",
       "      <td>4238.0</td>\n",
       "      <td>396.448585</td>\n",
       "      <td>3.717656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4980</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512318</th>\n",
       "      <td>3060</td>\n",
       "      <td>208248.303329</td>\n",
       "      <td>439.574555</td>\n",
       "      <td>4.152793</td>\n",
       "      <td>53.516385</td>\n",
       "      <td>1.191883</td>\n",
       "      <td>17.997605</td>\n",
       "      <td>22.405678</td>\n",
       "      <td>0.736660</td>\n",
       "      <td>28.701842</td>\n",
       "      <td>25.883701</td>\n",
       "      <td>15.004221</td>\n",
       "      <td>7548.831043</td>\n",
       "      <td>246.178558</td>\n",
       "      <td>5.610260</td>\n",
       "      <td>21.662747</td>\n",
       "      <td>1.267843</td>\n",
       "      <td>8.394836</td>\n",
       "      <td>20.068151</td>\n",
       "      <td>0.219879</td>\n",
       "      <td>5.081189</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.990635</td>\n",
       "      <td>2.659664e+07</td>\n",
       "      <td>3.426617e+08</td>\n",
       "      <td>7.449856e+06</td>\n",
       "      <td>1.149322e+08</td>\n",
       "      <td>1.408978e+08</td>\n",
       "      <td>4.706967e+06</td>\n",
       "      <td>8691.713694</td>\n",
       "      <td>111980.943607</td>\n",
       "      <td>2434.593391</td>\n",
       "      <td>37559.535747</td>\n",
       "      <td>46045.018769</td>\n",
       "      <td>1538.224385</td>\n",
       "      <td>11749.972138</td>\n",
       "      <td>45978.755732</td>\n",
       "      <td>2509.652248</td>\n",
       "      <td>17805.931661</td>\n",
       "      <td>40458.211385</td>\n",
       "      <td>468.885956</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267200.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1.619442e+09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.047904e-06</td>\n",
       "      <td>7.110778e-08</td>\n",
       "      <td>3.705090e-07</td>\n",
       "      <td>7.485030e-08</td>\n",
       "      <td>3.742515e-08</td>\n",
       "      <td>7.485030e-08</td>\n",
       "      <td>3.031437e-07</td>\n",
       "      <td>2.245509e-07</td>\n",
       "      <td>73600</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>372.911585</td>\n",
       "      <td>5.181084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3700</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512319</th>\n",
       "      <td>3803</td>\n",
       "      <td>206951.068996</td>\n",
       "      <td>336.801224</td>\n",
       "      <td>8.228796</td>\n",
       "      <td>62.478096</td>\n",
       "      <td>0.696861</td>\n",
       "      <td>12.629975</td>\n",
       "      <td>15.130581</td>\n",
       "      <td>0.831568</td>\n",
       "      <td>28.272125</td>\n",
       "      <td>26.229685</td>\n",
       "      <td>14.582193</td>\n",
       "      <td>6563.914573</td>\n",
       "      <td>264.291825</td>\n",
       "      <td>6.208800</td>\n",
       "      <td>22.759382</td>\n",
       "      <td>1.188099</td>\n",
       "      <td>7.192062</td>\n",
       "      <td>22.684423</td>\n",
       "      <td>0.232025</td>\n",
       "      <td>4.975858</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>0.983222</td>\n",
       "      <td>6.564858e+07</td>\n",
       "      <td>4.959340e+08</td>\n",
       "      <td>5.250390e+06</td>\n",
       "      <td>9.879792e+07</td>\n",
       "      <td>1.147826e+08</td>\n",
       "      <td>6.588681e+06</td>\n",
       "      <td>17262.314047</td>\n",
       "      <td>130405.990406</td>\n",
       "      <td>1380.591525</td>\n",
       "      <td>25978.942183</td>\n",
       "      <td>30182.131880</td>\n",
       "      <td>1732.495661</td>\n",
       "      <td>13041.372039</td>\n",
       "      <td>48829.070068</td>\n",
       "      <td>2297.477335</td>\n",
       "      <td>14707.273186</td>\n",
       "      <td>44622.023951</td>\n",
       "      <td>508.801136</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266800.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.619447e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.124438e-06</td>\n",
       "      <td>6.371814e-08</td>\n",
       "      <td>3.898051e-07</td>\n",
       "      <td>7.496252e-08</td>\n",
       "      <td>3.748126e-08</td>\n",
       "      <td>7.496252e-08</td>\n",
       "      <td>2.961019e-07</td>\n",
       "      <td>3.035982e-07</td>\n",
       "      <td>76600</td>\n",
       "      <td>0.287106</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>449.224197</td>\n",
       "      <td>4.778945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3710</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.013906</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512320</th>\n",
       "      <td>3281</td>\n",
       "      <td>204139.850108</td>\n",
       "      <td>390.420212</td>\n",
       "      <td>6.857118</td>\n",
       "      <td>56.626062</td>\n",
       "      <td>1.016596</td>\n",
       "      <td>13.776500</td>\n",
       "      <td>20.953071</td>\n",
       "      <td>0.772488</td>\n",
       "      <td>28.442658</td>\n",
       "      <td>26.432436</td>\n",
       "      <td>14.911266</td>\n",
       "      <td>7688.084786</td>\n",
       "      <td>242.283799</td>\n",
       "      <td>6.598437</td>\n",
       "      <td>24.151341</td>\n",
       "      <td>1.608945</td>\n",
       "      <td>7.782328</td>\n",
       "      <td>23.908767</td>\n",
       "      <td>0.236470</td>\n",
       "      <td>4.749328</td>\n",
       "      <td>0.141237</td>\n",
       "      <td>0.655360</td>\n",
       "      <td>4.690546e+07</td>\n",
       "      <td>3.839843e+08</td>\n",
       "      <td>6.466457e+06</td>\n",
       "      <td>9.173897e+07</td>\n",
       "      <td>1.354799e+08</td>\n",
       "      <td>5.219883e+06</td>\n",
       "      <td>14296.086335</td>\n",
       "      <td>117032.712352</td>\n",
       "      <td>1970.879806</td>\n",
       "      <td>27960.673621</td>\n",
       "      <td>41292.265092</td>\n",
       "      <td>1590.942698</td>\n",
       "      <td>13772.352381</td>\n",
       "      <td>51525.321369</td>\n",
       "      <td>2992.428589</td>\n",
       "      <td>15803.015948</td>\n",
       "      <td>46076.419562</td>\n",
       "      <td>519.163936</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276100.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1.619448e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.122782e-06</td>\n",
       "      <td>9.054690e-08</td>\n",
       "      <td>4.165158e-07</td>\n",
       "      <td>1.086563e-07</td>\n",
       "      <td>3.621876e-08</td>\n",
       "      <td>1.086563e-07</td>\n",
       "      <td>3.114813e-07</td>\n",
       "      <td>2.390438e-07</td>\n",
       "      <td>64200</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>410.935288</td>\n",
       "      <td>3.866538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4570</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512321</th>\n",
       "      <td>3620</td>\n",
       "      <td>203045.139149</td>\n",
       "      <td>385.978217</td>\n",
       "      <td>6.075653</td>\n",
       "      <td>54.750024</td>\n",
       "      <td>0.971723</td>\n",
       "      <td>14.838620</td>\n",
       "      <td>22.604694</td>\n",
       "      <td>0.743987</td>\n",
       "      <td>27.847579</td>\n",
       "      <td>27.110961</td>\n",
       "      <td>15.110062</td>\n",
       "      <td>5914.722753</td>\n",
       "      <td>255.687099</td>\n",
       "      <td>6.902912</td>\n",
       "      <td>21.863376</td>\n",
       "      <td>1.252370</td>\n",
       "      <td>8.081957</td>\n",
       "      <td>20.558332</td>\n",
       "      <td>0.208407</td>\n",
       "      <td>4.733242</td>\n",
       "      <td>0.493382</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>4.532896e+07</td>\n",
       "      <td>4.047396e+08</td>\n",
       "      <td>6.971648e+06</td>\n",
       "      <td>1.083322e+08</td>\n",
       "      <td>1.640471e+08</td>\n",
       "      <td>5.490289e+06</td>\n",
       "      <td>12521.812758</td>\n",
       "      <td>111806.518678</td>\n",
       "      <td>1925.869725</td>\n",
       "      <td>29926.025952</td>\n",
       "      <td>45316.891016</td>\n",
       "      <td>1516.654440</td>\n",
       "      <td>14269.994093</td>\n",
       "      <td>45872.532849</td>\n",
       "      <td>2389.602262</td>\n",
       "      <td>16162.428239</td>\n",
       "      <td>40923.238233</td>\n",
       "      <td>444.977376</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275800.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1.619452e+09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.789703e-07</td>\n",
       "      <td>7.614213e-08</td>\n",
       "      <td>3.625816e-07</td>\n",
       "      <td>7.251632e-08</td>\n",
       "      <td>3.625816e-08</td>\n",
       "      <td>1.087745e-07</td>\n",
       "      <td>2.755620e-07</td>\n",
       "      <td>2.175489e-07</td>\n",
       "      <td>66200</td>\n",
       "      <td>0.240029</td>\n",
       "      <td>5562.0</td>\n",
       "      <td>346.784867</td>\n",
       "      <td>5.692469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3080</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512322</th>\n",
       "      <td>4782</td>\n",
       "      <td>205058.940555</td>\n",
       "      <td>306.711093</td>\n",
       "      <td>8.985557</td>\n",
       "      <td>63.371647</td>\n",
       "      <td>0.829136</td>\n",
       "      <td>12.778305</td>\n",
       "      <td>13.199406</td>\n",
       "      <td>0.836728</td>\n",
       "      <td>27.065385</td>\n",
       "      <td>27.000937</td>\n",
       "      <td>15.426140</td>\n",
       "      <td>7144.194096</td>\n",
       "      <td>263.504412</td>\n",
       "      <td>7.927912</td>\n",
       "      <td>19.850390</td>\n",
       "      <td>1.427636</td>\n",
       "      <td>10.856853</td>\n",
       "      <td>17.863520</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>4.849513</td>\n",
       "      <td>0.269763</td>\n",
       "      <td>0.662683</td>\n",
       "      <td>8.948705e+07</td>\n",
       "      <td>6.261807e+08</td>\n",
       "      <td>7.780972e+06</td>\n",
       "      <td>1.238589e+08</td>\n",
       "      <td>1.250412e+08</td>\n",
       "      <td>8.250020e+06</td>\n",
       "      <td>18713.310443</td>\n",
       "      <td>130945.356023</td>\n",
       "      <td>1627.137554</td>\n",
       "      <td>25901.056153</td>\n",
       "      <td>26148.303159</td>\n",
       "      <td>1725.223733</td>\n",
       "      <td>16510.288213</td>\n",
       "      <td>42906.725770</td>\n",
       "      <td>2721.719599</td>\n",
       "      <td>21992.302973</td>\n",
       "      <td>34726.324968</td>\n",
       "      <td>429.848595</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279200.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.619457e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.110315e-06</td>\n",
       "      <td>6.805158e-08</td>\n",
       "      <td>3.760745e-07</td>\n",
       "      <td>7.163324e-08</td>\n",
       "      <td>3.581662e-08</td>\n",
       "      <td>1.074499e-07</td>\n",
       "      <td>2.757880e-07</td>\n",
       "      <td>2.399713e-07</td>\n",
       "      <td>76100</td>\n",
       "      <td>0.272564</td>\n",
       "      <td>771726.0</td>\n",
       "      <td>220.462934</td>\n",
       "      <td>6.576471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>4842.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4820</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gas_duration     gas_mean_V  gas_mean_T  gas_mean_O2  gas_mean_N2  \\\n",
       "NPLV                                                                        \n",
       "510008          2560  216789.292999  506.912198     8.080398    60.971011   \n",
       "510009          3949  217054.421867  375.840941    10.985339    64.784377   \n",
       "510010          2871  215606.942311  489.881937     8.745518    62.633599   \n",
       "510011          3261  218908.844905  439.273874     9.016227    62.605303   \n",
       "510012          2860  217981.805452  478.608197     8.470485    62.286450   \n",
       "...              ...            ...         ...          ...          ...   \n",
       "512318          3060  208248.303329  439.574555     4.152793    53.516385   \n",
       "512319          3803  206951.068996  336.801224     8.228796    62.478096   \n",
       "512320          3281  204139.850108  390.420212     6.857118    56.626062   \n",
       "512321          3620  203045.139149  385.978217     6.075653    54.750024   \n",
       "512322          4782  205058.940555  306.711093     8.985557    63.371647   \n",
       "\n",
       "        gas_mean_H2  gas_mean_CO2  gas_mean_CO  gas_mean_AR  \\\n",
       "NPLV                                                          \n",
       "510008     0.300348     13.646908    16.236455     0.801776   \n",
       "510009     0.163313     11.761720    11.466482     0.838266   \n",
       "510010     0.312984     12.723079    14.755786     0.828832   \n",
       "510011     0.100366     13.566362    13.771099     0.835434   \n",
       "510012     0.442823     13.643787    14.273926     0.802074   \n",
       "...             ...           ...          ...          ...   \n",
       "512318     1.191883     17.997605    22.405678     0.736660   \n",
       "512319     0.696861     12.629975    15.130581     0.831568   \n",
       "512320     1.016596     13.776500    20.953071     0.772488   \n",
       "512321     0.971723     14.838620    22.604694     0.743987   \n",
       "512322     0.829136     12.778305    13.199406     0.836728   \n",
       "\n",
       "        gas_mean_T фурмы 1  gas_mean_T фурмы 2  gas_mean_O2_pressure  \\\n",
       "NPLV                                                                   \n",
       "510008            0.000000            0.000000             13.356058   \n",
       "510009            0.000000            0.000000             13.950163   \n",
       "510010            0.000000            0.000000             14.022366   \n",
       "510011            0.000000            0.000000             14.250926   \n",
       "510012            0.000000            0.000000             14.259779   \n",
       "...                    ...                 ...                   ...   \n",
       "512318           28.701842           25.883701             15.004221   \n",
       "512319           28.272125           26.229685             14.582193   \n",
       "512320           28.442658           26.432436             14.911266   \n",
       "512321           27.847579           27.110961             15.110062   \n",
       "512322           27.065385           27.000937             15.426140   \n",
       "\n",
       "          gas_std_V   gas_std_T  gas_std_O2  gas_std_N2  gas_std_H2  \\\n",
       "NPLV                                                                  \n",
       "510008  5369.811888  273.329244    8.601033   19.843291    0.798206   \n",
       "510009  4250.571350  291.238099   10.616286   16.819827    0.538952   \n",
       "510010  6659.001169  301.143710    9.489587   19.181862    0.797407   \n",
       "510011  5341.347771  267.257197    8.395936   17.444834    0.215926   \n",
       "510012  5757.933597  282.254884    9.054424   18.477454    0.878580   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "512318  7548.831043  246.178558    5.610260   21.662747    1.267843   \n",
       "512319  6563.914573  264.291825    6.208800   22.759382    1.188099   \n",
       "512320  7688.084786  242.283799    6.598437   24.151341    1.608945   \n",
       "512321  5914.722753  255.687099    6.902912   21.863376    1.252370   \n",
       "512322  7144.194096  263.504412    7.927912   19.850390    1.427636   \n",
       "\n",
       "        gas_std_CO2  gas_std_CO  gas_std_AR  gas_std_T фурмы 1  \\\n",
       "NPLV                                                             \n",
       "510008     7.340789   20.627802    0.189599           0.000000   \n",
       "510009     8.095644   18.080320    0.167612           0.000000   \n",
       "510010     8.108025   19.036043    0.167892           0.000000   \n",
       "510011     7.790133   18.094440    0.194226           0.000000   \n",
       "510012     8.633744   18.366216    0.182802           0.000000   \n",
       "...             ...         ...         ...                ...   \n",
       "512318     8.394836   20.068151    0.219879           5.081189   \n",
       "512319     7.192062   22.684423    0.232025           4.975858   \n",
       "512320     7.782328   23.908767    0.236470           4.749328   \n",
       "512321     8.081957   20.558332    0.208407           4.733242   \n",
       "512322    10.856853   17.863520    0.193100           4.849513   \n",
       "\n",
       "        gas_std_T фурмы 2  gas_std_O2_pressure  gas_sum_volume_O2  \\\n",
       "NPLV                                                                \n",
       "510008           0.000000             0.292023       4.502321e+07   \n",
       "510009           0.000000             1.003299       9.485353e+07   \n",
       "510010           0.000000             0.330850       5.488448e+07   \n",
       "510011           0.000000             0.665478       6.478924e+07   \n",
       "510012           0.000000             0.652421       5.328600e+07   \n",
       "...                   ...                  ...                ...   \n",
       "512318           0.080459             0.990635       2.659664e+07   \n",
       "512319           0.087734             0.983222       6.564858e+07   \n",
       "512320           0.141237             0.655360       4.690546e+07   \n",
       "512321           0.493382             0.854355       4.532896e+07   \n",
       "512322           0.269763             0.662683       8.948705e+07   \n",
       "\n",
       "        gas_sum_volume_N2  gas_sum_volume_H2  gas_sum_volume_CO2  \\\n",
       "NPLV                                                               \n",
       "510008       3.391881e+08       1.624003e+06        7.575220e+07   \n",
       "510009       5.562788e+08       1.364358e+06        1.004032e+08   \n",
       "510010       3.886485e+08       1.874444e+06        7.840161e+07   \n",
       "510011       4.477267e+08       7.091111e+05        9.674182e+07   \n",
       "510012       3.894694e+08       2.698631e+06        8.476063e+07   \n",
       "...                   ...                ...                 ...   \n",
       "512318       3.426617e+08       7.449856e+06        1.149322e+08   \n",
       "512319       4.959340e+08       5.250390e+06        9.879792e+07   \n",
       "512320       3.839843e+08       6.466457e+06        9.173897e+07   \n",
       "512321       4.047396e+08       6.971648e+06        1.083322e+08   \n",
       "512322       6.261807e+08       7.780972e+06        1.238589e+08   \n",
       "\n",
       "        gas_sum_volume_CO  gas_sum_volume_AR  gas_mean_volume_O2  \\\n",
       "NPLV                                                               \n",
       "510008       8.913852e+07       4.458630e+06        17587.192761   \n",
       "510009       9.705018e+07       7.193678e+06        24019.631951   \n",
       "510010       9.005883e+07       5.138755e+06        19116.849917   \n",
       "510011       9.717645e+07       5.974200e+06        19867.905305   \n",
       "510012       8.769451e+07       5.013289e+06        18631.467155   \n",
       "...                   ...                ...                 ...   \n",
       "512318       1.408978e+08       4.706967e+06         8691.713694   \n",
       "512319       1.147826e+08       6.588681e+06        17262.314047   \n",
       "512320       1.354799e+08       5.219883e+06        14296.086335   \n",
       "512321       1.640471e+08       5.490289e+06        12521.812758   \n",
       "512322       1.250412e+08       8.250020e+06        18713.310443   \n",
       "\n",
       "        gas_mean_volume_N2  gas_mean_volume_H2  gas_mean_volume_CO2  \\\n",
       "NPLV                                                                  \n",
       "510008       132495.366168          634.376020         29590.704477   \n",
       "510009       140865.726324          345.494449         25424.967838   \n",
       "510010       135370.437027          652.889050         27308.119240   \n",
       "510011       137297.364374          217.452049         29666.305531   \n",
       "510012       136178.120683          943.577316         29636.583246   \n",
       "...                    ...                 ...                  ...   \n",
       "512318       111980.943607         2434.593391         37559.535747   \n",
       "512319       130405.990406         1380.591525         25978.942183   \n",
       "512320       117032.712352         1970.879806         27960.673621   \n",
       "512321       111806.518678         1925.869725         29926.025952   \n",
       "512322       130945.356023         1627.137554         25901.056153   \n",
       "\n",
       "        gas_mean_volume_CO  gas_mean_volume_AR  gas_std_volume_O2  \\\n",
       "NPLV                                                                \n",
       "510008        34819.734247         1741.652526       18701.426346   \n",
       "510009        24575.886359         1821.645526       23278.991109   \n",
       "510010        31368.453349         1789.883300       20947.742464   \n",
       "510011        29799.586702         1832.014654       18607.672797   \n",
       "510012        30662.417509         1752.898361       19987.724321   \n",
       "...                    ...                 ...                ...   \n",
       "512318        46045.018769         1538.224385       11749.972138   \n",
       "512319        30182.131880         1732.495661       13041.372039   \n",
       "512320        41292.265092         1590.942698       13772.352381   \n",
       "512321        45316.891016         1516.654440       14269.994093   \n",
       "512322        26148.303159         1725.223733       16510.288213   \n",
       "\n",
       "        gas_std_volume_N2  gas_std_volume_H2  gas_std_volume_CO2  \\\n",
       "NPLV                                                               \n",
       "510008       43818.901201        1655.726824        15946.086198   \n",
       "510009       37231.830524        1123.023713        17501.298735   \n",
       "510010       42260.955051        1623.914332        17333.228492   \n",
       "510011       38883.156660         468.388798        17089.798747   \n",
       "510012       41474.251736        1859.532540        18623.947548   \n",
       "...                   ...                ...                 ...   \n",
       "512318       45978.755732        2509.652248        17805.931661   \n",
       "512319       48829.070068        2297.477335        14707.273186   \n",
       "512320       51525.321369        2992.428589        15803.015948   \n",
       "512321       45872.532849        2389.602262        16162.428239   \n",
       "512322       42906.725770        2721.719599        21992.302973   \n",
       "\n",
       "        gas_std_volume_CO  gas_std_volume_AR  dayofmonth  hour  duration  \\\n",
       "NPLV                                                                       \n",
       "510008       44086.505490         425.909341           1     3    2579.0   \n",
       "510009       38641.706115         373.312144           1     4    4004.0   \n",
       "510010       40336.007001         376.987465           1     5    2904.0   \n",
       "510011       39012.937295         437.916480           1     6    3291.0   \n",
       "510012       39404.426535         419.124607           1     7    2895.0   \n",
       "...                   ...                ...         ...   ...       ...   \n",
       "512318       40458.211385         468.885956          26    13    3084.0   \n",
       "512319       44622.023951         508.801136          26    14    3843.0   \n",
       "512320       46076.419562         519.163936          26    15    3305.0   \n",
       "512321       40923.238233         444.977376          26    16    3660.0   \n",
       "512322       34726.324968         429.848595          26    17    4840.0   \n",
       "\n",
       "        truncated_NMZ  st_diff_is_zero  dayofweek  plavka_TIPE_GOL  \\\n",
       "NPLV                                                                 \n",
       "510008           17.0                1          4                0   \n",
       "510009           17.0                1          4                0   \n",
       "510010           21.0                1          4                0   \n",
       "510011           16.0                1          4                0   \n",
       "510012           14.0                1          4                0   \n",
       "...               ...              ...        ...              ...   \n",
       "512318            7.0                0          0                0   \n",
       "512319            7.0                0          0                0   \n",
       "512320           16.0                0          0                0   \n",
       "512321           16.0                0          0                0   \n",
       "512322           16.0                0          0                0   \n",
       "\n",
       "        plavka_TIPE_FUR  plavka_NAPR_ZAD  bow_.z0  bow_/Э   bow_/ЭТ  bow_3пс  \\\n",
       "NPLV                                                                           \n",
       "510008              1.0              1.0        0        0        0        0   \n",
       "510009              1.0              1.0        0        0        0        0   \n",
       "510010              1.0              0.0        0        1        0        1   \n",
       "510011              1.0              0.0        1        0        0        0   \n",
       "510012              1.0              2.0        0        0        1        0   \n",
       "...                 ...              ...      ...      ...      ...      ...   \n",
       "512318              0.0              2.0        1        0        1        0   \n",
       "512319              0.0              2.0        1        0        1        0   \n",
       "512320              0.0              1.0        0        0        0        0   \n",
       "512321              0.0              1.0        0        0        0        0   \n",
       "512322              0.0              1.0        0        0        0        0   \n",
       "\n",
       "        bow_SC2  bow_Ст3  bow_ЭТ   bow_пс/  bow_с/Э  bow_т3п       VES  \\\n",
       "NPLV                                                                     \n",
       "510008        0        0        0        0        0        0  263700.0   \n",
       "510009        0        0        0        0        0        0  264500.0   \n",
       "510010        0        1        0        1        1        1  263800.0   \n",
       "510011        0        0        0        0        0        0  264000.0   \n",
       "510012        1        0        1        0        0        0  263300.0   \n",
       "...         ...      ...      ...      ...      ...      ...       ...   \n",
       "512318        0        0        1        0        0        0  267200.0   \n",
       "512319        0        0        1        0        0        0  266800.0   \n",
       "512320        0        0        0        0        0        0  276100.0   \n",
       "512321        0        0        0        0        0        0  275800.0   \n",
       "512322        0        0        0        0        0        0  279200.0   \n",
       "\n",
       "             T    SI    MN      S      P    CR    NI    CU      V     TI  \\\n",
       "NPLV                                                                       \n",
       "510008  1396.0  0.44  0.22  0.023  0.097  0.03  0.01  0.03  0.103  0.084   \n",
       "510009  1419.0  0.68  0.20  0.017  0.087  0.02  0.01  0.03  0.084  0.096   \n",
       "510010  1384.0  0.56  0.26  0.017  0.096  0.03  0.01  0.03  0.115  0.110   \n",
       "510011  1401.0  0.48  0.27  0.018  0.091  0.03  0.01  0.02  0.112  0.110   \n",
       "510012  1422.0  0.47  0.23  0.018  0.096  0.02  0.01  0.03  0.083  0.070   \n",
       "...        ...   ...   ...    ...    ...   ...   ...   ...    ...    ...   \n",
       "512318  1415.0  0.38  0.28  0.019  0.099  0.02  0.01  0.02  0.081  0.060   \n",
       "512319  1405.0  0.50  0.30  0.017  0.104  0.02  0.01  0.02  0.079  0.081   \n",
       "512320  1398.0  0.61  0.31  0.025  0.115  0.03  0.01  0.03  0.086  0.066   \n",
       "512321  1408.0  0.38  0.27  0.021  0.100  0.02  0.01  0.03  0.076  0.060   \n",
       "512322  1413.0  0.50  0.31  0.019  0.105  0.02  0.01  0.03  0.077  0.067   \n",
       "\n",
       "        total_seconds  si_portion    mn_portion     s_portion     p_portion  \\\n",
       "NPLV                                                                          \n",
       "510008   1.609471e+09    0.000002  8.342814e-07  8.722033e-08  3.678422e-07   \n",
       "510009   1.609475e+09    0.000003  7.561437e-07  6.427221e-08  3.289225e-07   \n",
       "510010   1.609478e+09    0.000002  9.855951e-07  6.444276e-08  3.639121e-07   \n",
       "510011   1.609482e+09    0.000002  1.022727e-06  6.818182e-08  3.446970e-07   \n",
       "510012   1.609486e+09    0.000002  8.735283e-07  6.836308e-08  3.646031e-07   \n",
       "...               ...         ...           ...           ...           ...   \n",
       "512318   1.619442e+09    0.000001  1.047904e-06  7.110778e-08  3.705090e-07   \n",
       "512319   1.619447e+09    0.000002  1.124438e-06  6.371814e-08  3.898051e-07   \n",
       "512320   1.619448e+09    0.000002  1.122782e-06  9.054690e-08  4.165158e-07   \n",
       "512321   1.619452e+09    0.000001  9.789703e-07  7.614213e-08  3.625816e-07   \n",
       "512322   1.619457e+09    0.000002  1.110315e-06  6.805158e-08  3.760745e-07   \n",
       "\n",
       "          cr_portion    ni_portion    cu_portion     v_portion    ti_portion  \\\n",
       "NPLV                                                                           \n",
       "510008  1.137656e-07  3.792188e-08  1.137656e-07  3.905954e-07  3.185438e-07   \n",
       "510009  7.561437e-08  3.780718e-08  1.134216e-07  3.175803e-07  3.629490e-07   \n",
       "510010  1.137225e-07  3.790751e-08  1.137225e-07  4.359363e-07  4.169826e-07   \n",
       "510011  1.136364e-07  3.787879e-08  7.575758e-08  4.242424e-07  4.166667e-07   \n",
       "510012  7.595898e-08  3.797949e-08  1.139385e-07  3.152298e-07  2.658564e-07   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "512318  7.485030e-08  3.742515e-08  7.485030e-08  3.031437e-07  2.245509e-07   \n",
       "512319  7.496252e-08  3.748126e-08  7.496252e-08  2.961019e-07  3.035982e-07   \n",
       "512320  1.086563e-07  3.621876e-08  1.086563e-07  3.114813e-07  2.390438e-07   \n",
       "512321  7.251632e-08  3.625816e-08  1.087745e-07  2.755620e-07  2.175489e-07   \n",
       "512322  7.163324e-08  3.581662e-08  1.074499e-07  2.757880e-07  2.399713e-07   \n",
       "\n",
       "        ves_loma  ves_loma/ves_chuguna  durationproduv_    RAS_mean  POL_mean  \\\n",
       "NPLV                                                                            \n",
       "510008     76200              0.288965           4108.0  408.181995  4.116603   \n",
       "510009     78600              0.297164           3492.0  437.750429  3.223137   \n",
       "510010     76300              0.289234           3520.0  433.941227  3.188833   \n",
       "510011     84100              0.318561           3732.0  392.992501  6.287681   \n",
       "510012     76100              0.289024           4238.0  396.448585  3.717656   \n",
       "...          ...                   ...              ...         ...       ...   \n",
       "512318     73600              0.275449           5246.0  372.911585  5.181084   \n",
       "512319     76600              0.287106           3486.0  449.224197  4.778945   \n",
       "512320     64200              0.232524           3614.0  410.935288  3.866538   \n",
       "512321     66200              0.240029           5562.0  346.784867  5.692469   \n",
       "512322     76100              0.272564         771726.0  220.462934  6.576471   \n",
       "\n",
       "        O2_вн.пл.прост._0  O2_межпл.прост._0  O2_межпл.прост._1  O2_опер_0  \\\n",
       "NPLV                                                                         \n",
       "510008                0.0                0.0                0.0     2909.0   \n",
       "510009                0.0                0.0                0.0     2182.0   \n",
       "510010                0.0                0.0                0.0     2841.0   \n",
       "510011                0.0                0.0                0.0       10.0   \n",
       "510012                0.0                0.0                0.0     3225.0   \n",
       "...                   ...                ...                ...        ...   \n",
       "512318                0.0                0.0                0.0     1917.0   \n",
       "512319                0.0                0.0                0.0     1660.0   \n",
       "512320                0.0                0.0                0.0        0.0   \n",
       "512321                0.0                0.0                0.0      371.0   \n",
       "512322                0.0                0.0                0.0      665.0   \n",
       "\n",
       "        total_duration_вн.пл.прост._0  total_duration_межпл.прост._0  \\\n",
       "NPLV                                                                   \n",
       "510008                          246.0                            0.0   \n",
       "510009                          922.0                            0.0   \n",
       "510010                            0.0                            0.0   \n",
       "510011                            0.0                            0.0   \n",
       "510012                            0.0                            0.0   \n",
       "...                               ...                            ...   \n",
       "512318                          932.0                            0.0   \n",
       "512319                         1314.0                            0.0   \n",
       "512320                          438.0                            0.0   \n",
       "512321                          566.0                            0.0   \n",
       "512322                         2394.0                            0.0   \n",
       "\n",
       "        total_duration_межпл.прост._1  total_duration_опер_0  \\\n",
       "NPLV                                                           \n",
       "510008                          840.0                 2489.0   \n",
       "510009                         1140.0                 2987.0   \n",
       "510010                          594.0                 2796.0   \n",
       "510011                         1542.0                 2966.0   \n",
       "510012                          601.0                 2836.0   \n",
       "...                               ...                    ...   \n",
       "512318                          747.0                 3064.0   \n",
       "512319                         1734.0                 3783.0   \n",
       "512320                          859.0                 3150.0   \n",
       "512321                          704.0                 3654.0   \n",
       "512322                          520.0                 4842.0   \n",
       "\n",
       "        min_duration_вн.пл.прост._0  min_duration_межпл.прост._0  \\\n",
       "NPLV                                                               \n",
       "510008                        246.0                          0.0   \n",
       "510009                        302.0                          0.0   \n",
       "510010                          0.0                          0.0   \n",
       "510011                          0.0                          0.0   \n",
       "510012                          0.0                          0.0   \n",
       "...                             ...                          ...   \n",
       "512318                        179.0                          0.0   \n",
       "512319                       1314.0                          0.0   \n",
       "512320                        438.0                          0.0   \n",
       "512321                        104.0                          0.0   \n",
       "512322                       2394.0                          0.0   \n",
       "\n",
       "        min_duration_межпл.прост._1  min_duration_опер_0  \\\n",
       "NPLV                                                       \n",
       "510008                         46.0                 16.0   \n",
       "510009                         54.0                 31.0   \n",
       "510010                         55.0                133.0   \n",
       "510011                         42.0                 17.0   \n",
       "510012                         43.0                 54.0   \n",
       "...                             ...                  ...   \n",
       "512318                         94.0                  0.0   \n",
       "512319                         33.0                  0.0   \n",
       "512320                         62.0                  0.0   \n",
       "512321                         38.0                  0.0   \n",
       "512322                         18.0                  0.0   \n",
       "\n",
       "        max_duration_вн.пл.прост._0  max_duration_межпл.прост._0  \\\n",
       "NPLV                                                               \n",
       "510008                        246.0                          0.0   \n",
       "510009                        620.0                          0.0   \n",
       "510010                          0.0                          0.0   \n",
       "510011                          0.0                          0.0   \n",
       "510012                          0.0                          0.0   \n",
       "...                             ...                          ...   \n",
       "512318                        753.0                          0.0   \n",
       "512319                       1314.0                          0.0   \n",
       "512320                        438.0                          0.0   \n",
       "512321                        462.0                          0.0   \n",
       "512322                       2394.0                          0.0   \n",
       "\n",
       "        max_duration_межпл.прост._1  max_duration_опер_0  \\\n",
       "NPLV                                                       \n",
       "510008                        424.0               1170.0   \n",
       "510009                        574.0               1230.0   \n",
       "510010                        301.0               1226.0   \n",
       "510011                        775.0               1058.0   \n",
       "510012                        305.0               1239.0   \n",
       "...                             ...                  ...   \n",
       "512318                        377.0               1063.0   \n",
       "512319                        870.0               1415.0   \n",
       "512320                        434.0               1058.0   \n",
       "512321                        355.0               1169.0   \n",
       "512322                        263.0               2446.0   \n",
       "\n",
       "        total_operations_вн.пл.прост._0  total_operations_межпл.прост._0  \\\n",
       "NPLV                                                                       \n",
       "510008                              1.0                              0.0   \n",
       "510009                              2.0                              0.0   \n",
       "510010                              0.0                              0.0   \n",
       "510011                              0.0                              0.0   \n",
       "510012                              0.0                              0.0   \n",
       "...                                 ...                              ...   \n",
       "512318                              2.0                              0.0   \n",
       "512319                              1.0                              0.0   \n",
       "512320                              1.0                              0.0   \n",
       "512321                              2.0                              0.0   \n",
       "512322                              1.0                              0.0   \n",
       "\n",
       "        total_operations_межпл.прост._1  total_operations_опер_0  min_mass  \\\n",
       "NPLV                                                                         \n",
       "510008                              5.0                      6.0       220   \n",
       "510009                              6.0                      6.0        10   \n",
       "510010                              4.0                      6.0        10   \n",
       "510011                              4.0                      7.0       320   \n",
       "510012                              4.0                      9.0        40   \n",
       "...                                 ...                      ...       ...   \n",
       "512318                              3.0                      9.0        30   \n",
       "512319                              5.0                      8.0        10   \n",
       "512320                              4.0                      8.0        20   \n",
       "512321                              4.0                      9.0        10   \n",
       "512322                              3.0                      8.0        10   \n",
       "\n",
       "        max_mass  total_count  unique_count  min_ratio  max_ratio  \\\n",
       "NPLV                                                                \n",
       "510008      7300           12             4   0.000834   0.027683   \n",
       "510009      9950           15             4   0.000038   0.037618   \n",
       "510010      5050           13             5   0.000038   0.019143   \n",
       "510011      5020           13             4   0.001212   0.019015   \n",
       "510012      4980           16             5   0.000152   0.018914   \n",
       "...          ...          ...           ...        ...        ...   \n",
       "512318      3700           15             2   0.000112   0.013847   \n",
       "512319      3710           15             3   0.000037   0.013906   \n",
       "512320      4570           15             3   0.000072   0.016552   \n",
       "512321      3080           11             3   0.000036   0.011168   \n",
       "512322      4820           20             2   0.000036   0.017264   \n",
       "\n",
       "        unique_ratio  \n",
       "NPLV                  \n",
       "510008      0.333333  \n",
       "510009      0.266667  \n",
       "510010      0.384615  \n",
       "510011      0.307692  \n",
       "510012      0.312500  \n",
       "...              ...  \n",
       "512318      0.133333  \n",
       "512319      0.200000  \n",
       "512320      0.200000  \n",
       "512321      0.272727  \n",
       "512322      0.100000  \n",
       "\n",
       "[2061 rows x 113 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уаааэээаээыэыээа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp[\"is_train\"] = 1\n",
    "test_exp[\"is_train\"] = 0\n",
    "\n",
    "final = pd.concat([train_exp, test_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(final.drop(columns=[\"is_train\"]), final[\"is_train\"], \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_seconds',\n",
       " 'total_operations_межпл.прост._1',\n",
       " 'total_operations_межпл.прост._0',\n",
       " 'total_operations_вн.пл.прост._0',\n",
       " 'max_duration_опер_0',\n",
       " 'max_duration_межпл.прост._1',\n",
       " 'max_duration_межпл.прост._0',\n",
       " 'max_duration_вн.пл.прост._0',\n",
       " 'min_duration_опер_0',\n",
       " 'min_duration_межпл.прост._1',\n",
       " 'min_duration_межпл.прост._0',\n",
       " 'min_duration_вн.пл.прост._0',\n",
       " 'total_duration_опер_0',\n",
       " 'total_duration_межпл.прост._1',\n",
       " 'total_duration_межпл.прост._0',\n",
       " 'total_duration_вн.пл.прост._0',\n",
       " 'O2_опер_0',\n",
       " 'O2_межпл.прост._1',\n",
       " 'O2_межпл.прост._0',\n",
       " 'O2_вн.пл.прост._0',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '6',\n",
       " '5',\n",
       " '4',\n",
       " '3',\n",
       " '2',\n",
       " '1',\n",
       " '0',\n",
       " 'POL_mean',\n",
       " 'RAS_mean',\n",
       " 'durationproduv_',\n",
       " 'ves_loma/ves_chuguna',\n",
       " 'ves_loma',\n",
       " 'ti_portion',\n",
       " 'v_portion',\n",
       " 'cu_portion',\n",
       " 'ni_portion',\n",
       " 'cr_portion',\n",
       " 'p_portion',\n",
       " 's_portion',\n",
       " 'mn_portion',\n",
       " 'si_portion',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds',\n",
       " 'total_seconds']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1.0\n",
      "1.0 total_seconds\n",
      "[20:06:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1.0\n",
      "1.0 total_operations_опер_0\n",
      "[20:06:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920308636458426\n",
      "0.9920308636458426 total_duration_опер_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9928007362546017\n",
      "0.9928007362546017 gas_mean_volume_AR\n",
      "[20:06:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9931745099251746\n",
      "0.9931745099251746 gas_mean_T фурмы 1\n",
      "[20:06:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9896190906353508\n",
      "0.9896190906353508 gas_mean_AR\n",
      "[20:06:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998812351543943\n",
      "0.998812351543943 durationproduv_\n",
      "[20:06:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 0\n",
      "[20:06:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998812351543943\n",
      "0.998812351543943 O2_опер_0\n",
      "[20:06:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936708860759494\n",
      "0.9936708860759494 gas_mean_T фурмы 2\n",
      "[20:06:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987509739753779\n",
      "0.987509739753779 min_duration_опер_0\n",
      "[20:06:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9907577849363399\n",
      "0.9907577849363399 gas_mean_O2_pressure\n",
      "[20:06:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9878787878787878\n",
      "0.9878787878787878 gas_mean_V\n",
      "[20:06:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9843626223898095\n",
      "0.9843626223898095 gas_std_CO\n",
      "[20:06:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936708860759494\n",
      "0.9936708860759494 gas_std_volume_O2\n",
      "[20:06:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809679954063283\n",
      "0.9809679954063283 gas_std_N2\n",
      "[20:06:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9879071217079631\n",
      "0.9879071217079631 gas_mean_CO\n",
      "[20:06:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870552370552371\n",
      "0.9870552370552371 VES\n",
      "[20:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9665391539153915\n",
      "0.9665391539153915 gas_std_volume_AR\n",
      "[20:06:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732326753065687\n",
      "0.9732326753065687 p_portion\n",
      "[20:06:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9847581796734338\n",
      "0.9847581796734338 gas_sum_volume_CO\n",
      "[20:06:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856656804733728\n",
      "0.9856656804733728 P\n",
      "[20:06:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747281980106409\n",
      "0.9747281980106409 MN\n",
      "[20:06:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9693225489319867\n",
      "0.9693225489319867 cr_portion\n",
      "[20:06:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9812176746688989\n",
      "0.9812176746688989 CR\n",
      "[20:06:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900521552385335\n",
      "0.9900521552385335 gas_mean_volume_CO2\n",
      "[20:06:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817441251655427\n",
      "0.9817441251655427 gas_sum_volume_CO2\n",
      "[20:06:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9867526541255356\n",
      "0.9867526541255356 gas_std_O2\n",
      "[20:06:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833223353443942\n",
      "0.9833223353443942 gas_std_O2_pressure\n",
      "[20:06:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768676867686769\n",
      "0.9768676867686769 gas_std_volume_CO2\n",
      "[20:06:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767899408284024\n",
      "0.9767899408284024 gas_mean_volume_N2\n",
      "[20:06:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827071005917161\n",
      "0.9827071005917161 gas_mean_volume_O2\n",
      "[20:06:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802477793361384\n",
      "0.9802477793361384 gas_mean_CO2\n",
      "[20:06:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97310937260316\n",
      "0.97310937260316 ti_portion\n",
      "[20:07:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760916847917015\n",
      "0.9760916847917015 total_duration_межпл.прост._0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9760679079956189\n",
      "0.9760679079956189 gas_std_CO2\n",
      "[20:07:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9784645352792035\n",
      "0.9784645352792035 min_mass\n",
      "[20:07:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703946370613038\n",
      "0.9703946370613038 4\n",
      "[20:07:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9631675179062529\n",
      "0.9631675179062529 unique_ratio\n",
      "[20:07:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796105678504032\n",
      "0.9796105678504032 gas_std_AR\n",
      "[20:07:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664832106857956\n",
      "0.9664832106857956 RAS_mean\n",
      "[20:07:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9754150112414919\n",
      "0.9754150112414919 TI\n",
      "[20:07:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732823282328233\n",
      "0.9732823282328233 bow_SC2\n",
      "[20:07:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663970588235293\n",
      "0.9663970588235293 gas_std_T фурмы 1\n",
      "[20:07:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716726320673428\n",
      "0.9716726320673428 gas_mean_volume_CO\n",
      "[20:07:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748237585801744\n",
      "0.9748237585801744 gas_sum_volume_N2\n",
      "[20:07:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9815793754066364\n",
      "0.9815793754066364 gas_std_volume_CO\n",
      "[20:07:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973658269441402\n",
      "0.973658269441402 min_duration_межпл.прост._0\n",
      "[20:07:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9773630231913518\n",
      "0.9773630231913518 max_duration_межпл.прост._0\n",
      "[20:07:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979955509276789\n",
      "0.979955509276789 total_operations_межпл.прост._0\n",
      "[20:07:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775825183374084\n",
      "0.9775825183374084 POL_mean\n",
      "[20:07:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9572697522206639\n",
      "0.9572697522206639 6\n",
      "[20:07:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785935426802299\n",
      "0.9785935426802299 duration\n",
      "[20:07:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735184137757668\n",
      "0.9735184137757668 gas_mean_O2\n",
      "[20:07:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696391394864677\n",
      "0.9696391394864677 2\n",
      "[20:07:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714523629964806\n",
      "0.9714523629964806 gas_duration\n",
      "[20:07:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9530867143993635\n",
      "0.9530867143993635 5\n",
      "[20:07:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94130696926597\n",
      "0.94130696926597 v_portion\n",
      "[20:07:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9667970583633234\n",
      "0.9667970583633234 gas_std_T фурмы 2\n",
      "[20:07:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9674591503267973\n",
      "0.9674591503267973 bow_Ст3\n",
      "[20:07:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9463846033972261\n",
      "0.9463846033972261 gas_sum_volume_AR\n",
      "[20:07:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425995753984601\n",
      "0.9425995753984601 total_duration_вн.пл.прост._0\n",
      "[20:07:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9197374333953906\n",
      "0.9197374333953906 st_diff_is_zero\n",
      "[20:07:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9271452145214523\n",
      "0.9271452145214523 ni_portion\n",
      "[20:07:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419850244498779\n",
      "0.9419850244498779 CU\n",
      "[20:07:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958477481689263\n",
      "0.958477481689263 truncated_NMZ\n",
      "[20:07:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9188639785845742\n",
      "0.9188639785845742 max_duration_вн.пл.прост._0\n",
      "[20:07:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351666405883272\n",
      "0.9351666405883272 mn_portion\n",
      "[20:07:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959051432819681\n",
      "0.959051432819681 total_operations_вн.пл.прост._0\n",
      "[20:07:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9407000795544948\n",
      "0.9407000795544948 bow_.z0\n",
      "[20:07:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9183414427755447\n",
      "0.9183414427755447 S\n",
      "[20:07:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9297274917193615\n",
      "0.9297274917193615 V\n",
      "[20:07:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331635236988709\n",
      "0.9331635236988709 min_duration_вн.пл.прост._0\n",
      "[20:07:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420678185346022\n",
      "0.9420678185346022 gas_mean_volume_H2\n",
      "[20:07:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9104080380426447\n",
      "0.9104080380426447 plavka_TIPE_FUR\n",
      "[20:07:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9362527001321856\n",
      "0.9362527001321856 ves_loma\n",
      "[20:07:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9025540692207359\n",
      "0.9025540692207359 min_ratio\n",
      "[20:07:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9437020810514787\n",
      "0.9437020810514787 cu_portion\n",
      "[20:07:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9237814636985304\n",
      "0.9237814636985304 total_operations_межпл.прост._1\n",
      "[20:07:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9106831648658069\n",
      "0.9106831648658069 unique_count\n",
      "[20:07:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9106699346405229\n",
      "0.9106699346405229 max_ratio\n",
      "[20:07:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9040907612231621\n",
      "0.9040907612231621 dayofmonth\n",
      "[20:07:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8946706644743205\n",
      "0.8946706644743205 plavka_TIPE_GOL\n",
      "[20:07:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649672042840395\n",
      "0.8649672042840395 7\n",
      "[20:07:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8812030557873789\n",
      "0.8812030557873789 gas_std_H2\n",
      "[20:07:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8468857617860113\n",
      "0.8468857617860113 gas_mean_T\n",
      "[20:07:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8631293767229633\n",
      "0.8631293767229633 s_portion\n",
      "[20:07:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424262568795995\n",
      "0.8424262568795995 3\n",
      "[20:07:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8081601466992666\n",
      "0.8081601466992666 gas_std_volume_H2\n",
      "[20:07:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8510546500479386\n",
      "0.8510546500479386 8\n",
      "[20:07:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8303480348034803\n",
      "0.8303480348034803 gas_mean_H2\n",
      "[20:07:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818510246978455\n",
      "0.818510246978455 NI\n",
      "[20:07:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8423070803500398\n",
      "0.8423070803500398 1\n",
      "[20:07:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305351275230792\n",
      "0.8305351275230792 gas_std_T\n",
      "[20:07:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8003026078139358\n",
      "0.8003026078139358 gas_sum_volume_H2\n",
      "[20:07:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511862116641528\n",
      "0.7511862116641528 plavka_NAPR_ZAD\n",
      "[20:07:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7649914290166745\n",
      "0.7649914290166745 gas_sum_volume_O2\n",
      "[20:07:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7415177964950415\n"
     ]
    }
   ],
   "source": [
    "score = 1\n",
    "drop_cols = []\n",
    "\n",
    "while score > 0.75:\n",
    "    final = pd.concat([train_exp, test_exp]).drop(columns=drop_cols)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(final.drop(columns=[\"is_train\"]), final[\"is_train\"], \n",
    "                                                      test_size=0.2, shuffle=True)\n",
    "    \n",
    "    model = XGBClassifier().fit(X_train, y_train)\n",
    "    score = roc_auc_score(y_val, model.predict(X_val))\n",
    "    print(score)\n",
    "    feats = sorted(zip(model.feature_importances_, final.columns), reverse=True)[:20]\n",
    "    if score > 0.75:\n",
    "        to_remove = feats[0][1]\n",
    "        drop_cols.append(to_remove)\n",
    "        \n",
    "        print(score, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:01:26] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"label_encoder\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:01:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(label_encoder=False).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967105263157895"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.90479463, 'total_operations_вн.пл.прост._0'),\n",
       " (0.022730472, 'total_duration_межпл.прост._1'),\n",
       " (0.0062859147, 'VES'),\n",
       " (0.005563673, 'gas_mean_volume_AR'),\n",
       " (0.005538115, 'gas_std_volume_H2'),\n",
       " (0.0054176436, 'truncated_NMZ'),\n",
       " (0.0054025394, 'gas_mean_T фурмы 1'),\n",
       " (0.004650924, 'bow_.z0'),\n",
       " (0.004312052, 'POL_mean'),\n",
       " (0.004301582, 'gas_std_H2'),\n",
       " (0.0042566555, 'RAS_mean'),\n",
       " (0.0042419597, 'gas_mean_T фурмы 2'),\n",
       " (0.004045379, 's_portion'),\n",
       " (0.0038444232, 'gas_mean_V'),\n",
       " (0.0035454775, 'gas_mean_AR'),\n",
       " (0.0032197682, '0'),\n",
       " (0.0028090724, 'gas_std_T'),\n",
       " (0.0026673574, 'p_portion'),\n",
       " (0.0019110536, 'gas_std_N2'),\n",
       " (0.0004613711, 'durationproduv_')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model.feature_importances_, train.columns), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_mean_N2</th>\n",
       "      <th>gas_std_V</th>\n",
       "      <th>gas_std_volume_N2</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>bow_/Э</th>\n",
       "      <th>bow_/ЭТ</th>\n",
       "      <th>bow_3пс</th>\n",
       "      <th>bow_ЭТ</th>\n",
       "      <th>bow_пс/</th>\n",
       "      <th>bow_с/Э</th>\n",
       "      <th>bow_т3п</th>\n",
       "      <th>T</th>\n",
       "      <th>SI</th>\n",
       "      <th>si_portion</th>\n",
       "      <th>ves_loma/ves_chuguna</th>\n",
       "      <th>9</th>\n",
       "      <th>O2_вн.пл.прост._0</th>\n",
       "      <th>O2_межпл.прост._0</th>\n",
       "      <th>O2_межпл.прост._1</th>\n",
       "      <th>total_duration_межпл.прост._1</th>\n",
       "      <th>min_duration_межпл.прост._1</th>\n",
       "      <th>max_duration_межпл.прост._1</th>\n",
       "      <th>max_duration_опер_0</th>\n",
       "      <th>max_mass</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPLV</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510008</th>\n",
       "      <td>60.971011</td>\n",
       "      <td>5369.811888</td>\n",
       "      <td>43818.901201</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.288965</td>\n",
       "      <td>5.631197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>7300</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510009</th>\n",
       "      <td>64.784377</td>\n",
       "      <td>4250.571350</td>\n",
       "      <td>37231.830524</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>5.749108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>9950</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510010</th>\n",
       "      <td>62.633599</td>\n",
       "      <td>6659.001169</td>\n",
       "      <td>42260.955051</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>5.797691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>5050</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510011</th>\n",
       "      <td>62.605303</td>\n",
       "      <td>5341.347771</td>\n",
       "      <td>38883.156660</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.318561</td>\n",
       "      <td>5.484573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>5020</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510012</th>\n",
       "      <td>62.286450</td>\n",
       "      <td>5757.933597</td>\n",
       "      <td>41474.251736</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.289024</td>\n",
       "      <td>5.827915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>4980</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512318</th>\n",
       "      <td>53.516385</td>\n",
       "      <td>7548.831043</td>\n",
       "      <td>45978.755732</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>5.512657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512319</th>\n",
       "      <td>62.478096</td>\n",
       "      <td>6563.914573</td>\n",
       "      <td>48829.070068</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.287106</td>\n",
       "      <td>5.563581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>3710</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512320</th>\n",
       "      <td>56.626062</td>\n",
       "      <td>7688.084786</td>\n",
       "      <td>51525.321369</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>5.480371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>4570</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512321</th>\n",
       "      <td>54.750024</td>\n",
       "      <td>5914.722753</td>\n",
       "      <td>45872.532849</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.240029</td>\n",
       "      <td>5.727036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>3080</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512322</th>\n",
       "      <td>63.371647</td>\n",
       "      <td>7144.194096</td>\n",
       "      <td>42906.725770</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.272564</td>\n",
       "      <td>6.046026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>4820</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gas_mean_N2    gas_std_V  gas_std_volume_N2  hour  dayofweek  bow_/Э   \\\n",
       "NPLV                                                                            \n",
       "510008    60.971011  5369.811888       43818.901201     3          4        0   \n",
       "510009    64.784377  4250.571350       37231.830524     4          4        0   \n",
       "510010    62.633599  6659.001169       42260.955051     5          4        1   \n",
       "510011    62.605303  5341.347771       38883.156660     6          4        0   \n",
       "510012    62.286450  5757.933597       41474.251736     7          4        0   \n",
       "...             ...          ...                ...   ...        ...      ...   \n",
       "512318    53.516385  7548.831043       45978.755732    13          0        0   \n",
       "512319    62.478096  6563.914573       48829.070068    14          0        0   \n",
       "512320    56.626062  7688.084786       51525.321369    15          0        0   \n",
       "512321    54.750024  5914.722753       45872.532849    16          0        0   \n",
       "512322    63.371647  7144.194096       42906.725770    17          0        0   \n",
       "\n",
       "        bow_/ЭТ  bow_3пс  bow_ЭТ   bow_пс/  bow_с/Э  bow_т3п       T    SI  \\\n",
       "NPLV                                                                         \n",
       "510008        0        0        0        0        0        0  1396.0  0.44   \n",
       "510009        0        0        0        0        0        0  1419.0  0.68   \n",
       "510010        0        1        0        1        1        1  1384.0  0.56   \n",
       "510011        0        0        0        0        0        0  1401.0  0.48   \n",
       "510012        1        0        1        0        0        0  1422.0  0.47   \n",
       "...         ...      ...      ...      ...      ...      ...     ...   ...   \n",
       "512318        1        0        1        0        0        0  1415.0  0.38   \n",
       "512319        1        0        1        0        0        0  1405.0  0.50   \n",
       "512320        0        0        0        0        0        0  1398.0  0.61   \n",
       "512321        0        0        0        0        0        0  1408.0  0.38   \n",
       "512322        0        0        0        0        0        0  1413.0  0.50   \n",
       "\n",
       "        si_portion  ves_loma/ves_chuguna         9  O2_вн.пл.прост._0  \\\n",
       "NPLV                                                                    \n",
       "510008    0.000002              0.288965  5.631197                0.0   \n",
       "510009    0.000003              0.297164  5.749108                0.0   \n",
       "510010    0.000002              0.289234  5.797691                0.0   \n",
       "510011    0.000002              0.318561  5.484573                0.0   \n",
       "510012    0.000002              0.289024  5.827915                0.0   \n",
       "...            ...                   ...       ...                ...   \n",
       "512318    0.000001              0.275449  5.512657                0.0   \n",
       "512319    0.000002              0.287106  5.563581                0.0   \n",
       "512320    0.000002              0.232524  5.480371                0.0   \n",
       "512321    0.000001              0.240029  5.727036                0.0   \n",
       "512322    0.000002              0.272564  6.046026                0.0   \n",
       "\n",
       "        O2_межпл.прост._0  O2_межпл.прост._1  total_duration_межпл.прост._1  \\\n",
       "NPLV                                                                          \n",
       "510008                0.0                0.0                          840.0   \n",
       "510009                0.0                0.0                         1140.0   \n",
       "510010                0.0                0.0                          594.0   \n",
       "510011                0.0                0.0                         1542.0   \n",
       "510012                0.0                0.0                          601.0   \n",
       "...                   ...                ...                            ...   \n",
       "512318                0.0                0.0                          747.0   \n",
       "512319                0.0                0.0                         1734.0   \n",
       "512320                0.0                0.0                          859.0   \n",
       "512321                0.0                0.0                          704.0   \n",
       "512322                0.0                0.0                          520.0   \n",
       "\n",
       "        min_duration_межпл.прост._1  max_duration_межпл.прост._1  \\\n",
       "NPLV                                                               \n",
       "510008                         46.0                        424.0   \n",
       "510009                         54.0                        574.0   \n",
       "510010                         55.0                        301.0   \n",
       "510011                         42.0                        775.0   \n",
       "510012                         43.0                        305.0   \n",
       "...                             ...                          ...   \n",
       "512318                         94.0                        377.0   \n",
       "512319                         33.0                        870.0   \n",
       "512320                         62.0                        434.0   \n",
       "512321                         38.0                        355.0   \n",
       "512322                         18.0                        263.0   \n",
       "\n",
       "        max_duration_опер_0  max_mass  total_count  \n",
       "NPLV                                                \n",
       "510008               1170.0      7300           12  \n",
       "510009               1230.0      9950           15  \n",
       "510010               1226.0      5050           13  \n",
       "510011               1058.0      5020           13  \n",
       "510012               1239.0      4980           16  \n",
       "...                     ...       ...          ...  \n",
       "512318               1063.0      3700           15  \n",
       "512319               1415.0      3710           15  \n",
       "512320               1058.0      4570           15  \n",
       "512321               1169.0      3080           11  \n",
       "512322               2446.0      4820           20  \n",
       "\n",
       "[2061 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp = train.drop(columns=drop_cols)\n",
    "test_exp = test.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_columns = set(train_exp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import transform_for_linear\n",
    "\n",
    "train_exp_scaled, test_exp_scaled = transform_for_linear(train_exp, list(exp_columns.intersection(num_features)), list(exp_columns.intersection(cat_features)), test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6180d95eb49c48fca7a9152a4bca99c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon score: 0.6532288037166086 ± 0.08135455416444344\n",
      "Temperature score: 0.5285017421602788 ± 0.07750364766354875\n",
      "Overall score: 0.5908652729384437 ± 0.06094300909376339\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import NuSVR\n",
    "\n",
    "model_c = Ridge()\n",
    "model_tst = Ridge()\n",
    "\n",
    "res = pipeline(model_c, model_tst, train_exp_scaled, test_exp_scaled, train_exp_scaled, test_exp_scaled, y, sample, n_splits=50, pwc=pwrC, pwt=pwrT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"TST\"] = pwrT.inverse_transform(res[\"TST\"].values.reshape(-1, 1)).reshape(-1)\n",
    "res[\"C\"] = pwrC.inverse_transform(res[\"C\"].values.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"xgbaaaa2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pwrC = PowerTransformer('box-cox')\n",
    "pwrT = PowerTransformer('box-cox')\n",
    "\n",
    "y_exp = y.copy()\n",
    "\n",
    "y_exp[\"C\"] = pwrC.fit_transform(y['C'].values.reshape(-1, 1))\n",
    "y_exp[\"TST\"] = pwrT.fit_transform(y['TST'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1690.],\n",
       "       [1683.],\n",
       "       [1662.],\n",
       "       ...,\n",
       "       [1615.],\n",
       "       [1654.],\n",
       "       [1630.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwrT.inverse_transform(y_exp[\"TST\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 390\n"
     ]
    }
   ],
   "source": [
    "ns = set()\n",
    "\n",
    "for n in range(1, 780):\n",
    "    for k in range(2 * n):\n",
    "        if abs(k / (2 * n) - 0.5397435897435897) < 1e-8:\n",
    "            print(k, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TST</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPLV</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510008</th>\n",
       "      <td>1690</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510009</th>\n",
       "      <td>1683</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510010</th>\n",
       "      <td>1662</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510011</th>\n",
       "      <td>1609</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510012</th>\n",
       "      <td>1682</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512318</th>\n",
       "      <td>1626</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512319</th>\n",
       "      <td>1643</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512320</th>\n",
       "      <td>1615</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512321</th>\n",
       "      <td>1654</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512322</th>\n",
       "      <td>1630</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TST      C\n",
       "NPLV               \n",
       "510008  1690  0.060\n",
       "510009  1683  0.097\n",
       "510010  1662  0.091\n",
       "510011  1609  0.410\n",
       "510012  1682  0.120\n",
       "...      ...    ...\n",
       "512318  1626  0.145\n",
       "512319  1643  0.087\n",
       "512320  1615  0.141\n",
       "512321  1654  0.270\n",
       "512322  1630  0.183\n",
       "\n",
       "[2061 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=[\"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_duration</th>\n",
       "      <th>gas_mean_V</th>\n",
       "      <th>gas_mean_T</th>\n",
       "      <th>gas_mean_O2</th>\n",
       "      <th>gas_mean_N2</th>\n",
       "      <th>gas_mean_H2</th>\n",
       "      <th>gas_mean_CO2</th>\n",
       "      <th>gas_mean_CO</th>\n",
       "      <th>gas_mean_AR</th>\n",
       "      <th>gas_mean_T фурмы 1</th>\n",
       "      <th>gas_mean_T фурмы 2</th>\n",
       "      <th>gas_mean_O2_pressure</th>\n",
       "      <th>gas_std_V</th>\n",
       "      <th>gas_std_T</th>\n",
       "      <th>gas_std_O2</th>\n",
       "      <th>gas_std_N2</th>\n",
       "      <th>gas_std_H2</th>\n",
       "      <th>gas_std_CO2</th>\n",
       "      <th>gas_std_CO</th>\n",
       "      <th>gas_std_AR</th>\n",
       "      <th>gas_std_T фурмы 1</th>\n",
       "      <th>gas_std_T фурмы 2</th>\n",
       "      <th>gas_std_O2_pressure</th>\n",
       "      <th>gas_sum_volume_O2</th>\n",
       "      <th>gas_sum_volume_N2</th>\n",
       "      <th>gas_sum_volume_H2</th>\n",
       "      <th>gas_sum_volume_CO2</th>\n",
       "      <th>gas_sum_volume_CO</th>\n",
       "      <th>gas_sum_volume_AR</th>\n",
       "      <th>gas_mean_volume_O2</th>\n",
       "      <th>gas_mean_volume_N2</th>\n",
       "      <th>gas_mean_volume_H2</th>\n",
       "      <th>gas_mean_volume_CO2</th>\n",
       "      <th>gas_mean_volume_CO</th>\n",
       "      <th>gas_mean_volume_AR</th>\n",
       "      <th>gas_std_volume_O2</th>\n",
       "      <th>gas_std_volume_N2</th>\n",
       "      <th>gas_std_volume_H2</th>\n",
       "      <th>gas_std_volume_CO2</th>\n",
       "      <th>gas_std_volume_CO</th>\n",
       "      <th>gas_std_volume_AR</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>hour</th>\n",
       "      <th>duration</th>\n",
       "      <th>truncated_NMZ</th>\n",
       "      <th>st_diff_is_zero</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>plavka_TIPE_GOL</th>\n",
       "      <th>plavka_TIPE_FUR</th>\n",
       "      <th>plavka_NAPR_ZAD</th>\n",
       "      <th>bow_.z0</th>\n",
       "      <th>bow_/Э</th>\n",
       "      <th>bow_/ЭТ</th>\n",
       "      <th>bow_3пс</th>\n",
       "      <th>bow_SC2</th>\n",
       "      <th>bow_Ст3</th>\n",
       "      <th>bow_ЭТ</th>\n",
       "      <th>bow_пс/</th>\n",
       "      <th>bow_с/Э</th>\n",
       "      <th>bow_т3п</th>\n",
       "      <th>VES</th>\n",
       "      <th>T</th>\n",
       "      <th>SI</th>\n",
       "      <th>MN</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>CR</th>\n",
       "      <th>NI</th>\n",
       "      <th>CU</th>\n",
       "      <th>V</th>\n",
       "      <th>TI</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>si_portion</th>\n",
       "      <th>mn_portion</th>\n",
       "      <th>s_portion</th>\n",
       "      <th>p_portion</th>\n",
       "      <th>cr_portion</th>\n",
       "      <th>ni_portion</th>\n",
       "      <th>cu_portion</th>\n",
       "      <th>v_portion</th>\n",
       "      <th>ti_portion</th>\n",
       "      <th>ves_loma</th>\n",
       "      <th>ves_loma/ves_chuguna</th>\n",
       "      <th>durationproduv_</th>\n",
       "      <th>RAS_mean</th>\n",
       "      <th>POL_mean</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>O2_вн.пл.прост._0</th>\n",
       "      <th>O2_межпл.прост._0</th>\n",
       "      <th>O2_межпл.прост._1</th>\n",
       "      <th>O2_опер_0</th>\n",
       "      <th>total_duration_вн.пл.прост._0</th>\n",
       "      <th>total_duration_межпл.прост._0</th>\n",
       "      <th>total_duration_межпл.прост._1</th>\n",
       "      <th>total_duration_опер_0</th>\n",
       "      <th>min_duration_вн.пл.прост._0</th>\n",
       "      <th>min_duration_межпл.прост._0</th>\n",
       "      <th>min_duration_межпл.прост._1</th>\n",
       "      <th>min_duration_опер_0</th>\n",
       "      <th>max_duration_вн.пл.прост._0</th>\n",
       "      <th>max_duration_межпл.прост._0</th>\n",
       "      <th>max_duration_межпл.прост._1</th>\n",
       "      <th>max_duration_опер_0</th>\n",
       "      <th>total_operations_вн.пл.прост._0</th>\n",
       "      <th>total_operations_межпл.прост._0</th>\n",
       "      <th>total_operations_межпл.прост._1</th>\n",
       "      <th>total_operations_опер_0</th>\n",
       "      <th>min_mass</th>\n",
       "      <th>max_mass</th>\n",
       "      <th>total_count</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>min_ratio</th>\n",
       "      <th>max_ratio</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>TST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPLV</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510008</th>\n",
       "      <td>2560</td>\n",
       "      <td>216789.292999</td>\n",
       "      <td>506.912198</td>\n",
       "      <td>8.080398</td>\n",
       "      <td>60.971011</td>\n",
       "      <td>0.300348</td>\n",
       "      <td>13.646908</td>\n",
       "      <td>16.236455</td>\n",
       "      <td>0.801776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.356058</td>\n",
       "      <td>5369.811888</td>\n",
       "      <td>273.329244</td>\n",
       "      <td>8.601033</td>\n",
       "      <td>19.843291</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>7.340789</td>\n",
       "      <td>20.627802</td>\n",
       "      <td>0.189599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>4.502321e+07</td>\n",
       "      <td>3.391881e+08</td>\n",
       "      <td>1.624003e+06</td>\n",
       "      <td>7.575220e+07</td>\n",
       "      <td>8.913852e+07</td>\n",
       "      <td>4.458630e+06</td>\n",
       "      <td>17587.192761</td>\n",
       "      <td>132495.366168</td>\n",
       "      <td>634.376020</td>\n",
       "      <td>29590.704477</td>\n",
       "      <td>34819.734247</td>\n",
       "      <td>1741.652526</td>\n",
       "      <td>18701.426346</td>\n",
       "      <td>43818.901201</td>\n",
       "      <td>1655.726824</td>\n",
       "      <td>15946.086198</td>\n",
       "      <td>44086.505490</td>\n",
       "      <td>425.909341</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263700.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.609471e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.342814e-07</td>\n",
       "      <td>8.722033e-08</td>\n",
       "      <td>3.678422e-07</td>\n",
       "      <td>1.137656e-07</td>\n",
       "      <td>3.792188e-08</td>\n",
       "      <td>1.137656e-07</td>\n",
       "      <td>3.905954e-07</td>\n",
       "      <td>3.185438e-07</td>\n",
       "      <td>76200</td>\n",
       "      <td>0.288965</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>833.024315</td>\n",
       "      <td>1.145962</td>\n",
       "      <td>-1.156259</td>\n",
       "      <td>8.058909</td>\n",
       "      <td>7.624763</td>\n",
       "      <td>6.477648</td>\n",
       "      <td>4.481481</td>\n",
       "      <td>5.410652</td>\n",
       "      <td>6.022574</td>\n",
       "      <td>5.195676</td>\n",
       "      <td>5.381444</td>\n",
       "      <td>5.631197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220</td>\n",
       "      <td>7300</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510009</th>\n",
       "      <td>3949</td>\n",
       "      <td>217054.421867</td>\n",
       "      <td>375.840941</td>\n",
       "      <td>10.985339</td>\n",
       "      <td>64.784377</td>\n",
       "      <td>0.163313</td>\n",
       "      <td>11.761720</td>\n",
       "      <td>11.466482</td>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.950163</td>\n",
       "      <td>4250.571350</td>\n",
       "      <td>291.238099</td>\n",
       "      <td>10.616286</td>\n",
       "      <td>16.819827</td>\n",
       "      <td>0.538952</td>\n",
       "      <td>8.095644</td>\n",
       "      <td>18.080320</td>\n",
       "      <td>0.167612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003299</td>\n",
       "      <td>9.485353e+07</td>\n",
       "      <td>5.562788e+08</td>\n",
       "      <td>1.364358e+06</td>\n",
       "      <td>1.004032e+08</td>\n",
       "      <td>9.705018e+07</td>\n",
       "      <td>7.193678e+06</td>\n",
       "      <td>24019.631951</td>\n",
       "      <td>140865.726324</td>\n",
       "      <td>345.494449</td>\n",
       "      <td>25424.967838</td>\n",
       "      <td>24575.886359</td>\n",
       "      <td>1821.645526</td>\n",
       "      <td>23278.991109</td>\n",
       "      <td>37231.830524</td>\n",
       "      <td>1123.023713</td>\n",
       "      <td>17501.298735</td>\n",
       "      <td>38641.706115</td>\n",
       "      <td>373.312144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264500.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.609475e+09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.561437e-07</td>\n",
       "      <td>6.427221e-08</td>\n",
       "      <td>3.289225e-07</td>\n",
       "      <td>7.561437e-08</td>\n",
       "      <td>3.780718e-08</td>\n",
       "      <td>1.134216e-07</td>\n",
       "      <td>3.175803e-07</td>\n",
       "      <td>3.629490e-07</td>\n",
       "      <td>78600</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>832.179153</td>\n",
       "      <td>1.346743</td>\n",
       "      <td>-0.674527</td>\n",
       "      <td>12.779936</td>\n",
       "      <td>5.824023</td>\n",
       "      <td>2.713871</td>\n",
       "      <td>4.521441</td>\n",
       "      <td>5.085553</td>\n",
       "      <td>6.196332</td>\n",
       "      <td>5.750713</td>\n",
       "      <td>4.999381</td>\n",
       "      <td>5.749108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>2987.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9950</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510010</th>\n",
       "      <td>2871</td>\n",
       "      <td>215606.942311</td>\n",
       "      <td>489.881937</td>\n",
       "      <td>8.745518</td>\n",
       "      <td>62.633599</td>\n",
       "      <td>0.312984</td>\n",
       "      <td>12.723079</td>\n",
       "      <td>14.755786</td>\n",
       "      <td>0.828832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.022366</td>\n",
       "      <td>6659.001169</td>\n",
       "      <td>301.143710</td>\n",
       "      <td>9.489587</td>\n",
       "      <td>19.181862</td>\n",
       "      <td>0.797407</td>\n",
       "      <td>8.108025</td>\n",
       "      <td>19.036043</td>\n",
       "      <td>0.167892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330850</td>\n",
       "      <td>5.488448e+07</td>\n",
       "      <td>3.886485e+08</td>\n",
       "      <td>1.874444e+06</td>\n",
       "      <td>7.840161e+07</td>\n",
       "      <td>9.005883e+07</td>\n",
       "      <td>5.138755e+06</td>\n",
       "      <td>19116.849917</td>\n",
       "      <td>135370.437027</td>\n",
       "      <td>652.889050</td>\n",
       "      <td>27308.119240</td>\n",
       "      <td>31368.453349</td>\n",
       "      <td>1789.883300</td>\n",
       "      <td>20947.742464</td>\n",
       "      <td>42260.955051</td>\n",
       "      <td>1623.914332</td>\n",
       "      <td>17333.228492</td>\n",
       "      <td>40336.007001</td>\n",
       "      <td>376.987465</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>263800.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.609478e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.855951e-07</td>\n",
       "      <td>6.444276e-08</td>\n",
       "      <td>3.639121e-07</td>\n",
       "      <td>1.137225e-07</td>\n",
       "      <td>3.790751e-08</td>\n",
       "      <td>1.137225e-07</td>\n",
       "      <td>4.359363e-07</td>\n",
       "      <td>4.169826e-07</td>\n",
       "      <td>76300</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>821.524510</td>\n",
       "      <td>1.262255</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>12.429848</td>\n",
       "      <td>5.910546</td>\n",
       "      <td>2.883735</td>\n",
       "      <td>4.516992</td>\n",
       "      <td>5.105981</td>\n",
       "      <td>6.147994</td>\n",
       "      <td>5.715422</td>\n",
       "      <td>5.011985</td>\n",
       "      <td>5.797691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>2796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5050</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510011</th>\n",
       "      <td>3261</td>\n",
       "      <td>218908.844905</td>\n",
       "      <td>439.273874</td>\n",
       "      <td>9.016227</td>\n",
       "      <td>62.605303</td>\n",
       "      <td>0.100366</td>\n",
       "      <td>13.566362</td>\n",
       "      <td>13.771099</td>\n",
       "      <td>0.835434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.250926</td>\n",
       "      <td>5341.347771</td>\n",
       "      <td>267.257197</td>\n",
       "      <td>8.395936</td>\n",
       "      <td>17.444834</td>\n",
       "      <td>0.215926</td>\n",
       "      <td>7.790133</td>\n",
       "      <td>18.094440</td>\n",
       "      <td>0.194226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665478</td>\n",
       "      <td>6.478924e+07</td>\n",
       "      <td>4.477267e+08</td>\n",
       "      <td>7.091111e+05</td>\n",
       "      <td>9.674182e+07</td>\n",
       "      <td>9.717645e+07</td>\n",
       "      <td>5.974200e+06</td>\n",
       "      <td>19867.905305</td>\n",
       "      <td>137297.364374</td>\n",
       "      <td>217.452049</td>\n",
       "      <td>29666.305531</td>\n",
       "      <td>29799.586702</td>\n",
       "      <td>1832.014654</td>\n",
       "      <td>18607.672797</td>\n",
       "      <td>38883.156660</td>\n",
       "      <td>468.388798</td>\n",
       "      <td>17089.798747</td>\n",
       "      <td>39012.937295</td>\n",
       "      <td>437.916480</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264000.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.609482e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.022727e-06</td>\n",
       "      <td>6.818182e-08</td>\n",
       "      <td>3.446970e-07</td>\n",
       "      <td>1.136364e-07</td>\n",
       "      <td>3.787879e-08</td>\n",
       "      <td>7.575758e-08</td>\n",
       "      <td>4.242424e-07</td>\n",
       "      <td>4.166667e-07</td>\n",
       "      <td>84100</td>\n",
       "      <td>0.318561</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>805.565217</td>\n",
       "      <td>1.442741</td>\n",
       "      <td>-0.561065</td>\n",
       "      <td>-3.350970</td>\n",
       "      <td>7.085355</td>\n",
       "      <td>2.852356</td>\n",
       "      <td>4.773051</td>\n",
       "      <td>5.025595</td>\n",
       "      <td>6.558962</td>\n",
       "      <td>4.313759</td>\n",
       "      <td>5.554585</td>\n",
       "      <td>5.484573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>320</td>\n",
       "      <td>5020</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510012</th>\n",
       "      <td>2860</td>\n",
       "      <td>217981.805452</td>\n",
       "      <td>478.608197</td>\n",
       "      <td>8.470485</td>\n",
       "      <td>62.286450</td>\n",
       "      <td>0.442823</td>\n",
       "      <td>13.643787</td>\n",
       "      <td>14.273926</td>\n",
       "      <td>0.802074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.259779</td>\n",
       "      <td>5757.933597</td>\n",
       "      <td>282.254884</td>\n",
       "      <td>9.054424</td>\n",
       "      <td>18.477454</td>\n",
       "      <td>0.878580</td>\n",
       "      <td>8.633744</td>\n",
       "      <td>18.366216</td>\n",
       "      <td>0.182802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652421</td>\n",
       "      <td>5.328600e+07</td>\n",
       "      <td>3.894694e+08</td>\n",
       "      <td>2.698631e+06</td>\n",
       "      <td>8.476063e+07</td>\n",
       "      <td>8.769451e+07</td>\n",
       "      <td>5.013289e+06</td>\n",
       "      <td>18631.467155</td>\n",
       "      <td>136178.120683</td>\n",
       "      <td>943.577316</td>\n",
       "      <td>29636.583246</td>\n",
       "      <td>30662.417509</td>\n",
       "      <td>1752.898361</td>\n",
       "      <td>19987.724321</td>\n",
       "      <td>41474.251736</td>\n",
       "      <td>1859.532540</td>\n",
       "      <td>18623.947548</td>\n",
       "      <td>39404.426535</td>\n",
       "      <td>419.124607</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263300.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.609486e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.735283e-07</td>\n",
       "      <td>6.836308e-08</td>\n",
       "      <td>3.646031e-07</td>\n",
       "      <td>7.595898e-08</td>\n",
       "      <td>3.797949e-08</td>\n",
       "      <td>1.139385e-07</td>\n",
       "      <td>3.152298e-07</td>\n",
       "      <td>2.658564e-07</td>\n",
       "      <td>76100</td>\n",
       "      <td>0.289024</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>813.665590</td>\n",
       "      <td>1.141244</td>\n",
       "      <td>-0.585319</td>\n",
       "      <td>12.929362</td>\n",
       "      <td>5.491992</td>\n",
       "      <td>1.965759</td>\n",
       "      <td>4.635198</td>\n",
       "      <td>4.976575</td>\n",
       "      <td>6.157715</td>\n",
       "      <td>5.814332</td>\n",
       "      <td>4.916671</td>\n",
       "      <td>5.827915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4980</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512318</th>\n",
       "      <td>3060</td>\n",
       "      <td>208248.303329</td>\n",
       "      <td>439.574555</td>\n",
       "      <td>4.152793</td>\n",
       "      <td>53.516385</td>\n",
       "      <td>1.191883</td>\n",
       "      <td>17.997605</td>\n",
       "      <td>22.405678</td>\n",
       "      <td>0.736660</td>\n",
       "      <td>28.701842</td>\n",
       "      <td>25.883701</td>\n",
       "      <td>15.004221</td>\n",
       "      <td>7548.831043</td>\n",
       "      <td>246.178558</td>\n",
       "      <td>5.610260</td>\n",
       "      <td>21.662747</td>\n",
       "      <td>1.267843</td>\n",
       "      <td>8.394836</td>\n",
       "      <td>20.068151</td>\n",
       "      <td>0.219879</td>\n",
       "      <td>5.081189</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.990635</td>\n",
       "      <td>2.659664e+07</td>\n",
       "      <td>3.426617e+08</td>\n",
       "      <td>7.449856e+06</td>\n",
       "      <td>1.149322e+08</td>\n",
       "      <td>1.408978e+08</td>\n",
       "      <td>4.706967e+06</td>\n",
       "      <td>8691.713694</td>\n",
       "      <td>111980.943607</td>\n",
       "      <td>2434.593391</td>\n",
       "      <td>37559.535747</td>\n",
       "      <td>46045.018769</td>\n",
       "      <td>1538.224385</td>\n",
       "      <td>11749.972138</td>\n",
       "      <td>45978.755732</td>\n",
       "      <td>2509.652248</td>\n",
       "      <td>17805.931661</td>\n",
       "      <td>40458.211385</td>\n",
       "      <td>468.885956</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267200.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1.619442e+09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.047904e-06</td>\n",
       "      <td>7.110778e-08</td>\n",
       "      <td>3.705090e-07</td>\n",
       "      <td>7.485030e-08</td>\n",
       "      <td>3.742515e-08</td>\n",
       "      <td>7.485030e-08</td>\n",
       "      <td>3.031437e-07</td>\n",
       "      <td>2.245509e-07</td>\n",
       "      <td>73600</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>853.589454</td>\n",
       "      <td>1.487194</td>\n",
       "      <td>-0.570159</td>\n",
       "      <td>-3.360159</td>\n",
       "      <td>7.136364</td>\n",
       "      <td>3.007238</td>\n",
       "      <td>4.801440</td>\n",
       "      <td>5.021038</td>\n",
       "      <td>6.548068</td>\n",
       "      <td>4.302829</td>\n",
       "      <td>5.579718</td>\n",
       "      <td>5.512657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3700</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512319</th>\n",
       "      <td>3803</td>\n",
       "      <td>206951.068996</td>\n",
       "      <td>336.801224</td>\n",
       "      <td>8.228796</td>\n",
       "      <td>62.478096</td>\n",
       "      <td>0.696861</td>\n",
       "      <td>12.629975</td>\n",
       "      <td>15.130581</td>\n",
       "      <td>0.831568</td>\n",
       "      <td>28.272125</td>\n",
       "      <td>26.229685</td>\n",
       "      <td>14.582193</td>\n",
       "      <td>6563.914573</td>\n",
       "      <td>264.291825</td>\n",
       "      <td>6.208800</td>\n",
       "      <td>22.759382</td>\n",
       "      <td>1.188099</td>\n",
       "      <td>7.192062</td>\n",
       "      <td>22.684423</td>\n",
       "      <td>0.232025</td>\n",
       "      <td>4.975858</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>0.983222</td>\n",
       "      <td>6.564858e+07</td>\n",
       "      <td>4.959340e+08</td>\n",
       "      <td>5.250390e+06</td>\n",
       "      <td>9.879792e+07</td>\n",
       "      <td>1.147826e+08</td>\n",
       "      <td>6.588681e+06</td>\n",
       "      <td>17262.314047</td>\n",
       "      <td>130405.990406</td>\n",
       "      <td>1380.591525</td>\n",
       "      <td>25978.942183</td>\n",
       "      <td>30182.131880</td>\n",
       "      <td>1732.495661</td>\n",
       "      <td>13041.372039</td>\n",
       "      <td>48829.070068</td>\n",
       "      <td>2297.477335</td>\n",
       "      <td>14707.273186</td>\n",
       "      <td>44622.023951</td>\n",
       "      <td>508.801136</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266800.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.619447e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.124438e-06</td>\n",
       "      <td>6.371814e-08</td>\n",
       "      <td>3.898051e-07</td>\n",
       "      <td>7.496252e-08</td>\n",
       "      <td>3.748126e-08</td>\n",
       "      <td>7.496252e-08</td>\n",
       "      <td>2.961019e-07</td>\n",
       "      <td>3.035982e-07</td>\n",
       "      <td>76600</td>\n",
       "      <td>0.287106</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>851.745487</td>\n",
       "      <td>1.286227</td>\n",
       "      <td>-0.833243</td>\n",
       "      <td>-0.390571</td>\n",
       "      <td>7.876576</td>\n",
       "      <td>5.187843</td>\n",
       "      <td>4.629604</td>\n",
       "      <td>5.283978</td>\n",
       "      <td>6.331582</td>\n",
       "      <td>4.512397</td>\n",
       "      <td>5.647919</td>\n",
       "      <td>5.563581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3710</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.013906</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512320</th>\n",
       "      <td>3281</td>\n",
       "      <td>204139.850108</td>\n",
       "      <td>390.420212</td>\n",
       "      <td>6.857118</td>\n",
       "      <td>56.626062</td>\n",
       "      <td>1.016596</td>\n",
       "      <td>13.776500</td>\n",
       "      <td>20.953071</td>\n",
       "      <td>0.772488</td>\n",
       "      <td>28.442658</td>\n",
       "      <td>26.432436</td>\n",
       "      <td>14.911266</td>\n",
       "      <td>7688.084786</td>\n",
       "      <td>242.283799</td>\n",
       "      <td>6.598437</td>\n",
       "      <td>24.151341</td>\n",
       "      <td>1.608945</td>\n",
       "      <td>7.782328</td>\n",
       "      <td>23.908767</td>\n",
       "      <td>0.236470</td>\n",
       "      <td>4.749328</td>\n",
       "      <td>0.141237</td>\n",
       "      <td>0.655360</td>\n",
       "      <td>4.690546e+07</td>\n",
       "      <td>3.839843e+08</td>\n",
       "      <td>6.466457e+06</td>\n",
       "      <td>9.173897e+07</td>\n",
       "      <td>1.354799e+08</td>\n",
       "      <td>5.219883e+06</td>\n",
       "      <td>14296.086335</td>\n",
       "      <td>117032.712352</td>\n",
       "      <td>1970.879806</td>\n",
       "      <td>27960.673621</td>\n",
       "      <td>41292.265092</td>\n",
       "      <td>1590.942698</td>\n",
       "      <td>13772.352381</td>\n",
       "      <td>51525.321369</td>\n",
       "      <td>2992.428589</td>\n",
       "      <td>15803.015948</td>\n",
       "      <td>46076.419562</td>\n",
       "      <td>519.163936</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276100.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1.619448e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.122782e-06</td>\n",
       "      <td>9.054690e-08</td>\n",
       "      <td>4.165158e-07</td>\n",
       "      <td>1.086563e-07</td>\n",
       "      <td>3.621876e-08</td>\n",
       "      <td>1.086563e-07</td>\n",
       "      <td>3.114813e-07</td>\n",
       "      <td>2.390438e-07</td>\n",
       "      <td>64200</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>836.458333</td>\n",
       "      <td>1.445606</td>\n",
       "      <td>-0.553893</td>\n",
       "      <td>-3.405646</td>\n",
       "      <td>7.067086</td>\n",
       "      <td>2.816972</td>\n",
       "      <td>4.777777</td>\n",
       "      <td>5.021437</td>\n",
       "      <td>6.564477</td>\n",
       "      <td>4.311214</td>\n",
       "      <td>5.549003</td>\n",
       "      <td>5.480371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4570</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512321</th>\n",
       "      <td>3620</td>\n",
       "      <td>203045.139149</td>\n",
       "      <td>385.978217</td>\n",
       "      <td>6.075653</td>\n",
       "      <td>54.750024</td>\n",
       "      <td>0.971723</td>\n",
       "      <td>14.838620</td>\n",
       "      <td>22.604694</td>\n",
       "      <td>0.743987</td>\n",
       "      <td>27.847579</td>\n",
       "      <td>27.110961</td>\n",
       "      <td>15.110062</td>\n",
       "      <td>5914.722753</td>\n",
       "      <td>255.687099</td>\n",
       "      <td>6.902912</td>\n",
       "      <td>21.863376</td>\n",
       "      <td>1.252370</td>\n",
       "      <td>8.081957</td>\n",
       "      <td>20.558332</td>\n",
       "      <td>0.208407</td>\n",
       "      <td>4.733242</td>\n",
       "      <td>0.493382</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>4.532896e+07</td>\n",
       "      <td>4.047396e+08</td>\n",
       "      <td>6.971648e+06</td>\n",
       "      <td>1.083322e+08</td>\n",
       "      <td>1.640471e+08</td>\n",
       "      <td>5.490289e+06</td>\n",
       "      <td>12521.812758</td>\n",
       "      <td>111806.518678</td>\n",
       "      <td>1925.869725</td>\n",
       "      <td>29926.025952</td>\n",
       "      <td>45316.891016</td>\n",
       "      <td>1516.654440</td>\n",
       "      <td>14269.994093</td>\n",
       "      <td>45872.532849</td>\n",
       "      <td>2389.602262</td>\n",
       "      <td>16162.428239</td>\n",
       "      <td>40923.238233</td>\n",
       "      <td>444.977376</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275800.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1.619452e+09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.789703e-07</td>\n",
       "      <td>7.614213e-08</td>\n",
       "      <td>3.625816e-07</td>\n",
       "      <td>7.251632e-08</td>\n",
       "      <td>3.625816e-08</td>\n",
       "      <td>1.087745e-07</td>\n",
       "      <td>2.755620e-07</td>\n",
       "      <td>2.175489e-07</td>\n",
       "      <td>66200</td>\n",
       "      <td>0.240029</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>808.969178</td>\n",
       "      <td>1.533904</td>\n",
       "      <td>-1.131414</td>\n",
       "      <td>7.823157</td>\n",
       "      <td>8.000347</td>\n",
       "      <td>7.026843</td>\n",
       "      <td>4.192688</td>\n",
       "      <td>5.539564</td>\n",
       "      <td>5.876938</td>\n",
       "      <td>5.048804</td>\n",
       "      <td>5.455830</td>\n",
       "      <td>5.727036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3080</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512322</th>\n",
       "      <td>4782</td>\n",
       "      <td>205058.940555</td>\n",
       "      <td>306.711093</td>\n",
       "      <td>8.985557</td>\n",
       "      <td>63.371647</td>\n",
       "      <td>0.829136</td>\n",
       "      <td>12.778305</td>\n",
       "      <td>13.199406</td>\n",
       "      <td>0.836728</td>\n",
       "      <td>27.065385</td>\n",
       "      <td>27.000937</td>\n",
       "      <td>15.426140</td>\n",
       "      <td>7144.194096</td>\n",
       "      <td>263.504412</td>\n",
       "      <td>7.927912</td>\n",
       "      <td>19.850390</td>\n",
       "      <td>1.427636</td>\n",
       "      <td>10.856853</td>\n",
       "      <td>17.863520</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>4.849513</td>\n",
       "      <td>0.269763</td>\n",
       "      <td>0.662683</td>\n",
       "      <td>8.948705e+07</td>\n",
       "      <td>6.261807e+08</td>\n",
       "      <td>7.780972e+06</td>\n",
       "      <td>1.238589e+08</td>\n",
       "      <td>1.250412e+08</td>\n",
       "      <td>8.250020e+06</td>\n",
       "      <td>18713.310443</td>\n",
       "      <td>130945.356023</td>\n",
       "      <td>1627.137554</td>\n",
       "      <td>25901.056153</td>\n",
       "      <td>26148.303159</td>\n",
       "      <td>1725.223733</td>\n",
       "      <td>16510.288213</td>\n",
       "      <td>42906.725770</td>\n",
       "      <td>2721.719599</td>\n",
       "      <td>21992.302973</td>\n",
       "      <td>34726.324968</td>\n",
       "      <td>429.848595</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279200.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.619457e+09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.110315e-06</td>\n",
       "      <td>6.805158e-08</td>\n",
       "      <td>3.760745e-07</td>\n",
       "      <td>7.163324e-08</td>\n",
       "      <td>3.581662e-08</td>\n",
       "      <td>1.074499e-07</td>\n",
       "      <td>2.757880e-07</td>\n",
       "      <td>2.399713e-07</td>\n",
       "      <td>76100</td>\n",
       "      <td>0.272564</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>766.718704</td>\n",
       "      <td>1.738373</td>\n",
       "      <td>-0.493701</td>\n",
       "      <td>13.762460</td>\n",
       "      <td>4.228726</td>\n",
       "      <td>-1.164349</td>\n",
       "      <td>5.105068</td>\n",
       "      <td>4.727051</td>\n",
       "      <td>6.257432</td>\n",
       "      <td>5.783409</td>\n",
       "      <td>4.816247</td>\n",
       "      <td>6.046026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>4842.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4820</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gas_duration     gas_mean_V  gas_mean_T  gas_mean_O2  gas_mean_N2  \\\n",
       "NPLV                                                                        \n",
       "510008          2560  216789.292999  506.912198     8.080398    60.971011   \n",
       "510009          3949  217054.421867  375.840941    10.985339    64.784377   \n",
       "510010          2871  215606.942311  489.881937     8.745518    62.633599   \n",
       "510011          3261  218908.844905  439.273874     9.016227    62.605303   \n",
       "510012          2860  217981.805452  478.608197     8.470485    62.286450   \n",
       "...              ...            ...         ...          ...          ...   \n",
       "512318          3060  208248.303329  439.574555     4.152793    53.516385   \n",
       "512319          3803  206951.068996  336.801224     8.228796    62.478096   \n",
       "512320          3281  204139.850108  390.420212     6.857118    56.626062   \n",
       "512321          3620  203045.139149  385.978217     6.075653    54.750024   \n",
       "512322          4782  205058.940555  306.711093     8.985557    63.371647   \n",
       "\n",
       "        gas_mean_H2  gas_mean_CO2  gas_mean_CO  gas_mean_AR  \\\n",
       "NPLV                                                          \n",
       "510008     0.300348     13.646908    16.236455     0.801776   \n",
       "510009     0.163313     11.761720    11.466482     0.838266   \n",
       "510010     0.312984     12.723079    14.755786     0.828832   \n",
       "510011     0.100366     13.566362    13.771099     0.835434   \n",
       "510012     0.442823     13.643787    14.273926     0.802074   \n",
       "...             ...           ...          ...          ...   \n",
       "512318     1.191883     17.997605    22.405678     0.736660   \n",
       "512319     0.696861     12.629975    15.130581     0.831568   \n",
       "512320     1.016596     13.776500    20.953071     0.772488   \n",
       "512321     0.971723     14.838620    22.604694     0.743987   \n",
       "512322     0.829136     12.778305    13.199406     0.836728   \n",
       "\n",
       "        gas_mean_T фурмы 1  gas_mean_T фурмы 2  gas_mean_O2_pressure  \\\n",
       "NPLV                                                                   \n",
       "510008            0.000000            0.000000             13.356058   \n",
       "510009            0.000000            0.000000             13.950163   \n",
       "510010            0.000000            0.000000             14.022366   \n",
       "510011            0.000000            0.000000             14.250926   \n",
       "510012            0.000000            0.000000             14.259779   \n",
       "...                    ...                 ...                   ...   \n",
       "512318           28.701842           25.883701             15.004221   \n",
       "512319           28.272125           26.229685             14.582193   \n",
       "512320           28.442658           26.432436             14.911266   \n",
       "512321           27.847579           27.110961             15.110062   \n",
       "512322           27.065385           27.000937             15.426140   \n",
       "\n",
       "          gas_std_V   gas_std_T  gas_std_O2  gas_std_N2  gas_std_H2  \\\n",
       "NPLV                                                                  \n",
       "510008  5369.811888  273.329244    8.601033   19.843291    0.798206   \n",
       "510009  4250.571350  291.238099   10.616286   16.819827    0.538952   \n",
       "510010  6659.001169  301.143710    9.489587   19.181862    0.797407   \n",
       "510011  5341.347771  267.257197    8.395936   17.444834    0.215926   \n",
       "510012  5757.933597  282.254884    9.054424   18.477454    0.878580   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "512318  7548.831043  246.178558    5.610260   21.662747    1.267843   \n",
       "512319  6563.914573  264.291825    6.208800   22.759382    1.188099   \n",
       "512320  7688.084786  242.283799    6.598437   24.151341    1.608945   \n",
       "512321  5914.722753  255.687099    6.902912   21.863376    1.252370   \n",
       "512322  7144.194096  263.504412    7.927912   19.850390    1.427636   \n",
       "\n",
       "        gas_std_CO2  gas_std_CO  gas_std_AR  gas_std_T фурмы 1  \\\n",
       "NPLV                                                             \n",
       "510008     7.340789   20.627802    0.189599           0.000000   \n",
       "510009     8.095644   18.080320    0.167612           0.000000   \n",
       "510010     8.108025   19.036043    0.167892           0.000000   \n",
       "510011     7.790133   18.094440    0.194226           0.000000   \n",
       "510012     8.633744   18.366216    0.182802           0.000000   \n",
       "...             ...         ...         ...                ...   \n",
       "512318     8.394836   20.068151    0.219879           5.081189   \n",
       "512319     7.192062   22.684423    0.232025           4.975858   \n",
       "512320     7.782328   23.908767    0.236470           4.749328   \n",
       "512321     8.081957   20.558332    0.208407           4.733242   \n",
       "512322    10.856853   17.863520    0.193100           4.849513   \n",
       "\n",
       "        gas_std_T фурмы 2  gas_std_O2_pressure  gas_sum_volume_O2  \\\n",
       "NPLV                                                                \n",
       "510008           0.000000             0.292023       4.502321e+07   \n",
       "510009           0.000000             1.003299       9.485353e+07   \n",
       "510010           0.000000             0.330850       5.488448e+07   \n",
       "510011           0.000000             0.665478       6.478924e+07   \n",
       "510012           0.000000             0.652421       5.328600e+07   \n",
       "...                   ...                  ...                ...   \n",
       "512318           0.080459             0.990635       2.659664e+07   \n",
       "512319           0.087734             0.983222       6.564858e+07   \n",
       "512320           0.141237             0.655360       4.690546e+07   \n",
       "512321           0.493382             0.854355       4.532896e+07   \n",
       "512322           0.269763             0.662683       8.948705e+07   \n",
       "\n",
       "        gas_sum_volume_N2  gas_sum_volume_H2  gas_sum_volume_CO2  \\\n",
       "NPLV                                                               \n",
       "510008       3.391881e+08       1.624003e+06        7.575220e+07   \n",
       "510009       5.562788e+08       1.364358e+06        1.004032e+08   \n",
       "510010       3.886485e+08       1.874444e+06        7.840161e+07   \n",
       "510011       4.477267e+08       7.091111e+05        9.674182e+07   \n",
       "510012       3.894694e+08       2.698631e+06        8.476063e+07   \n",
       "...                   ...                ...                 ...   \n",
       "512318       3.426617e+08       7.449856e+06        1.149322e+08   \n",
       "512319       4.959340e+08       5.250390e+06        9.879792e+07   \n",
       "512320       3.839843e+08       6.466457e+06        9.173897e+07   \n",
       "512321       4.047396e+08       6.971648e+06        1.083322e+08   \n",
       "512322       6.261807e+08       7.780972e+06        1.238589e+08   \n",
       "\n",
       "        gas_sum_volume_CO  gas_sum_volume_AR  gas_mean_volume_O2  \\\n",
       "NPLV                                                               \n",
       "510008       8.913852e+07       4.458630e+06        17587.192761   \n",
       "510009       9.705018e+07       7.193678e+06        24019.631951   \n",
       "510010       9.005883e+07       5.138755e+06        19116.849917   \n",
       "510011       9.717645e+07       5.974200e+06        19867.905305   \n",
       "510012       8.769451e+07       5.013289e+06        18631.467155   \n",
       "...                   ...                ...                 ...   \n",
       "512318       1.408978e+08       4.706967e+06         8691.713694   \n",
       "512319       1.147826e+08       6.588681e+06        17262.314047   \n",
       "512320       1.354799e+08       5.219883e+06        14296.086335   \n",
       "512321       1.640471e+08       5.490289e+06        12521.812758   \n",
       "512322       1.250412e+08       8.250020e+06        18713.310443   \n",
       "\n",
       "        gas_mean_volume_N2  gas_mean_volume_H2  gas_mean_volume_CO2  \\\n",
       "NPLV                                                                  \n",
       "510008       132495.366168          634.376020         29590.704477   \n",
       "510009       140865.726324          345.494449         25424.967838   \n",
       "510010       135370.437027          652.889050         27308.119240   \n",
       "510011       137297.364374          217.452049         29666.305531   \n",
       "510012       136178.120683          943.577316         29636.583246   \n",
       "...                    ...                 ...                  ...   \n",
       "512318       111980.943607         2434.593391         37559.535747   \n",
       "512319       130405.990406         1380.591525         25978.942183   \n",
       "512320       117032.712352         1970.879806         27960.673621   \n",
       "512321       111806.518678         1925.869725         29926.025952   \n",
       "512322       130945.356023         1627.137554         25901.056153   \n",
       "\n",
       "        gas_mean_volume_CO  gas_mean_volume_AR  gas_std_volume_O2  \\\n",
       "NPLV                                                                \n",
       "510008        34819.734247         1741.652526       18701.426346   \n",
       "510009        24575.886359         1821.645526       23278.991109   \n",
       "510010        31368.453349         1789.883300       20947.742464   \n",
       "510011        29799.586702         1832.014654       18607.672797   \n",
       "510012        30662.417509         1752.898361       19987.724321   \n",
       "...                    ...                 ...                ...   \n",
       "512318        46045.018769         1538.224385       11749.972138   \n",
       "512319        30182.131880         1732.495661       13041.372039   \n",
       "512320        41292.265092         1590.942698       13772.352381   \n",
       "512321        45316.891016         1516.654440       14269.994093   \n",
       "512322        26148.303159         1725.223733       16510.288213   \n",
       "\n",
       "        gas_std_volume_N2  gas_std_volume_H2  gas_std_volume_CO2  \\\n",
       "NPLV                                                               \n",
       "510008       43818.901201        1655.726824        15946.086198   \n",
       "510009       37231.830524        1123.023713        17501.298735   \n",
       "510010       42260.955051        1623.914332        17333.228492   \n",
       "510011       38883.156660         468.388798        17089.798747   \n",
       "510012       41474.251736        1859.532540        18623.947548   \n",
       "...                   ...                ...                 ...   \n",
       "512318       45978.755732        2509.652248        17805.931661   \n",
       "512319       48829.070068        2297.477335        14707.273186   \n",
       "512320       51525.321369        2992.428589        15803.015948   \n",
       "512321       45872.532849        2389.602262        16162.428239   \n",
       "512322       42906.725770        2721.719599        21992.302973   \n",
       "\n",
       "        gas_std_volume_CO  gas_std_volume_AR  dayofmonth  hour  duration  \\\n",
       "NPLV                                                                       \n",
       "510008       44086.505490         425.909341           1     3    2579.0   \n",
       "510009       38641.706115         373.312144           1     4    4004.0   \n",
       "510010       40336.007001         376.987465           1     5    2904.0   \n",
       "510011       39012.937295         437.916480           1     6    3291.0   \n",
       "510012       39404.426535         419.124607           1     7    2895.0   \n",
       "...                   ...                ...         ...   ...       ...   \n",
       "512318       40458.211385         468.885956          26    13    3084.0   \n",
       "512319       44622.023951         508.801136          26    14    3843.0   \n",
       "512320       46076.419562         519.163936          26    15    3305.0   \n",
       "512321       40923.238233         444.977376          26    16    3660.0   \n",
       "512322       34726.324968         429.848595          26    17    4840.0   \n",
       "\n",
       "        truncated_NMZ  st_diff_is_zero  dayofweek  plavka_TIPE_GOL  \\\n",
       "NPLV                                                                 \n",
       "510008           17.0                1          4                0   \n",
       "510009           17.0                1          4                0   \n",
       "510010           21.0                1          4                0   \n",
       "510011           16.0                1          4                0   \n",
       "510012           14.0                1          4                0   \n",
       "...               ...              ...        ...              ...   \n",
       "512318            7.0                0          0                0   \n",
       "512319            7.0                0          0                0   \n",
       "512320           16.0                0          0                0   \n",
       "512321           16.0                0          0                0   \n",
       "512322           16.0                0          0                0   \n",
       "\n",
       "        plavka_TIPE_FUR  plavka_NAPR_ZAD  bow_.z0  bow_/Э   bow_/ЭТ  bow_3пс  \\\n",
       "NPLV                                                                           \n",
       "510008              1.0              1.0        0        0        0        0   \n",
       "510009              1.0              1.0        0        0        0        0   \n",
       "510010              1.0              0.0        0        1        0        1   \n",
       "510011              1.0              0.0        1        0        0        0   \n",
       "510012              1.0              2.0        0        0        1        0   \n",
       "...                 ...              ...      ...      ...      ...      ...   \n",
       "512318              0.0              2.0        1        0        1        0   \n",
       "512319              0.0              2.0        1        0        1        0   \n",
       "512320              0.0              1.0        0        0        0        0   \n",
       "512321              0.0              1.0        0        0        0        0   \n",
       "512322              0.0              1.0        0        0        0        0   \n",
       "\n",
       "        bow_SC2  bow_Ст3  bow_ЭТ   bow_пс/  bow_с/Э  bow_т3п       VES  \\\n",
       "NPLV                                                                     \n",
       "510008        0        0        0        0        0        0  263700.0   \n",
       "510009        0        0        0        0        0        0  264500.0   \n",
       "510010        0        1        0        1        1        1  263800.0   \n",
       "510011        0        0        0        0        0        0  264000.0   \n",
       "510012        1        0        1        0        0        0  263300.0   \n",
       "...         ...      ...      ...      ...      ...      ...       ...   \n",
       "512318        0        0        1        0        0        0  267200.0   \n",
       "512319        0        0        1        0        0        0  266800.0   \n",
       "512320        0        0        0        0        0        0  276100.0   \n",
       "512321        0        0        0        0        0        0  275800.0   \n",
       "512322        0        0        0        0        0        0  279200.0   \n",
       "\n",
       "             T    SI    MN      S      P    CR    NI    CU      V     TI  \\\n",
       "NPLV                                                                       \n",
       "510008  1396.0  0.44  0.22  0.023  0.097  0.03  0.01  0.03  0.103  0.084   \n",
       "510009  1419.0  0.68  0.20  0.017  0.087  0.02  0.01  0.03  0.084  0.096   \n",
       "510010  1384.0  0.56  0.26  0.017  0.096  0.03  0.01  0.03  0.115  0.110   \n",
       "510011  1401.0  0.48  0.27  0.018  0.091  0.03  0.01  0.02  0.112  0.110   \n",
       "510012  1422.0  0.47  0.23  0.018  0.096  0.02  0.01  0.03  0.083  0.070   \n",
       "...        ...   ...   ...    ...    ...   ...   ...   ...    ...    ...   \n",
       "512318  1415.0  0.38  0.28  0.019  0.099  0.02  0.01  0.02  0.081  0.060   \n",
       "512319  1405.0  0.50  0.30  0.017  0.104  0.02  0.01  0.02  0.079  0.081   \n",
       "512320  1398.0  0.61  0.31  0.025  0.115  0.03  0.01  0.03  0.086  0.066   \n",
       "512321  1408.0  0.38  0.27  0.021  0.100  0.02  0.01  0.03  0.076  0.060   \n",
       "512322  1413.0  0.50  0.31  0.019  0.105  0.02  0.01  0.03  0.077  0.067   \n",
       "\n",
       "        total_seconds  si_portion    mn_portion     s_portion     p_portion  \\\n",
       "NPLV                                                                          \n",
       "510008   1.609471e+09    0.000002  8.342814e-07  8.722033e-08  3.678422e-07   \n",
       "510009   1.609475e+09    0.000003  7.561437e-07  6.427221e-08  3.289225e-07   \n",
       "510010   1.609478e+09    0.000002  9.855951e-07  6.444276e-08  3.639121e-07   \n",
       "510011   1.609482e+09    0.000002  1.022727e-06  6.818182e-08  3.446970e-07   \n",
       "510012   1.609486e+09    0.000002  8.735283e-07  6.836308e-08  3.646031e-07   \n",
       "...               ...         ...           ...           ...           ...   \n",
       "512318   1.619442e+09    0.000001  1.047904e-06  7.110778e-08  3.705090e-07   \n",
       "512319   1.619447e+09    0.000002  1.124438e-06  6.371814e-08  3.898051e-07   \n",
       "512320   1.619448e+09    0.000002  1.122782e-06  9.054690e-08  4.165158e-07   \n",
       "512321   1.619452e+09    0.000001  9.789703e-07  7.614213e-08  3.625816e-07   \n",
       "512322   1.619457e+09    0.000002  1.110315e-06  6.805158e-08  3.760745e-07   \n",
       "\n",
       "          cr_portion    ni_portion    cu_portion     v_portion    ti_portion  \\\n",
       "NPLV                                                                           \n",
       "510008  1.137656e-07  3.792188e-08  1.137656e-07  3.905954e-07  3.185438e-07   \n",
       "510009  7.561437e-08  3.780718e-08  1.134216e-07  3.175803e-07  3.629490e-07   \n",
       "510010  1.137225e-07  3.790751e-08  1.137225e-07  4.359363e-07  4.169826e-07   \n",
       "510011  1.136364e-07  3.787879e-08  7.575758e-08  4.242424e-07  4.166667e-07   \n",
       "510012  7.595898e-08  3.797949e-08  1.139385e-07  3.152298e-07  2.658564e-07   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "512318  7.485030e-08  3.742515e-08  7.485030e-08  3.031437e-07  2.245509e-07   \n",
       "512319  7.496252e-08  3.748126e-08  7.496252e-08  2.961019e-07  3.035982e-07   \n",
       "512320  1.086563e-07  3.621876e-08  1.086563e-07  3.114813e-07  2.390438e-07   \n",
       "512321  7.251632e-08  3.625816e-08  1.087745e-07  2.755620e-07  2.175489e-07   \n",
       "512322  7.163324e-08  3.581662e-08  1.074499e-07  2.757880e-07  2.399713e-07   \n",
       "\n",
       "        ves_loma  ves_loma/ves_chuguna  durationproduv_    RAS_mean  POL_mean  \\\n",
       "NPLV                                                                            \n",
       "510008     76200              0.288965           1168.0  833.024315  1.145962   \n",
       "510009     78600              0.297164           1226.0  832.179153  1.346743   \n",
       "510010     76300              0.289234           1222.0  821.524510  1.262255   \n",
       "510011     84100              0.318561           1056.0  805.565217  1.442741   \n",
       "510012     76100              0.289024           1236.0  813.665590  1.141244   \n",
       "...          ...                   ...              ...         ...       ...   \n",
       "512318     73600              0.275449           1060.0  853.589454  1.487194   \n",
       "512319     76600              0.287106           1106.0  851.745487  1.286227   \n",
       "512320     64200              0.232524           1054.0  836.458333  1.445606   \n",
       "512321     66200              0.240029           1166.0  808.969178  1.533904   \n",
       "512322     76100              0.272564           1356.0  766.718704  1.738373   \n",
       "\n",
       "               0          1         2         3         4         5         6  \\\n",
       "NPLV                                                                            \n",
       "510008 -1.156259   8.058909  7.624763  6.477648  4.481481  5.410652  6.022574   \n",
       "510009 -0.674527  12.779936  5.824023  2.713871  4.521441  5.085553  6.196332   \n",
       "510010 -0.704444  12.429848  5.910546  2.883735  4.516992  5.105981  6.147994   \n",
       "510011 -0.561065  -3.350970  7.085355  2.852356  4.773051  5.025595  6.558962   \n",
       "510012 -0.585319  12.929362  5.491992  1.965759  4.635198  4.976575  6.157715   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "512318 -0.570159  -3.360159  7.136364  3.007238  4.801440  5.021038  6.548068   \n",
       "512319 -0.833243  -0.390571  7.876576  5.187843  4.629604  5.283978  6.331582   \n",
       "512320 -0.553893  -3.405646  7.067086  2.816972  4.777777  5.021437  6.564477   \n",
       "512321 -1.131414   7.823157  8.000347  7.026843  4.192688  5.539564  5.876938   \n",
       "512322 -0.493701  13.762460  4.228726 -1.164349  5.105068  4.727051  6.257432   \n",
       "\n",
       "               7         8         9  O2_вн.пл.прост._0  O2_межпл.прост._0  \\\n",
       "NPLV                                                                         \n",
       "510008  5.195676  5.381444  5.631197                0.0                0.0   \n",
       "510009  5.750713  4.999381  5.749108                0.0                0.0   \n",
       "510010  5.715422  5.011985  5.797691                0.0                0.0   \n",
       "510011  4.313759  5.554585  5.484573                0.0                0.0   \n",
       "510012  5.814332  4.916671  5.827915                0.0                0.0   \n",
       "...          ...       ...       ...                ...                ...   \n",
       "512318  4.302829  5.579718  5.512657                0.0                0.0   \n",
       "512319  4.512397  5.647919  5.563581                0.0                0.0   \n",
       "512320  4.311214  5.549003  5.480371                0.0                0.0   \n",
       "512321  5.048804  5.455830  5.727036                0.0                0.0   \n",
       "512322  5.783409  4.816247  6.046026                0.0                0.0   \n",
       "\n",
       "        O2_межпл.прост._1  O2_опер_0  total_duration_вн.пл.прост._0  \\\n",
       "NPLV                                                                  \n",
       "510008                0.0     2909.0                          246.0   \n",
       "510009                0.0     2182.0                          922.0   \n",
       "510010                0.0     2841.0                            0.0   \n",
       "510011                0.0       10.0                            0.0   \n",
       "510012                0.0     3225.0                            0.0   \n",
       "...                   ...        ...                            ...   \n",
       "512318                0.0     1917.0                          932.0   \n",
       "512319                0.0     1660.0                         1314.0   \n",
       "512320                0.0        0.0                          438.0   \n",
       "512321                0.0      371.0                          566.0   \n",
       "512322                0.0      665.0                         2394.0   \n",
       "\n",
       "        total_duration_межпл.прост._0  total_duration_межпл.прост._1  \\\n",
       "NPLV                                                                   \n",
       "510008                            0.0                          840.0   \n",
       "510009                            0.0                         1140.0   \n",
       "510010                            0.0                          594.0   \n",
       "510011                            0.0                         1542.0   \n",
       "510012                            0.0                          601.0   \n",
       "...                               ...                            ...   \n",
       "512318                            0.0                          747.0   \n",
       "512319                            0.0                         1734.0   \n",
       "512320                            0.0                          859.0   \n",
       "512321                            0.0                          704.0   \n",
       "512322                            0.0                          520.0   \n",
       "\n",
       "        total_duration_опер_0  min_duration_вн.пл.прост._0  \\\n",
       "NPLV                                                         \n",
       "510008                 2489.0                        246.0   \n",
       "510009                 2987.0                        302.0   \n",
       "510010                 2796.0                          0.0   \n",
       "510011                 2966.0                          0.0   \n",
       "510012                 2836.0                          0.0   \n",
       "...                       ...                          ...   \n",
       "512318                 3064.0                        179.0   \n",
       "512319                 3783.0                       1314.0   \n",
       "512320                 3150.0                        438.0   \n",
       "512321                 3654.0                        104.0   \n",
       "512322                 4842.0                       2394.0   \n",
       "\n",
       "        min_duration_межпл.прост._0  min_duration_межпл.прост._1  \\\n",
       "NPLV                                                               \n",
       "510008                          0.0                         46.0   \n",
       "510009                          0.0                         54.0   \n",
       "510010                          0.0                         55.0   \n",
       "510011                          0.0                         42.0   \n",
       "510012                          0.0                         43.0   \n",
       "...                             ...                          ...   \n",
       "512318                          0.0                         94.0   \n",
       "512319                          0.0                         33.0   \n",
       "512320                          0.0                         62.0   \n",
       "512321                          0.0                         38.0   \n",
       "512322                          0.0                         18.0   \n",
       "\n",
       "        min_duration_опер_0  max_duration_вн.пл.прост._0  \\\n",
       "NPLV                                                       \n",
       "510008                 16.0                        246.0   \n",
       "510009                 31.0                        620.0   \n",
       "510010                133.0                          0.0   \n",
       "510011                 17.0                          0.0   \n",
       "510012                 54.0                          0.0   \n",
       "...                     ...                          ...   \n",
       "512318                  0.0                        753.0   \n",
       "512319                  0.0                       1314.0   \n",
       "512320                  0.0                        438.0   \n",
       "512321                  0.0                        462.0   \n",
       "512322                  0.0                       2394.0   \n",
       "\n",
       "        max_duration_межпл.прост._0  max_duration_межпл.прост._1  \\\n",
       "NPLV                                                               \n",
       "510008                          0.0                        424.0   \n",
       "510009                          0.0                        574.0   \n",
       "510010                          0.0                        301.0   \n",
       "510011                          0.0                        775.0   \n",
       "510012                          0.0                        305.0   \n",
       "...                             ...                          ...   \n",
       "512318                          0.0                        377.0   \n",
       "512319                          0.0                        870.0   \n",
       "512320                          0.0                        434.0   \n",
       "512321                          0.0                        355.0   \n",
       "512322                          0.0                        263.0   \n",
       "\n",
       "        max_duration_опер_0  total_operations_вн.пл.прост._0  \\\n",
       "NPLV                                                           \n",
       "510008               1170.0                              1.0   \n",
       "510009               1230.0                              2.0   \n",
       "510010               1226.0                              0.0   \n",
       "510011               1058.0                              0.0   \n",
       "510012               1239.0                              0.0   \n",
       "...                     ...                              ...   \n",
       "512318               1063.0                              2.0   \n",
       "512319               1415.0                              1.0   \n",
       "512320               1058.0                              1.0   \n",
       "512321               1169.0                              2.0   \n",
       "512322               2446.0                              1.0   \n",
       "\n",
       "        total_operations_межпл.прост._0  total_operations_межпл.прост._1  \\\n",
       "NPLV                                                                       \n",
       "510008                              0.0                              5.0   \n",
       "510009                              0.0                              6.0   \n",
       "510010                              0.0                              4.0   \n",
       "510011                              0.0                              4.0   \n",
       "510012                              0.0                              4.0   \n",
       "...                                 ...                              ...   \n",
       "512318                              0.0                              3.0   \n",
       "512319                              0.0                              5.0   \n",
       "512320                              0.0                              4.0   \n",
       "512321                              0.0                              4.0   \n",
       "512322                              0.0                              3.0   \n",
       "\n",
       "        total_operations_опер_0  min_mass  max_mass  total_count  \\\n",
       "NPLV                                                               \n",
       "510008                      6.0       220      7300           12   \n",
       "510009                      6.0        10      9950           15   \n",
       "510010                      6.0        10      5050           13   \n",
       "510011                      7.0       320      5020           13   \n",
       "510012                      9.0        40      4980           16   \n",
       "...                         ...       ...       ...          ...   \n",
       "512318                      9.0        30      3700           15   \n",
       "512319                      8.0        10      3710           15   \n",
       "512320                      8.0        20      4570           15   \n",
       "512321                      9.0        10      3080           11   \n",
       "512322                      8.0        10      4820           20   \n",
       "\n",
       "        unique_count  min_ratio  max_ratio  unique_ratio   TST  \n",
       "NPLV                                                            \n",
       "510008             4   0.000834   0.027683      0.333333  1690  \n",
       "510009             4   0.000038   0.037618      0.266667  1683  \n",
       "510010             5   0.000038   0.019143      0.384615  1662  \n",
       "510011             4   0.001212   0.019015      0.307692  1609  \n",
       "510012             5   0.000152   0.018914      0.312500  1682  \n",
       "...              ...        ...        ...           ...   ...  \n",
       "512318             2   0.000112   0.013847      0.133333  1626  \n",
       "512319             3   0.000037   0.013906      0.200000  1643  \n",
       "512320             3   0.000072   0.016552      0.200000  1615  \n",
       "512321             3   0.000036   0.011168      0.272727  1654  \n",
       "512322             2   0.000036   0.017264      0.100000  1630  \n",
       "\n",
       "[2061 rows x 124 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['TST'] = y['TST']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start automl preset with listed constraints:\n",
      "- time: 300 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (2061, 124)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 295.5632073879242 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -811.5131923890432\n",
      "Linear model: C = 5e-05 score = -678.5329326165357\n",
      "Linear model: C = 0.0001 score = -624.68812705746\n",
      "Linear model: C = 0.0005 score = -543.5094248820232\n",
      "Linear model: C = 0.001 score = -526.3673264692395\n",
      "Linear model: C = 0.005 score = -509.25276642377526\n",
      "Linear model: C = 0.01 score = -505.4698728695692\n",
      "Linear model: C = 0.05 score = -497.48121416608444\n",
      "Linear model: C = 0.1 score = -494.00208935159606\n",
      "Linear model: C = 0.5 score = -487.6751135452391\n",
      "Linear model: C = 1 score = -486.9911472813991\n",
      "Linear model: C = 5 score = -484.9870781386519\n",
      "Linear model: C = 10 score = -486.6887130297486\n",
      "Linear model: C = 50 score = -486.6835306641842\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -815.7782516534106\n",
      "Linear model: C = 5e-05 score = -690.1827650590646\n",
      "Linear model: C = 0.0001 score = -638.0570385516124\n",
      "Linear model: C = 0.0005 score = -554.2574005936751\n",
      "Linear model: C = 0.001 score = -536.7803233135672\n",
      "Linear model: C = 0.005 score = -536.2133688423602\n",
      "Linear model: C = 0.01 score = -575.1876242698613\n",
      "Linear model: C = 0.05 score = -1501.4769029233298\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -766.6718052218044\n",
      "Linear model: C = 5e-05 score = -647.8049252162715\n",
      "Linear model: C = 0.0001 score = -603.002257958597\n",
      "Linear model: C = 0.0005 score = -543.8636646349236\n",
      "Linear model: C = 0.001 score = -533.5543888614523\n",
      "Linear model: C = 0.005 score = -525.1910319413664\n",
      "Linear model: C = 0.01 score = -523.6606501861322\n",
      "Linear model: C = 0.05 score = -522.247232859466\n",
      "Linear model: C = 0.1 score = -523.8707202719977\n",
      "Linear model: C = 0.5 score = -531.8843656282475\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -919.1339058145446\n",
      "Linear model: C = 5e-05 score = -796.1111267964961\n",
      "Linear model: C = 0.0001 score = -741.6381345372466\n",
      "Linear model: C = 0.0005 score = -670.2655056106668\n",
      "Linear model: C = 0.001 score = -668.8731862944235\n",
      "Linear model: C = 0.005 score = -693.7760687193029\n",
      "Linear model: C = 0.01 score = -703.8775089137184\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -883.5270977547952\n",
      "Linear model: C = 5e-05 score = -732.6155285588601\n",
      "Linear model: C = 0.0001 score = -665.5072428736004\n",
      "Linear model: C = 0.0005 score = -556.5838740630057\n",
      "Linear model: C = 0.001 score = -533.4034493280557\n",
      "Linear model: C = 0.005 score = -514.61306668044\n",
      "Linear model: C = 0.01 score = -513.8410787909717\n",
      "Linear model: C = 0.05 score = -514.9818673354474\n",
      "Linear model: C = 0.1 score = -514.7289948824757\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 289.0885798931122\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 570.358\n",
      "[200]\tvalid's l2: 489.493\n",
      "[300]\tvalid's l2: 460.008\n",
      "[400]\tvalid's l2: 445.173\n",
      "[500]\tvalid's l2: 435.253\n",
      "[600]\tvalid's l2: 429.486\n",
      "[700]\tvalid's l2: 425.391\n",
      "[800]\tvalid's l2: 422.403\n",
      "[900]\tvalid's l2: 421.077\n",
      "[1000]\tvalid's l2: 420.192\n",
      "[1100]\tvalid's l2: 420.559\n",
      "[1200]\tvalid's l2: 419.396\n",
      "[1300]\tvalid's l2: 419.184\n",
      "[1400]\tvalid's l2: 419.737\n",
      "Early stopping, best iteration is:\n",
      "[1266]\tvalid's l2: 418.774\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 556.858\n",
      "[200]\tvalid's l2: 481.217\n",
      "[300]\tvalid's l2: 453.917\n",
      "[400]\tvalid's l2: 438.468\n",
      "[500]\tvalid's l2: 431.306\n",
      "[600]\tvalid's l2: 427.266\n",
      "[700]\tvalid's l2: 425.821\n",
      "[800]\tvalid's l2: 423.855\n",
      "[900]\tvalid's l2: 422.801\n",
      "[1000]\tvalid's l2: 422.395\n",
      "[1100]\tvalid's l2: 422.023\n",
      "[1200]\tvalid's l2: 421.467\n",
      "[1300]\tvalid's l2: 420.513\n",
      "[1400]\tvalid's l2: 420.633\n",
      "[1500]\tvalid's l2: 420.559\n",
      "Early stopping, best iteration is:\n",
      "[1312]\tvalid's l2: 420.434\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 582.64\n",
      "[200]\tvalid's l2: 506.195\n",
      "[300]\tvalid's l2: 475.984\n",
      "[400]\tvalid's l2: 460.696\n",
      "[500]\tvalid's l2: 454.347\n",
      "[600]\tvalid's l2: 451.754\n",
      "[700]\tvalid's l2: 449.953\n",
      "[800]\tvalid's l2: 449.913\n",
      "[900]\tvalid's l2: 449.691\n",
      "Early stopping, best iteration is:\n",
      "[746]\tvalid's l2: 449.138\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 548.472\n",
      "[200]\tvalid's l2: 476.229\n",
      "[300]\tvalid's l2: 451.73\n",
      "[400]\tvalid's l2: 441.187\n",
      "[500]\tvalid's l2: 437.17\n",
      "[600]\tvalid's l2: 435.111\n",
      "[700]\tvalid's l2: 432.895\n",
      "[800]\tvalid's l2: 432.615\n",
      "[900]\tvalid's l2: 432.494\n",
      "[1000]\tvalid's l2: 431.975\n",
      "[1100]\tvalid's l2: 432.397\n",
      "Early stopping, best iteration is:\n",
      "[952]\tvalid's l2: 431.585\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 700.274\n",
      "[200]\tvalid's l2: 629.302\n",
      "[300]\tvalid's l2: 599.529\n",
      "[400]\tvalid's l2: 582.344\n",
      "[500]\tvalid's l2: 574.492\n",
      "[600]\tvalid's l2: 572.691\n",
      "[700]\tvalid's l2: 568.899\n",
      "[800]\tvalid's l2: 568.068\n",
      "[900]\tvalid's l2: 567.449\n",
      "[1000]\tvalid's l2: 566.835\n",
      "[1100]\tvalid's l2: 565.336\n",
      "[1200]\tvalid's l2: 565.308\n",
      "[1300]\tvalid's l2: 565.569\n",
      "[1400]\tvalid's l2: 564.882\n",
      "[1500]\tvalid's l2: 565.453\n",
      "[1600]\tvalid's l2: 566.28\n",
      "Early stopping, best iteration is:\n",
      "[1433]\tvalid's l2: 564.738\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 605.223\n",
      "[200]\tvalid's l2: 507.743\n",
      "[300]\tvalid's l2: 469.805\n",
      "[400]\tvalid's l2: 452.227\n",
      "[500]\tvalid's l2: 444.377\n",
      "[600]\tvalid's l2: 438.278\n",
      "[700]\tvalid's l2: 436.636\n",
      "[800]\tvalid's l2: 434.798\n",
      "[900]\tvalid's l2: 433.649\n",
      "[1000]\tvalid's l2: 432.645\n",
      "[1100]\tvalid's l2: 433.174\n",
      "Early stopping, best iteration is:\n",
      "[982]\tvalid's l2: 432.407\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l2: 530.612\n",
      "[200]\tvalid's l2: 452.512\n",
      "[300]\tvalid's l2: 428.05\n",
      "[400]\tvalid's l2: 419.076\n",
      "[500]\tvalid's l2: 414.514\n",
      "[600]\tvalid's l2: 412.773\n",
      "[700]\tvalid's l2: 411.67\n",
      "[800]\tvalid's l2: 411.403\n",
      "[900]\tvalid's l2: 410.848\n",
      "[1000]\tvalid's l2: 411.003\n",
      "[1100]\tvalid's l2: 410.848\n",
      "[1200]\tvalid's l2: 411.007\n",
      "Early stopping, best iteration is:\n",
      "[1074]\tvalid's l2: 410.718\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 420.729\n",
      "[200]\tvalid's l2: 417.938\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid's l2: 416.006\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 467.05\n",
      "[200]\tvalid's l2: 466.588\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid's l2: 465.797\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 426.602\n",
      "[200]\tvalid's l2: 427.747\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid's l2: 425.641\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 593.288\n",
      "[200]\tvalid's l2: 592.652\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid's l2: 590.92\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 448.212\n",
      "[200]\tvalid's l2: 445.455\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid's l2: 444.604\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_2_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2981589\ttest: 29.8552516\tbest: 29.8552516 (0)\ttotal: 1.6ms\tremaining: 3.21s\n",
      "100:\tlearn: 19.9020520\ttest: 22.1215009\tbest: 22.1215009 (100)\ttotal: 134ms\tremaining: 2.52s\n",
      "200:\tlearn: 16.2033614\ttest: 21.3353889\tbest: 21.3132728 (192)\ttotal: 290ms\tremaining: 2.6s\n",
      "300:\tlearn: 13.4371156\ttest: 21.0896483\tbest: 21.0609932 (259)\ttotal: 415ms\tremaining: 2.34s\n",
      "400:\tlearn: 11.3475561\ttest: 21.0409473\tbest: 21.0008792 (343)\ttotal: 575ms\tremaining: 2.29s\n",
      "500:\tlearn: 9.7290766\ttest: 21.0225705\tbest: 20.9969477 (469)\ttotal: 705ms\tremaining: 2.11s\n",
      "600:\tlearn: 8.3331869\ttest: 20.9815867\tbest: 20.9815867 (600)\ttotal: 831ms\tremaining: 1.94s\n",
      "700:\tlearn: 7.1811388\ttest: 20.9491146\tbest: 20.9422492 (698)\ttotal: 956ms\tremaining: 1.77s\n",
      "800:\tlearn: 6.1967112\ttest: 20.9665392\tbest: 20.9418478 (712)\ttotal: 1.08s\tremaining: 1.61s\n",
      "900:\tlearn: 5.3720743\ttest: 20.9509756\tbest: 20.9418478 (712)\ttotal: 1.2s\tremaining: 1.46s\n",
      "1000:\tlearn: 4.6760249\ttest: 20.9546768\tbest: 20.9418478 (712)\ttotal: 1.32s\tremaining: 1.32s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.94184781\n",
      "bestIteration = 712\n",
      "\n",
      "Shrink model to first 713 iterations.\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3320650\ttest: 29.9197878\tbest: 29.9197878 (0)\ttotal: 1.4ms\tremaining: 2.8s\n",
      "100:\tlearn: 19.9225215\ttest: 22.7604567\tbest: 22.7604567 (100)\ttotal: 127ms\tremaining: 2.39s\n",
      "200:\tlearn: 16.3746653\ttest: 22.1065298\tbest: 22.0916482 (199)\ttotal: 247ms\tremaining: 2.21s\n",
      "300:\tlearn: 13.6496247\ttest: 21.8706104\tbest: 21.8652822 (298)\ttotal: 372ms\tremaining: 2.1s\n",
      "400:\tlearn: 11.5917709\ttest: 21.8075123\tbest: 21.8075123 (400)\ttotal: 496ms\tremaining: 1.98s\n",
      "500:\tlearn: 9.8847115\ttest: 21.8128009\tbest: 21.7993825 (403)\ttotal: 625ms\tremaining: 1.87s\n",
      "600:\tlearn: 8.5190097\ttest: 21.8349853\tbest: 21.7993825 (403)\ttotal: 747ms\tremaining: 1.74s\n",
      "700:\tlearn: 7.3714609\ttest: 21.7774873\tbest: 21.7724665 (685)\ttotal: 931ms\tremaining: 1.73s\n",
      "800:\tlearn: 6.4136605\ttest: 21.7872346\tbest: 21.7515676 (729)\ttotal: 1.31s\tremaining: 1.97s\n",
      "900:\tlearn: 5.5809150\ttest: 21.7625240\tbest: 21.7515676 (729)\ttotal: 1.49s\tremaining: 1.82s\n",
      "1000:\tlearn: 4.8490013\ttest: 21.7373569\tbest: 21.7363914 (960)\ttotal: 1.69s\tremaining: 1.69s\n",
      "1100:\tlearn: 4.2402852\ttest: 21.7428164\tbest: 21.7198205 (1017)\ttotal: 1.83s\tremaining: 1.49s\n",
      "1200:\tlearn: 3.7059141\ttest: 21.7405918\tbest: 21.7198205 (1017)\ttotal: 1.98s\tremaining: 1.31s\n",
      "1300:\tlearn: 3.2448574\ttest: 21.7270829\tbest: 21.7191678 (1280)\ttotal: 2.12s\tremaining: 1.14s\n",
      "1400:\tlearn: 2.8370011\ttest: 21.7287981\tbest: 21.7187534 (1308)\ttotal: 2.26s\tremaining: 967ms\n",
      "1500:\tlearn: 2.4972444\ttest: 21.7230357\tbest: 21.7187534 (1308)\ttotal: 2.38s\tremaining: 792ms\n",
      "1600:\tlearn: 2.1990864\ttest: 21.7284349\tbest: 21.7163070 (1511)\ttotal: 2.5s\tremaining: 624ms\n",
      "1700:\tlearn: 1.9337362\ttest: 21.7363243\tbest: 21.7163070 (1511)\ttotal: 2.64s\tremaining: 465ms\n",
      "1800:\tlearn: 1.6928520\ttest: 21.7469184\tbest: 21.7163070 (1511)\ttotal: 2.82s\tremaining: 311ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 21.71630703\n",
      "bestIteration = 1511\n",
      "\n",
      "Shrink model to first 1512 iterations.\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.5626213\ttest: 29.0912154\tbest: 29.0912154 (0)\ttotal: 2.52ms\tremaining: 5.04s\n",
      "100:\tlearn: 19.7611627\ttest: 22.1112230\tbest: 22.1112230 (100)\ttotal: 173ms\tremaining: 3.26s\n",
      "200:\tlearn: 16.1758167\ttest: 21.5615824\tbest: 21.5484118 (198)\ttotal: 344ms\tremaining: 3.08s\n",
      "300:\tlearn: 13.4120759\ttest: 21.2876512\tbest: 21.2571980 (272)\ttotal: 586ms\tremaining: 3.31s\n",
      "400:\tlearn: 11.3324258\ttest: 21.2793783\tbest: 21.2363730 (359)\ttotal: 714ms\tremaining: 2.85s\n",
      "500:\tlearn: 9.7029943\ttest: 21.2668903\tbest: 21.2363730 (359)\ttotal: 843ms\tremaining: 2.52s\n",
      "600:\tlearn: 8.3582620\ttest: 21.2531858\tbest: 21.2363730 (359)\ttotal: 966ms\tremaining: 2.25s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 21.23637303\n",
      "bestIteration = 359\n",
      "\n",
      "Shrink model to first 360 iterations.\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 29.9381564\ttest: 31.4106515\tbest: 31.4106515 (0)\ttotal: 1.71ms\tremaining: 3.42s\n",
      "100:\tlearn: 19.5050949\ttest: 25.3196171\tbest: 25.3196171 (100)\ttotal: 142ms\tremaining: 2.67s\n",
      "200:\tlearn: 15.9407546\ttest: 24.3756551\tbest: 24.3691448 (195)\ttotal: 393ms\tremaining: 3.52s\n",
      "300:\tlearn: 13.1703367\ttest: 23.9516136\tbest: 23.9516136 (300)\ttotal: 773ms\tremaining: 4.36s\n",
      "400:\tlearn: 11.1818029\ttest: 23.8710788\tbest: 23.8702206 (389)\ttotal: 1.21s\tremaining: 4.8s\n",
      "500:\tlearn: 9.5877968\ttest: 23.8197214\tbest: 23.8169062 (438)\ttotal: 1.74s\tremaining: 5.2s\n",
      "600:\tlearn: 8.2948078\ttest: 23.8016559\tbest: 23.8016559 (600)\ttotal: 1.97s\tremaining: 4.58s\n",
      "700:\tlearn: 7.1670840\ttest: 23.7951638\tbest: 23.7821041 (649)\ttotal: 2.15s\tremaining: 3.99s\n",
      "800:\tlearn: 6.2062916\ttest: 23.8368475\tbest: 23.7821041 (649)\ttotal: 2.33s\tremaining: 3.49s\n",
      "900:\tlearn: 5.3964751\ttest: 23.8484877\tbest: 23.7821041 (649)\ttotal: 2.46s\tremaining: 3.01s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 23.78210406\n",
      "bestIteration = 649\n",
      "\n",
      "Shrink model to first 650 iterations.\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.0226940\ttest: 31.1623985\tbest: 31.1623985 (0)\ttotal: 1.96ms\tremaining: 3.91s\n",
      "100:\tlearn: 19.6990756\ttest: 22.4493994\tbest: 22.4493994 (100)\ttotal: 479ms\tremaining: 9s\n",
      "200:\tlearn: 16.2582376\ttest: 21.4765652\tbest: 21.4765652 (200)\ttotal: 1.13s\tremaining: 10.1s\n",
      "300:\tlearn: 13.4612014\ttest: 21.0723565\tbest: 21.0723565 (300)\ttotal: 1.36s\tremaining: 7.68s\n",
      "400:\tlearn: 11.3645444\ttest: 20.9396598\tbest: 20.8808753 (373)\ttotal: 1.55s\tremaining: 6.19s\n",
      "500:\tlearn: 9.6971042\ttest: 20.8495969\tbest: 20.8446338 (498)\ttotal: 2.01s\tremaining: 6.02s\n",
      "600:\tlearn: 8.3715029\ttest: 20.8034478\tbest: 20.7737360 (572)\ttotal: 2.37s\tremaining: 5.51s\n",
      "700:\tlearn: 7.2174269\ttest: 20.8121796\tbest: 20.7717559 (617)\ttotal: 2.56s\tremaining: 4.74s\n",
      "800:\tlearn: 6.2438892\ttest: 20.7911588\tbest: 20.7717559 (617)\ttotal: 2.69s\tremaining: 4.02s\n",
      "900:\tlearn: 5.4020599\ttest: 20.8075336\tbest: 20.7717559 (617)\ttotal: 2.81s\tremaining: 3.42s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.77175588\n",
      "bestIteration = 617\n",
      "\n",
      "Shrink model to first 618 iterations.\n",
      "Lvl_0_Pipe_1_Mod_2_CatBoost fitting and predicting completed\n",
      "Optuna may run 155.2673909664154 secs\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3761559\ttest: 29.9396542\tbest: 29.9396542 (0)\ttotal: 1.15ms\tremaining: 2.31s\n",
      "100:\tlearn: 21.8159588\ttest: 22.2881725\tbest: 22.2881725 (100)\ttotal: 90.6ms\tremaining: 1.7s\n",
      "200:\tlearn: 19.2495939\ttest: 21.1621299\tbest: 21.1621299 (200)\ttotal: 190ms\tremaining: 1.7s\n",
      "300:\tlearn: 17.2323724\ttest: 20.7251862\tbest: 20.7204669 (299)\ttotal: 286ms\tremaining: 1.61s\n",
      "400:\tlearn: 15.7313586\ttest: 20.5446384\tbest: 20.5248538 (383)\ttotal: 378ms\tremaining: 1.51s\n",
      "500:\tlearn: 14.4624434\ttest: 20.4327663\tbest: 20.4224237 (489)\ttotal: 469ms\tremaining: 1.4s\n",
      "600:\tlearn: 13.3308481\ttest: 20.4343426\tbest: 20.4035169 (568)\ttotal: 561ms\tremaining: 1.3s\n",
      "700:\tlearn: 12.2799340\ttest: 20.4361956\tbest: 20.3973465 (615)\ttotal: 655ms\tremaining: 1.21s\n",
      "800:\tlearn: 11.4035969\ttest: 20.4556328\tbest: 20.3973465 (615)\ttotal: 748ms\tremaining: 1.12s\n",
      "900:\tlearn: 10.6085373\ttest: 20.4324914\tbest: 20.3973465 (615)\ttotal: 845ms\tremaining: 1.03s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.39734649\n",
      "bestIteration = 615\n",
      "\n",
      "Shrink model to first 616 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980296\ttest: 29.8551288\tbest: 29.8551288 (0)\ttotal: 1.5ms\tremaining: 3s\n",
      "100:\tlearn: 19.8959530\ttest: 22.1211352\tbest: 22.1211352 (100)\ttotal: 159ms\tremaining: 2.99s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200:\tlearn: 16.1995829\ttest: 21.3561561\tbest: 21.3264675 (192)\ttotal: 308ms\tremaining: 2.76s\n",
      "300:\tlearn: 13.4260606\ttest: 21.0762967\tbest: 21.0462985 (265)\ttotal: 459ms\tremaining: 2.59s\n",
      "400:\tlearn: 11.3162050\ttest: 21.0785132\tbest: 21.0223363 (334)\ttotal: 608ms\tremaining: 2.42s\n",
      "500:\tlearn: 9.7090949\ttest: 21.0116306\tbest: 21.0111706 (499)\ttotal: 732ms\tremaining: 2.19s\n",
      "600:\tlearn: 8.3246078\ttest: 20.9825269\tbest: 20.9804072 (598)\ttotal: 856ms\tremaining: 1.99s\n",
      "700:\tlearn: 7.2180387\ttest: 20.9189858\tbest: 20.9167983 (698)\ttotal: 978ms\tremaining: 1.81s\n",
      "800:\tlearn: 6.2174149\ttest: 20.9235345\tbest: 20.9090897 (751)\ttotal: 1.13s\tremaining: 1.69s\n",
      "900:\tlearn: 5.3895778\ttest: 20.9517097\tbest: 20.9090897 (751)\ttotal: 1.26s\tremaining: 1.53s\n",
      "1000:\tlearn: 4.7043129\ttest: 20.9313530\tbest: 20.9090897 (751)\ttotal: 1.38s\tremaining: 1.38s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90908967\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3939367\ttest: 29.9292652\tbest: 29.9292652 (0)\ttotal: 799us\tremaining: 1.6s\n",
      "100:\tlearn: 22.4204826\ttest: 22.5514841\tbest: 22.5514841 (100)\ttotal: 69.9ms\tremaining: 1.31s\n",
      "200:\tlearn: 20.2111836\ttest: 21.4927025\tbest: 21.4927025 (200)\ttotal: 134ms\tremaining: 1.2s\n",
      "300:\tlearn: 18.5561563\ttest: 21.0466999\tbest: 21.0447744 (299)\ttotal: 199ms\tremaining: 1.12s\n",
      "400:\tlearn: 17.3659291\ttest: 20.8551307\tbest: 20.8270870 (366)\ttotal: 316ms\tremaining: 1.26s\n",
      "500:\tlearn: 16.3002101\ttest: 20.8599724\tbest: 20.8268350 (488)\ttotal: 387ms\tremaining: 1.16s\n",
      "600:\tlearn: 15.4006248\ttest: 20.8236663\tbest: 20.8037633 (567)\ttotal: 456ms\tremaining: 1.06s\n",
      "700:\tlearn: 14.6000072\ttest: 20.7492282\tbest: 20.7457872 (696)\ttotal: 520ms\tremaining: 964ms\n",
      "800:\tlearn: 13.8737122\ttest: 20.7220509\tbest: 20.7141676 (798)\ttotal: 585ms\tremaining: 876ms\n",
      "900:\tlearn: 13.2196426\ttest: 20.7062049\tbest: 20.6974854 (815)\ttotal: 651ms\tremaining: 794ms\n",
      "1000:\tlearn: 12.5830921\ttest: 20.6451162\tbest: 20.6451162 (1000)\ttotal: 717ms\tremaining: 715ms\n",
      "1100:\tlearn: 11.9962263\ttest: 20.6579575\tbest: 20.6281712 (1008)\ttotal: 786ms\tremaining: 642ms\n",
      "1200:\tlearn: 11.4514454\ttest: 20.6577088\tbest: 20.6281712 (1008)\ttotal: 847ms\tremaining: 563ms\n",
      "1300:\tlearn: 10.9465412\ttest: 20.6371308\tbest: 20.6152237 (1260)\ttotal: 908ms\tremaining: 488ms\n",
      "1400:\tlearn: 10.4708102\ttest: 20.6276587\tbest: 20.6094205 (1354)\ttotal: 1s\tremaining: 429ms\n",
      "1500:\tlearn: 10.0183816\ttest: 20.6431579\tbest: 20.6094205 (1354)\ttotal: 1.07s\tremaining: 355ms\n",
      "1600:\tlearn: 9.6156553\ttest: 20.6544038\tbest: 20.6094205 (1354)\ttotal: 1.13s\tremaining: 282ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.60942051\n",
      "bestIteration = 1354\n",
      "\n",
      "Shrink model to first 1355 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2784998\ttest: 29.8765793\tbest: 29.8765793 (0)\ttotal: 2.26ms\tremaining: 4.53s\n",
      "100:\tlearn: 18.0402060\ttest: 22.0322068\tbest: 22.0322068 (100)\ttotal: 187ms\tremaining: 3.52s\n",
      "200:\tlearn: 13.6633239\ttest: 21.0721641\tbest: 21.0721641 (200)\ttotal: 405ms\tremaining: 3.62s\n",
      "300:\tlearn: 10.4215567\ttest: 20.7736007\tbest: 20.7736007 (300)\ttotal: 961ms\tremaining: 5.42s\n",
      "400:\tlearn: 8.0733115\ttest: 20.6677180\tbest: 20.6677180 (400)\ttotal: 1.47s\tremaining: 5.85s\n",
      "500:\tlearn: 6.2943735\ttest: 20.6389778\tbest: 20.6258952 (419)\ttotal: 2.01s\tremaining: 6.02s\n",
      "600:\tlearn: 4.9245989\ttest: 20.6479512\tbest: 20.6258952 (419)\ttotal: 2.2s\tremaining: 5.12s\n",
      "700:\tlearn: 3.8988450\ttest: 20.6648422\tbest: 20.6258952 (419)\ttotal: 2.68s\tremaining: 4.96s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.62589515\n",
      "bestIteration = 419\n",
      "\n",
      "Shrink model to first 420 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2200555\ttest: 29.8807593\tbest: 29.8807593 (0)\ttotal: 4.02ms\tremaining: 8.04s\n",
      "100:\tlearn: 15.6996860\ttest: 21.8320018\tbest: 21.8320018 (100)\ttotal: 935ms\tremaining: 17.6s\n",
      "200:\tlearn: 10.5600028\ttest: 20.9639719\tbest: 20.9599142 (197)\ttotal: 1.42s\tremaining: 12.7s\n",
      "300:\tlearn: 7.0746884\ttest: 20.7930421\tbest: 20.7763704 (294)\ttotal: 1.96s\tremaining: 11.1s\n",
      "400:\tlearn: 4.7841099\ttest: 20.7229932\tbest: 20.7171106 (397)\ttotal: 2.47s\tremaining: 9.84s\n",
      "500:\tlearn: 3.2968175\ttest: 20.6915809\tbest: 20.6903218 (498)\ttotal: 3.15s\tremaining: 9.43s\n",
      "600:\tlearn: 2.2573987\ttest: 20.6721948\tbest: 20.6721948 (600)\ttotal: 3.55s\tremaining: 8.27s\n",
      "700:\tlearn: 1.5852843\ttest: 20.6716060\tbest: 20.6618156 (661)\ttotal: 3.88s\tremaining: 7.2s\n",
      "800:\tlearn: 1.1052681\ttest: 20.6849040\tbest: 20.6618156 (661)\ttotal: 4.27s\tremaining: 6.39s\n",
      "900:\tlearn: 0.7646140\ttest: 20.6796179\tbest: 20.6618156 (661)\ttotal: 5.16s\tremaining: 6.29s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.66181565\n",
      "bestIteration = 661\n",
      "\n",
      "Shrink model to first 662 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925603\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 762us\tremaining: 1.52s\n",
      "100:\tlearn: 22.3675416\ttest: 22.5593946\tbest: 22.5593946 (100)\ttotal: 78.5ms\tremaining: 1.48s\n",
      "200:\tlearn: 20.1453054\ttest: 21.5587636\tbest: 21.5587636 (200)\ttotal: 157ms\tremaining: 1.41s\n",
      "300:\tlearn: 18.3618849\ttest: 21.0831353\tbest: 21.0810032 (299)\ttotal: 250ms\tremaining: 1.41s\n",
      "400:\tlearn: 17.1156623\ttest: 20.9830215\tbest: 20.9452952 (373)\ttotal: 348ms\tremaining: 1.39s\n",
      "500:\tlearn: 15.9948182\ttest: 20.8726511\tbest: 20.8589263 (488)\ttotal: 410ms\tremaining: 1.23s\n",
      "600:\tlearn: 15.0970275\ttest: 20.8733245\tbest: 20.8589263 (488)\ttotal: 505ms\tremaining: 1.18s\n",
      "700:\tlearn: 14.3113505\ttest: 20.7384577\tbest: 20.7384577 (700)\ttotal: 707ms\tremaining: 1.31s\n",
      "800:\tlearn: 13.5757210\ttest: 20.7028379\tbest: 20.7020357 (795)\ttotal: 930ms\tremaining: 1.39s\n",
      "900:\tlearn: 12.9216215\ttest: 20.7051681\tbest: 20.6887408 (814)\ttotal: 1.16s\tremaining: 1.41s\n",
      "1000:\tlearn: 12.2715419\ttest: 20.7077834\tbest: 20.6887408 (814)\ttotal: 1.36s\tremaining: 1.36s\n",
      "1100:\tlearn: 11.6848595\ttest: 20.6270315\tbest: 20.6235139 (1097)\ttotal: 1.59s\tremaining: 1.3s\n",
      "1200:\tlearn: 11.1603574\ttest: 20.6004800\tbest: 20.5951480 (1198)\ttotal: 1.91s\tremaining: 1.27s\n",
      "1300:\tlearn: 10.6328603\ttest: 20.5625991\tbest: 20.5461822 (1281)\ttotal: 2.11s\tremaining: 1.13s\n",
      "1400:\tlearn: 10.1587776\ttest: 20.5569158\tbest: 20.5461822 (1281)\ttotal: 2.23s\tremaining: 953ms\n",
      "1500:\tlearn: 9.7364737\ttest: 20.5220483\tbest: 20.5203524 (1493)\ttotal: 2.43s\tremaining: 809ms\n",
      "1600:\tlearn: 9.3204950\ttest: 20.5874025\tbest: 20.5203524 (1493)\ttotal: 2.53s\tremaining: 631ms\n",
      "1700:\tlearn: 8.9423713\ttest: 20.5625935\tbest: 20.5203524 (1493)\ttotal: 2.61s\tremaining: 459ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.5203524\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980296\ttest: 29.8551289\tbest: 29.8551289 (0)\ttotal: 1.38ms\tremaining: 2.76s\n",
      "100:\tlearn: 19.8959554\ttest: 22.1211354\tbest: 22.1211354 (100)\ttotal: 155ms\tremaining: 2.92s\n",
      "200:\tlearn: 16.1995866\ttest: 21.3561557\tbest: 21.3264672 (192)\ttotal: 288ms\tremaining: 2.58s\n",
      "300:\tlearn: 13.4260647\ttest: 21.0762961\tbest: 21.0462980 (265)\ttotal: 438ms\tremaining: 2.47s\n",
      "400:\tlearn: 11.3162094\ttest: 21.0785123\tbest: 21.0223356 (334)\ttotal: 590ms\tremaining: 2.35s\n",
      "500:\tlearn: 9.7090992\ttest: 21.0116298\tbest: 21.0111699 (499)\ttotal: 716ms\tremaining: 2.14s\n",
      "600:\tlearn: 8.3246121\ttest: 20.9825260\tbest: 20.9804063 (598)\ttotal: 844ms\tremaining: 1.96s\n",
      "700:\tlearn: 7.2180428\ttest: 20.9189850\tbest: 20.9167975 (698)\ttotal: 1.14s\tremaining: 2.12s\n",
      "800:\tlearn: 6.2174188\ttest: 20.9235336\tbest: 20.9090888 (751)\ttotal: 1.57s\tremaining: 2.36s\n",
      "900:\tlearn: 5.3895814\ttest: 20.9517088\tbest: 20.9090888 (751)\ttotal: 2.02s\tremaining: 2.46s\n",
      "1000:\tlearn: 4.7043163\ttest: 20.9313522\tbest: 20.9090888 (751)\ttotal: 2.17s\tremaining: 2.17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90908882\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925603\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 873us\tremaining: 1.75s\n",
      "100:\tlearn: 22.3675414\ttest: 22.5593946\tbest: 22.5593946 (100)\ttotal: 74.6ms\tremaining: 1.4s\n",
      "200:\tlearn: 20.1453050\ttest: 21.5587636\tbest: 21.5587636 (200)\ttotal: 139ms\tremaining: 1.24s\n",
      "300:\tlearn: 18.3618844\ttest: 21.0831354\tbest: 21.0810032 (299)\ttotal: 204ms\tremaining: 1.15s\n",
      "400:\tlearn: 17.1156618\ttest: 20.9830216\tbest: 20.9452953 (373)\ttotal: 268ms\tremaining: 1.07s\n",
      "500:\tlearn: 15.9948176\ttest: 20.8726512\tbest: 20.8589264 (488)\ttotal: 359ms\tremaining: 1.07s\n",
      "600:\tlearn: 15.0970269\ttest: 20.8733246\tbest: 20.8589264 (488)\ttotal: 424ms\tremaining: 986ms\n",
      "700:\tlearn: 14.3113499\ttest: 20.7384579\tbest: 20.7384579 (700)\ttotal: 485ms\tremaining: 899ms\n",
      "800:\tlearn: 13.5757203\ttest: 20.7028381\tbest: 20.7020358 (795)\ttotal: 546ms\tremaining: 817ms\n",
      "900:\tlearn: 12.9216208\ttest: 20.7051683\tbest: 20.6887409 (814)\ttotal: 642ms\tremaining: 783ms\n",
      "1000:\tlearn: 12.2715412\ttest: 20.7077836\tbest: 20.6887409 (814)\ttotal: 703ms\tremaining: 702ms\n",
      "1100:\tlearn: 11.6848589\ttest: 20.6270316\tbest: 20.6235141 (1097)\ttotal: 765ms\tremaining: 624ms\n",
      "1200:\tlearn: 11.1603568\ttest: 20.6004802\tbest: 20.5951481 (1198)\ttotal: 826ms\tremaining: 549ms\n",
      "1300:\tlearn: 10.6328597\ttest: 20.5625993\tbest: 20.5461823 (1281)\ttotal: 916ms\tremaining: 492ms\n",
      "1400:\tlearn: 10.1587770\ttest: 20.5569160\tbest: 20.5461823 (1281)\ttotal: 1.01s\tremaining: 430ms\n",
      "1500:\tlearn: 9.7364730\ttest: 20.5220484\tbest: 20.5203526 (1493)\ttotal: 1.07s\tremaining: 355ms\n",
      "1600:\tlearn: 9.3204944\ttest: 20.5874027\tbest: 20.5203526 (1493)\ttotal: 1.14s\tremaining: 285ms\n",
      "1700:\tlearn: 8.9423707\ttest: 20.5625937\tbest: 20.5203526 (1493)\ttotal: 1.21s\tremaining: 212ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52035256\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2995208\ttest: 29.8565399\tbest: 29.8565399 (0)\ttotal: 1.43ms\tremaining: 2.87s\n",
      "100:\tlearn: 19.8928038\ttest: 22.1031115\tbest: 22.1031115 (100)\ttotal: 120ms\tremaining: 2.25s\n",
      "200:\tlearn: 16.3108260\ttest: 21.2874873\tbest: 21.2698499 (197)\ttotal: 271ms\tremaining: 2.42s\n",
      "300:\tlearn: 13.5649686\ttest: 20.9940872\tbest: 20.9940872 (300)\ttotal: 388ms\tremaining: 2.19s\n",
      "400:\tlearn: 11.4538149\ttest: 20.9209356\tbest: 20.9133363 (347)\ttotal: 510ms\tremaining: 2.03s\n",
      "500:\tlearn: 9.8741563\ttest: 20.8503666\tbest: 20.8496763 (499)\ttotal: 627ms\tremaining: 1.88s\n",
      "600:\tlearn: 8.4691073\ttest: 20.8011171\tbest: 20.7842159 (573)\ttotal: 753ms\tremaining: 1.75s\n",
      "700:\tlearn: 7.3106299\ttest: 20.8587287\tbest: 20.7842159 (573)\ttotal: 898ms\tremaining: 1.66s\n",
      "800:\tlearn: 6.3496874\ttest: 20.8489486\tbest: 20.7842159 (573)\ttotal: 1.03s\tremaining: 1.55s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.78421589\n",
      "bestIteration = 573\n",
      "\n",
      "Shrink model to first 574 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980574\ttest: 29.8551552\tbest: 29.8551552 (0)\ttotal: 1.32ms\tremaining: 2.65s\n",
      "100:\tlearn: 19.8972674\ttest: 22.1212131\tbest: 22.1212131 (100)\ttotal: 120ms\tremaining: 2.25s\n",
      "200:\tlearn: 16.2015906\ttest: 21.3559221\tbest: 21.3263030 (192)\ttotal: 243ms\tremaining: 2.17s\n",
      "300:\tlearn: 13.4178595\ttest: 21.1416219\tbest: 21.1040753 (259)\ttotal: 362ms\tremaining: 2.04s\n",
      "400:\tlearn: 11.3019215\ttest: 21.0553848\tbest: 21.0474318 (393)\ttotal: 510ms\tremaining: 2.03s\n",
      "500:\tlearn: 9.6667033\ttest: 20.9578250\tbest: 20.9562354 (499)\ttotal: 630ms\tremaining: 1.88s\n",
      "600:\tlearn: 8.2937939\ttest: 20.9386815\tbest: 20.9103853 (551)\ttotal: 781ms\tremaining: 1.82s\n",
      "700:\tlearn: 7.1858519\ttest: 20.9192192\tbest: 20.9103853 (551)\ttotal: 899ms\tremaining: 1.67s\n",
      "800:\tlearn: 6.1909223\ttest: 20.9097907\tbest: 20.8978960 (792)\ttotal: 1.05s\tremaining: 1.57s\n",
      "900:\tlearn: 5.3874853\ttest: 20.8923482\tbest: 20.8860200 (893)\ttotal: 1.17s\tremaining: 1.43s\n",
      "1000:\tlearn: 4.6798323\ttest: 20.9163326\tbest: 20.8800534 (911)\ttotal: 1.29s\tremaining: 1.29s\n",
      "1100:\tlearn: 4.0758693\ttest: 20.9052905\tbest: 20.8800534 (911)\ttotal: 1.41s\tremaining: 1.15s\n",
      "1200:\tlearn: 3.5685941\ttest: 20.8864967\tbest: 20.8800534 (911)\ttotal: 1.53s\tremaining: 1.02s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.88005343\n",
      "bestIteration = 911\n",
      "\n",
      "Shrink model to first 912 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3581110\ttest: 29.9242946\tbest: 29.9242946 (0)\ttotal: 994us\tremaining: 1.99s\n",
      "100:\tlearn: 21.2466793\ttest: 22.2013826\tbest: 22.2013826 (100)\ttotal: 90.1ms\tremaining: 1.69s\n",
      "200:\tlearn: 18.2608915\ttest: 21.1949619\tbest: 21.1949619 (200)\ttotal: 179ms\tremaining: 1.6s\n",
      "300:\tlearn: 16.0827850\ttest: 20.7446897\tbest: 20.7446897 (300)\ttotal: 268ms\tremaining: 1.51s\n",
      "400:\tlearn: 14.3908808\ttest: 20.6246565\tbest: 20.6125170 (393)\ttotal: 381ms\tremaining: 1.52s\n",
      "500:\tlearn: 13.0437948\ttest: 20.5588532\tbest: 20.5481708 (497)\ttotal: 466ms\tremaining: 1.39s\n",
      "600:\tlearn: 11.8217362\ttest: 20.5926519\tbest: 20.5481708 (497)\ttotal: 580ms\tremaining: 1.35s\n",
      "700:\tlearn: 10.7703627\ttest: 20.5829929\tbest: 20.5481708 (497)\ttotal: 671ms\tremaining: 1.24s\n",
      "800:\tlearn: 9.8687819\ttest: 20.5316435\tbest: 20.5316435 (800)\ttotal: 760ms\tremaining: 1.14s\n",
      "900:\tlearn: 9.0755213\ttest: 20.4779692\tbest: 20.4759489 (897)\ttotal: 849ms\tremaining: 1.03s\n",
      "1000:\tlearn: 8.3426003\ttest: 20.4907058\tbest: 20.4709840 (908)\ttotal: 939ms\tremaining: 937ms\n",
      "1100:\tlearn: 7.6771051\ttest: 20.4818595\tbest: 20.4709840 (908)\ttotal: 1.02s\tremaining: 836ms\n",
      "1200:\tlearn: 7.0876633\ttest: 20.4246813\tbest: 20.4246813 (1200)\ttotal: 1.14s\tremaining: 756ms\n",
      "1300:\tlearn: 6.5329936\ttest: 20.4095572\tbest: 20.4007377 (1228)\ttotal: 1.23s\tremaining: 660ms\n",
      "1400:\tlearn: 6.0342713\ttest: 20.4355213\tbest: 20.3969669 (1331)\ttotal: 1.31s\tremaining: 562ms\n",
      "1500:\tlearn: 5.5853310\ttest: 20.4507530\tbest: 20.3969669 (1331)\ttotal: 1.4s\tremaining: 467ms\n",
      "1600:\tlearn: 5.1697685\ttest: 20.4704378\tbest: 20.3969669 (1331)\ttotal: 1.52s\tremaining: 379ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.3969669\n",
      "bestIteration = 1331\n",
      "\n",
      "Shrink model to first 1332 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3951427\ttest: 29.9552749\tbest: 29.9552749 (0)\ttotal: 997us\tremaining: 1.99s\n",
      "100:\tlearn: 21.9696202\ttest: 22.4001566\tbest: 22.4001566 (100)\ttotal: 95.1ms\tremaining: 1.79s\n",
      "200:\tlearn: 19.6520154\ttest: 21.2849732\tbest: 21.2849732 (200)\ttotal: 185ms\tremaining: 1.65s\n",
      "300:\tlearn: 17.7582565\ttest: 20.7694770\tbest: 20.7694770 (300)\ttotal: 274ms\tremaining: 1.55s\n",
      "400:\tlearn: 16.4098703\ttest: 20.6512993\tbest: 20.6512993 (400)\ttotal: 364ms\tremaining: 1.45s\n",
      "500:\tlearn: 15.1950686\ttest: 20.5198005\tbest: 20.5132630 (466)\ttotal: 454ms\tremaining: 1.36s\n",
      "600:\tlearn: 14.0917837\ttest: 20.4933142\tbest: 20.4662859 (573)\ttotal: 544ms\tremaining: 1.26s\n",
      "700:\tlearn: 13.0763702\ttest: 20.4407977\tbest: 20.4197972 (691)\ttotal: 633ms\tremaining: 1.17s\n",
      "800:\tlearn: 12.2021796\ttest: 20.3578799\tbest: 20.3555211 (798)\ttotal: 722ms\tremaining: 1.08s\n",
      "900:\tlearn: 11.4192043\ttest: 20.3598043\tbest: 20.3331858 (847)\ttotal: 813ms\tremaining: 992ms\n",
      "1000:\tlearn: 10.7121441\ttest: 20.3482680\tbest: 20.3317796 (985)\ttotal: 903ms\tremaining: 901ms\n",
      "1100:\tlearn: 10.0257309\ttest: 20.3629822\tbest: 20.3317796 (985)\ttotal: 996ms\tremaining: 813ms\n",
      "1200:\tlearn: 9.4070644\ttest: 20.3779907\tbest: 20.3317796 (985)\ttotal: 1.09s\tremaining: 723ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.33177957\n",
      "bestIteration = 985\n",
      "\n",
      "Shrink model to first 986 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580798\ttest: 29.9242659\tbest: 29.9242659 (0)\ttotal: 990us\tremaining: 1.98s\n",
      "100:\tlearn: 21.2447469\ttest: 22.2012985\tbest: 22.2012985 (100)\ttotal: 87.8ms\tremaining: 1.65s\n",
      "200:\tlearn: 18.2454812\ttest: 21.1922391\tbest: 21.1922391 (200)\ttotal: 179ms\tremaining: 1.6s\n",
      "300:\tlearn: 16.0109710\ttest: 20.6532445\tbest: 20.6532445 (300)\ttotal: 270ms\tremaining: 1.52s\n",
      "400:\tlearn: 14.3298335\ttest: 20.5600828\tbest: 20.5238361 (382)\ttotal: 361ms\tremaining: 1.44s\n",
      "500:\tlearn: 13.0114249\ttest: 20.4602572\tbest: 20.4513561 (496)\ttotal: 450ms\tremaining: 1.35s\n",
      "600:\tlearn: 11.7764888\ttest: 20.4984960\tbest: 20.4513561 (496)\ttotal: 540ms\tremaining: 1.26s\n",
      "700:\tlearn: 10.7450694\ttest: 20.4638414\tbest: 20.4417271 (661)\ttotal: 633ms\tremaining: 1.17s\n",
      "800:\tlearn: 9.8449850\ttest: 20.3510348\tbest: 20.3503833 (797)\ttotal: 724ms\tremaining: 1.08s\n",
      "900:\tlearn: 9.0525727\ttest: 20.3190609\tbest: 20.3106690 (857)\ttotal: 813ms\tremaining: 991ms\n",
      "1000:\tlearn: 8.3276257\ttest: 20.2982393\tbest: 20.2891870 (997)\ttotal: 934ms\tremaining: 932ms\n",
      "1100:\tlearn: 7.6586675\ttest: 20.2851029\tbest: 20.2766495 (1075)\ttotal: 1.03s\tremaining: 845ms\n",
      "1200:\tlearn: 7.0538099\ttest: 20.2779212\tbest: 20.2615403 (1157)\ttotal: 1.14s\tremaining: 759ms\n",
      "1300:\tlearn: 6.5282890\ttest: 20.2975502\tbest: 20.2615403 (1157)\ttotal: 1.23s\tremaining: 660ms\n",
      "1400:\tlearn: 6.0298398\ttest: 20.3050468\tbest: 20.2615403 (1157)\ttotal: 1.32s\tremaining: 563ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.26154025\n",
      "bestIteration = 1157\n",
      "\n",
      "Shrink model to first 1158 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3926034\ttest: 29.9531762\tbest: 29.9531762 (0)\ttotal: 1.21ms\tremaining: 2.42s\n",
      "100:\tlearn: 21.9506411\ttest: 22.3987167\tbest: 22.3987167 (100)\ttotal: 115ms\tremaining: 2.16s\n",
      "200:\tlearn: 19.6127783\ttest: 21.3382722\tbest: 21.3382722 (200)\ttotal: 205ms\tremaining: 1.84s\n",
      "300:\tlearn: 17.6969625\ttest: 20.8918169\tbest: 20.8918169 (300)\ttotal: 289ms\tremaining: 1.63s\n",
      "400:\tlearn: 16.3416289\ttest: 20.7514108\tbest: 20.7463290 (394)\ttotal: 407ms\tremaining: 1.62s\n",
      "500:\tlearn: 15.1086260\ttest: 20.6377662\tbest: 20.6377662 (500)\ttotal: 491ms\tremaining: 1.47s\n",
      "600:\tlearn: 14.0269487\ttest: 20.5594861\tbest: 20.5465141 (589)\ttotal: 576ms\tremaining: 1.34s\n",
      "700:\tlearn: 13.0124892\ttest: 20.5483218\tbest: 20.5067665 (658)\ttotal: 695ms\tremaining: 1.29s\n",
      "800:\tlearn: 12.1467805\ttest: 20.4730860\tbest: 20.4730860 (800)\ttotal: 782ms\tremaining: 1.17s\n",
      "900:\tlearn: 11.3999197\ttest: 20.4766836\tbest: 20.4527142 (820)\ttotal: 866ms\tremaining: 1.06s\n",
      "1000:\tlearn: 10.6866852\ttest: 20.4666202\tbest: 20.4527142 (820)\ttotal: 955ms\tremaining: 953ms\n",
      "1100:\tlearn: 10.0258368\ttest: 20.4271426\tbest: 20.4233817 (1095)\ttotal: 1.04s\tremaining: 848ms\n",
      "1200:\tlearn: 9.4128681\ttest: 20.4637377\tbest: 20.4202912 (1114)\ttotal: 1.12s\tremaining: 748ms\n",
      "1300:\tlearn: 8.8260622\ttest: 20.4729844\tbest: 20.4202912 (1114)\ttotal: 1.23s\tremaining: 660ms\n",
      "1400:\tlearn: 8.3047032\ttest: 20.4954318\tbest: 20.4202912 (1114)\ttotal: 1.31s\tremaining: 562ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.42029115\n",
      "bestIteration = 1114\n",
      "\n",
      "Shrink model to first 1115 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580311\ttest: 29.9242212\tbest: 29.9242212 (0)\ttotal: 932us\tremaining: 1.86s\n",
      "100:\tlearn: 21.2417076\ttest: 22.2011712\tbest: 22.2011712 (100)\ttotal: 85.7ms\tremaining: 1.61s\n",
      "200:\tlearn: 18.2406916\ttest: 21.1924249\tbest: 21.1924249 (200)\ttotal: 169ms\tremaining: 1.51s\n",
      "300:\tlearn: 16.0053753\ttest: 20.6536090\tbest: 20.6536090 (300)\ttotal: 285ms\tremaining: 1.61s\n",
      "400:\tlearn: 14.3170725\ttest: 20.5523292\tbest: 20.5176351 (382)\ttotal: 376ms\tremaining: 1.5s\n",
      "500:\tlearn: 12.9711048\ttest: 20.4789663\tbest: 20.4588636 (497)\ttotal: 463ms\tremaining: 1.39s\n",
      "600:\tlearn: 11.7842786\ttest: 20.5063436\tbest: 20.4588636 (497)\ttotal: 553ms\tremaining: 1.29s\n",
      "700:\tlearn: 10.7477035\ttest: 20.4870101\tbest: 20.4550090 (659)\ttotal: 637ms\tremaining: 1.18s\n",
      "800:\tlearn: 9.8486568\ttest: 20.4326068\tbest: 20.4233584 (796)\ttotal: 722ms\tremaining: 1.08s\n",
      "900:\tlearn: 9.0469726\ttest: 20.4241068\tbest: 20.4233584 (796)\ttotal: 812ms\tremaining: 990ms\n",
      "1000:\tlearn: 8.3070555\ttest: 20.4083066\tbest: 20.4034056 (986)\ttotal: 897ms\tremaining: 895ms\n",
      "1100:\tlearn: 7.6547995\ttest: 20.3696611\tbest: 20.3696611 (1100)\ttotal: 981ms\tremaining: 801ms\n",
      "1200:\tlearn: 7.0656518\ttest: 20.3807926\tbest: 20.3547404 (1130)\ttotal: 1.14s\tremaining: 758ms\n",
      "1300:\tlearn: 6.5097172\ttest: 20.3738150\tbest: 20.3547404 (1130)\ttotal: 1.35s\tremaining: 723ms\n",
      "1400:\tlearn: 6.0131572\ttest: 20.3719334\tbest: 20.3547404 (1130)\ttotal: 1.56s\tremaining: 668ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35474037\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2804140\ttest: 29.8779127\tbest: 29.8779127 (0)\ttotal: 3.25ms\tremaining: 6.49s\n",
      "100:\tlearn: 18.0993346\ttest: 22.0396580\tbest: 22.0396580 (100)\ttotal: 512ms\tremaining: 9.63s\n",
      "200:\tlearn: 13.7193544\ttest: 20.9662826\tbest: 20.9662826 (200)\ttotal: 836ms\tremaining: 7.48s\n",
      "300:\tlearn: 10.4765888\ttest: 20.6250754\tbest: 20.6250754 (300)\ttotal: 1.08s\tremaining: 6.08s\n",
      "400:\tlearn: 8.0695192\ttest: 20.5837735\tbest: 20.5710709 (398)\ttotal: 1.71s\tremaining: 6.83s\n",
      "500:\tlearn: 6.3337026\ttest: 20.5454745\tbest: 20.5292926 (442)\ttotal: 1.89s\tremaining: 5.67s\n",
      "600:\tlearn: 4.9723433\ttest: 20.5133818\tbest: 20.5063571 (581)\ttotal: 2.27s\tremaining: 5.28s\n",
      "700:\tlearn: 3.9470455\ttest: 20.5190255\tbest: 20.5063571 (581)\ttotal: 2.78s\tremaining: 5.15s\n",
      "800:\tlearn: 3.1385954\ttest: 20.5299830\tbest: 20.5063571 (581)\ttotal: 2.95s\tremaining: 4.42s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.50635705\n",
      "bestIteration = 581\n",
      "\n",
      "Shrink model to first 582 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580330\ttest: 29.9242229\tbest: 29.9242229 (0)\ttotal: 4.92ms\tremaining: 9.83s\n",
      "100:\tlearn: 21.2418217\ttest: 22.2011758\tbest: 22.2011758 (100)\ttotal: 171ms\tremaining: 3.22s\n",
      "200:\tlearn: 18.2408713\ttest: 21.1924178\tbest: 21.1924178 (200)\ttotal: 407ms\tremaining: 3.64s\n",
      "300:\tlearn: 16.0055852\ttest: 20.6535952\tbest: 20.6535952 (300)\ttotal: 649ms\tremaining: 3.66s\n",
      "400:\tlearn: 14.3173016\ttest: 20.5522970\tbest: 20.5176067 (382)\ttotal: 832ms\tremaining: 3.32s\n",
      "500:\tlearn: 12.9713436\ttest: 20.4789313\tbest: 20.4588294 (497)\ttotal: 1.07s\tremaining: 3.19s\n",
      "600:\tlearn: 11.7845259\ttest: 20.5063080\tbest: 20.4588294 (497)\ttotal: 1.16s\tremaining: 2.69s\n",
      "700:\tlearn: 10.7479539\ttest: 20.4869677\tbest: 20.4549706 (659)\ttotal: 1.24s\tremaining: 2.3s\n",
      "800:\tlearn: 9.8489053\ttest: 20.4325665\tbest: 20.4233176 (796)\ttotal: 1.34s\tremaining: 2.01s\n",
      "900:\tlearn: 9.0472164\ttest: 20.4240644\tbest: 20.4233176 (796)\ttotal: 1.43s\tremaining: 1.75s\n",
      "1000:\tlearn: 8.3072939\ttest: 20.4082623\tbest: 20.4033617 (986)\ttotal: 1.52s\tremaining: 1.52s\n",
      "1100:\tlearn: 7.6550308\ttest: 20.3696154\tbest: 20.3696154 (1100)\ttotal: 1.61s\tremaining: 1.32s\n",
      "1200:\tlearn: 7.0658770\ttest: 20.3807460\tbest: 20.3546935 (1130)\ttotal: 1.7s\tremaining: 1.13s\n",
      "1300:\tlearn: 6.5152437\ttest: 20.3685292\tbest: 20.3546935 (1130)\ttotal: 1.83s\tremaining: 983ms\n",
      "1400:\tlearn: 6.0006196\ttest: 20.3770587\tbest: 20.3546935 (1130)\ttotal: 2.16s\tremaining: 925ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35469346\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2919401\ttest: 29.8857799\tbest: 29.8857799 (0)\ttotal: 6.76ms\tremaining: 13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 18.4265926\ttest: 22.1291710\tbest: 22.1291710 (100)\ttotal: 434ms\tremaining: 8.17s\n",
      "200:\tlearn: 14.2205407\ttest: 21.2588067\tbest: 21.2588067 (200)\ttotal: 617ms\tremaining: 5.53s\n",
      "300:\tlearn: 10.9722003\ttest: 20.9977374\tbest: 20.9877064 (296)\ttotal: 799ms\tremaining: 4.51s\n",
      "400:\tlearn: 8.7031674\ttest: 20.8075365\tbest: 20.8075365 (400)\ttotal: 972ms\tremaining: 3.88s\n",
      "500:\tlearn: 6.9226808\ttest: 20.6906504\tbest: 20.6803717 (484)\ttotal: 1.16s\tremaining: 3.46s\n",
      "600:\tlearn: 5.4900622\ttest: 20.6794529\tbest: 20.6762228 (597)\ttotal: 1.33s\tremaining: 3.1s\n",
      "700:\tlearn: 4.3991393\ttest: 20.6935549\tbest: 20.6673667 (617)\ttotal: 1.51s\tremaining: 2.8s\n",
      "800:\tlearn: 3.5590108\ttest: 20.6590865\tbest: 20.6590865 (800)\ttotal: 1.69s\tremaining: 2.52s\n",
      "900:\tlearn: 2.8927084\ttest: 20.6817574\tbest: 20.6583827 (805)\ttotal: 1.89s\tremaining: 2.31s\n",
      "1000:\tlearn: 2.3162371\ttest: 20.6656233\tbest: 20.6583827 (805)\ttotal: 2.07s\tremaining: 2.06s\n",
      "1100:\tlearn: 1.8827142\ttest: 20.6764576\tbest: 20.6583827 (805)\ttotal: 2.27s\tremaining: 1.85s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.65838272\n",
      "bestIteration = 805\n",
      "\n",
      "Shrink model to first 806 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925722\ttest: 29.9282402\tbest: 29.9282402 (0)\ttotal: 728us\tremaining: 1.46s\n",
      "100:\tlearn: 22.3683358\ttest: 22.5595541\tbest: 22.5595541 (100)\ttotal: 62.9ms\tremaining: 1.18s\n",
      "200:\tlearn: 20.1469657\ttest: 21.5587042\tbest: 21.5587042 (200)\ttotal: 128ms\tremaining: 1.14s\n",
      "300:\tlearn: 18.3641078\ttest: 21.0828356\tbest: 21.0807041 (299)\ttotal: 193ms\tremaining: 1.09s\n",
      "400:\tlearn: 17.1180235\ttest: 20.9825700\tbest: 20.9448694 (373)\ttotal: 258ms\tremaining: 1.03s\n",
      "500:\tlearn: 15.9976647\ttest: 20.8620189\tbest: 20.8479984 (488)\ttotal: 326ms\tremaining: 974ms\n",
      "600:\tlearn: 15.1290997\ttest: 20.8592557\tbest: 20.8364497 (538)\ttotal: 387ms\tremaining: 902ms\n",
      "700:\tlearn: 14.3367541\ttest: 20.7195307\tbest: 20.7147743 (699)\ttotal: 472ms\tremaining: 874ms\n",
      "800:\tlearn: 13.6031561\ttest: 20.7007595\tbest: 20.7007595 (800)\ttotal: 538ms\tremaining: 805ms\n",
      "900:\tlearn: 12.9323893\ttest: 20.6996781\tbest: 20.6873789 (814)\ttotal: 603ms\tremaining: 735ms\n",
      "1000:\tlearn: 12.3036950\ttest: 20.6932247\tbest: 20.6780088 (981)\ttotal: 667ms\tremaining: 666ms\n",
      "1100:\tlearn: 11.6932645\ttest: 20.6846554\tbest: 20.6676158 (1008)\ttotal: 733ms\tremaining: 599ms\n",
      "1200:\tlearn: 11.1523848\ttest: 20.6693423\tbest: 20.6606326 (1185)\ttotal: 823ms\tremaining: 547ms\n",
      "1300:\tlearn: 10.6473771\ttest: 20.6597267\tbest: 20.6496834 (1285)\ttotal: 884ms\tremaining: 475ms\n",
      "1400:\tlearn: 10.1608442\ttest: 20.6905205\tbest: 20.6496834 (1285)\ttotal: 949ms\tremaining: 406ms\n",
      "1500:\tlearn: 9.7119418\ttest: 20.6466068\tbest: 20.6428568 (1494)\ttotal: 1.01s\tremaining: 337ms\n",
      "1600:\tlearn: 9.2875920\ttest: 20.7028465\tbest: 20.6428568 (1494)\ttotal: 1.08s\tremaining: 269ms\n",
      "1700:\tlearn: 8.8922987\ttest: 20.6597347\tbest: 20.6428568 (1494)\ttotal: 1.14s\tremaining: 201ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.64285682\n",
      "bestIteration = 1494\n",
      "\n",
      "Shrink model to first 1495 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580308\ttest: 29.9242208\tbest: 29.9242208 (0)\ttotal: 968us\tremaining: 1.94s\n",
      "100:\tlearn: 21.2416829\ttest: 22.2011702\tbest: 22.2011702 (100)\ttotal: 91.7ms\tremaining: 1.72s\n",
      "200:\tlearn: 18.2406528\ttest: 21.1924264\tbest: 21.1924264 (200)\ttotal: 183ms\tremaining: 1.64s\n",
      "300:\tlearn: 16.0053300\ttest: 20.6536120\tbest: 20.6536120 (300)\ttotal: 278ms\tremaining: 1.57s\n",
      "400:\tlearn: 14.3170230\ttest: 20.5523362\tbest: 20.5176412 (382)\ttotal: 366ms\tremaining: 1.46s\n",
      "500:\tlearn: 12.9710532\ttest: 20.4789738\tbest: 20.4588710 (497)\ttotal: 479ms\tremaining: 1.43s\n",
      "600:\tlearn: 11.7842252\ttest: 20.5063513\tbest: 20.4588710 (497)\ttotal: 564ms\tremaining: 1.31s\n",
      "700:\tlearn: 10.7476494\ttest: 20.4870192\tbest: 20.4550173 (659)\ttotal: 653ms\tremaining: 1.21s\n",
      "800:\tlearn: 9.8486031\ttest: 20.4326155\tbest: 20.4233672 (796)\ttotal: 742ms\tremaining: 1.11s\n",
      "900:\tlearn: 9.0469200\ttest: 20.4241160\tbest: 20.4233672 (796)\ttotal: 834ms\tremaining: 1.02s\n",
      "1000:\tlearn: 8.3044716\ttest: 20.4063932\tbest: 20.4025120 (986)\ttotal: 920ms\tremaining: 918ms\n",
      "1100:\tlearn: 7.6573820\ttest: 20.3599107\tbest: 20.3599107 (1100)\ttotal: 1.03s\tremaining: 846ms\n",
      "1200:\tlearn: 7.0708173\ttest: 20.3594419\tbest: 20.3351488 (1131)\ttotal: 1.12s\tremaining: 745ms\n",
      "1300:\tlearn: 6.5260762\ttest: 20.3199978\tbest: 20.3099202 (1281)\ttotal: 1.2s\tremaining: 647ms\n",
      "1400:\tlearn: 6.0187236\ttest: 20.3379414\tbest: 20.3099202 (1281)\ttotal: 1.31s\tremaining: 559ms\n",
      "1500:\tlearn: 5.5791562\ttest: 20.3702939\tbest: 20.3099202 (1281)\ttotal: 1.39s\tremaining: 464ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992015\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2200628\ttest: 29.8807618\tbest: 29.8807618 (0)\ttotal: 3.36ms\tremaining: 6.72s\n",
      "100:\tlearn: 15.6998256\ttest: 21.8320119\tbest: 21.8320119 (100)\ttotal: 331ms\tremaining: 6.22s\n",
      "200:\tlearn: 10.5601679\ttest: 20.9639732\tbest: 20.9599152 (197)\ttotal: 654ms\tremaining: 5.85s\n",
      "300:\tlearn: 7.0630402\ttest: 20.7947223\tbest: 20.7835499 (291)\ttotal: 972ms\tremaining: 5.49s\n",
      "400:\tlearn: 4.7940114\ttest: 20.7987844\tbest: 20.7686671 (325)\ttotal: 1.32s\tremaining: 5.27s\n",
      "500:\tlearn: 3.2812516\ttest: 20.7963336\tbest: 20.7686671 (325)\ttotal: 2.01s\tremaining: 6.01s\n",
      "600:\tlearn: 2.2384484\ttest: 20.8044985\tbest: 20.7686671 (325)\ttotal: 3.04s\tremaining: 7.08s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.76866707\n",
      "bestIteration = 325\n",
      "\n",
      "Shrink model to first 326 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580352\ttest: 29.9242250\tbest: 29.9242250 (0)\ttotal: 1ms\tremaining: 2s\n",
      "100:\tlearn: 21.2419647\ttest: 22.2011817\tbest: 22.2011817 (100)\ttotal: 87.7ms\tremaining: 1.65s\n",
      "200:\tlearn: 18.2410966\ttest: 21.1924089\tbest: 21.1924089 (200)\ttotal: 178ms\tremaining: 1.59s\n",
      "300:\tlearn: 16.0058482\ttest: 20.6535779\tbest: 20.6535779 (300)\ttotal: 269ms\tremaining: 1.52s\n",
      "400:\tlearn: 14.3175888\ttest: 20.5522567\tbest: 20.5175712 (382)\ttotal: 355ms\tremaining: 1.41s\n",
      "500:\tlearn: 12.9716429\ttest: 20.4788874\tbest: 20.4587865 (497)\ttotal: 445ms\tremaining: 1.33s\n",
      "600:\tlearn: 11.7848360\ttest: 20.5062634\tbest: 20.4587865 (497)\ttotal: 539ms\tremaining: 1.25s\n",
      "700:\tlearn: 10.7482678\ttest: 20.4869147\tbest: 20.4549225 (659)\ttotal: 624ms\tremaining: 1.16s\n",
      "800:\tlearn: 9.8492167\ttest: 20.4325159\tbest: 20.4232665 (796)\ttotal: 866ms\tremaining: 1.29s\n",
      "900:\tlearn: 9.0357562\ttest: 20.4435674\tbest: 20.4232665 (796)\ttotal: 1.15s\tremaining: 1.4s\n",
      "1000:\tlearn: 8.3083523\ttest: 20.4407236\tbest: 20.4232665 (796)\ttotal: 1.37s\tremaining: 1.37s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.42326652\n",
      "bestIteration = 796\n",
      "\n",
      "Shrink model to first 797 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580308\ttest: 29.9242209\tbest: 29.9242209 (0)\ttotal: 2.93ms\tremaining: 5.85s\n",
      "100:\tlearn: 21.2416840\ttest: 22.2011702\tbest: 22.2011702 (100)\ttotal: 220ms\tremaining: 4.13s\n",
      "200:\tlearn: 18.2406546\ttest: 21.1924263\tbest: 21.1924263 (200)\ttotal: 516ms\tremaining: 4.62s\n",
      "300:\tlearn: 16.0053321\ttest: 20.6536119\tbest: 20.6536119 (300)\ttotal: 811ms\tremaining: 4.58s\n",
      "400:\tlearn: 14.3170253\ttest: 20.5523358\tbest: 20.5176409 (382)\ttotal: 1.05s\tremaining: 4.2s\n",
      "500:\tlearn: 12.9710555\ttest: 20.4789735\tbest: 20.4588707 (497)\ttotal: 1.3s\tremaining: 3.89s\n",
      "600:\tlearn: 11.7842276\ttest: 20.5063510\tbest: 20.4588707 (497)\ttotal: 1.59s\tremaining: 3.7s\n",
      "700:\tlearn: 10.7476519\ttest: 20.4870188\tbest: 20.4550170 (659)\ttotal: 1.9s\tremaining: 3.52s\n",
      "800:\tlearn: 9.8486056\ttest: 20.4326151\tbest: 20.4233668 (796)\ttotal: 2.02s\tremaining: 3.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\tlearn: 9.0469224\ttest: 20.4241156\tbest: 20.4233668 (796)\ttotal: 2.11s\tremaining: 2.58s\n",
      "1000:\tlearn: 8.3044740\ttest: 20.4063927\tbest: 20.4025116 (986)\ttotal: 2.23s\tremaining: 2.22s\n",
      "1100:\tlearn: 7.6573843\ttest: 20.3599102\tbest: 20.3599102 (1100)\ttotal: 2.32s\tremaining: 1.89s\n",
      "1200:\tlearn: 7.0708196\ttest: 20.3594414\tbest: 20.3351484 (1131)\ttotal: 2.42s\tremaining: 1.61s\n",
      "1300:\tlearn: 6.5260783\ttest: 20.3199973\tbest: 20.3099197 (1281)\ttotal: 2.5s\tremaining: 1.34s\n",
      "1400:\tlearn: 6.0187257\ttest: 20.3379409\tbest: 20.3099197 (1281)\ttotal: 2.62s\tremaining: 1.12s\n",
      "1500:\tlearn: 5.5791582\ttest: 20.3702934\tbest: 20.3099197 (1281)\ttotal: 2.71s\tremaining: 901ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30991968\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925604\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 704us\tremaining: 1.41s\n",
      "100:\tlearn: 22.3675457\ttest: 22.5593954\tbest: 22.5593954 (100)\ttotal: 64.8ms\tremaining: 1.22s\n",
      "200:\tlearn: 20.1453140\ttest: 21.5587633\tbest: 21.5587633 (200)\ttotal: 126ms\tremaining: 1.13s\n",
      "300:\tlearn: 18.3618963\ttest: 21.0831338\tbest: 21.0810016 (299)\ttotal: 191ms\tremaining: 1.08s\n",
      "400:\tlearn: 17.1156745\ttest: 20.9830192\tbest: 20.9452930 (373)\ttotal: 258ms\tremaining: 1.03s\n",
      "500:\tlearn: 15.9948319\ttest: 20.8726483\tbest: 20.8589234 (488)\ttotal: 320ms\tremaining: 957ms\n",
      "600:\tlearn: 15.0970418\ttest: 20.8733207\tbest: 20.8589234 (488)\ttotal: 382ms\tremaining: 888ms\n",
      "700:\tlearn: 14.3113649\ttest: 20.7384541\tbest: 20.7384541 (700)\ttotal: 454ms\tremaining: 841ms\n",
      "800:\tlearn: 13.5757355\ttest: 20.7028342\tbest: 20.7020320 (795)\ttotal: 519ms\tremaining: 777ms\n",
      "900:\tlearn: 12.9216364\ttest: 20.7051645\tbest: 20.6887369 (814)\ttotal: 582ms\tremaining: 710ms\n",
      "1000:\tlearn: 12.2715567\ttest: 20.7077798\tbest: 20.6887369 (814)\ttotal: 645ms\tremaining: 644ms\n",
      "1100:\tlearn: 11.6848743\ttest: 20.6270278\tbest: 20.6235102 (1097)\ttotal: 719ms\tremaining: 587ms\n",
      "1200:\tlearn: 11.1603720\ttest: 20.6004764\tbest: 20.5951443 (1198)\ttotal: 785ms\tremaining: 522ms\n",
      "1300:\tlearn: 10.6328748\ttest: 20.5625957\tbest: 20.5461787 (1281)\ttotal: 847ms\tremaining: 455ms\n",
      "1400:\tlearn: 10.1587919\ttest: 20.5569123\tbest: 20.5461787 (1281)\ttotal: 910ms\tremaining: 389ms\n",
      "1500:\tlearn: 9.7364880\ttest: 20.5220447\tbest: 20.5203489 (1493)\ttotal: 1.02s\tremaining: 338ms\n",
      "1600:\tlearn: 9.3205091\ttest: 20.5873990\tbest: 20.5203489 (1493)\ttotal: 1.21s\tremaining: 301ms\n",
      "1700:\tlearn: 8.9423852\ttest: 20.5625898\tbest: 20.5203489 (1493)\ttotal: 1.47s\tremaining: 259ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52034887\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580306\ttest: 29.9242207\tbest: 29.9242207 (0)\ttotal: 2.17ms\tremaining: 4.34s\n",
      "100:\tlearn: 21.2416703\ttest: 22.2011696\tbest: 22.2011696 (100)\ttotal: 252ms\tremaining: 4.74s\n",
      "200:\tlearn: 18.2406329\ttest: 21.1924272\tbest: 21.1924272 (200)\ttotal: 383ms\tremaining: 3.43s\n",
      "300:\tlearn: 16.0053067\ttest: 20.6536135\tbest: 20.6536135 (300)\ttotal: 472ms\tremaining: 2.66s\n",
      "400:\tlearn: 14.3169976\ttest: 20.5523397\tbest: 20.5176444 (382)\ttotal: 564ms\tremaining: 2.25s\n",
      "500:\tlearn: 12.9710267\ttest: 20.4789777\tbest: 20.4588748 (497)\ttotal: 649ms\tremaining: 1.94s\n",
      "600:\tlearn: 11.7841977\ttest: 20.5063553\tbest: 20.4588748 (497)\ttotal: 740ms\tremaining: 1.72s\n",
      "700:\tlearn: 10.7476216\ttest: 20.4870239\tbest: 20.4550216 (659)\ttotal: 832ms\tremaining: 1.54s\n",
      "800:\tlearn: 9.8485756\ttest: 20.4326200\tbest: 20.4233717 (796)\ttotal: 925ms\tremaining: 1.38s\n",
      "900:\tlearn: 9.0468929\ttest: 20.4241207\tbest: 20.4233717 (796)\ttotal: 1.02s\tremaining: 1.24s\n",
      "1000:\tlearn: 8.3044451\ttest: 20.4063981\tbest: 20.4025169 (986)\ttotal: 1.1s\tremaining: 1.1s\n",
      "1100:\tlearn: 7.6573562\ttest: 20.3599158\tbest: 20.3599158 (1100)\ttotal: 1.19s\tremaining: 971ms\n",
      "1200:\tlearn: 7.0707923\ttest: 20.3594473\tbest: 20.3351539 (1131)\ttotal: 1.28s\tremaining: 851ms\n",
      "1300:\tlearn: 6.5260518\ttest: 20.3200030\tbest: 20.3099254 (1281)\ttotal: 1.36s\tremaining: 733ms\n",
      "1400:\tlearn: 6.0187002\ttest: 20.3379468\tbest: 20.3099254 (1281)\ttotal: 1.45s\tremaining: 619ms\n",
      "1500:\tlearn: 5.5791337\ttest: 20.3702992\tbest: 20.3099254 (1281)\ttotal: 1.54s\tremaining: 513ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992538\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2982121\ttest: 29.8553020\tbest: 29.8553020 (0)\ttotal: 1.61ms\tremaining: 3.21s\n",
      "100:\tlearn: 19.8439842\ttest: 22.1427242\tbest: 22.1427242 (100)\ttotal: 121ms\tremaining: 2.27s\n",
      "200:\tlearn: 16.2154644\ttest: 21.2308084\tbest: 21.2308084 (200)\ttotal: 257ms\tremaining: 2.3s\n",
      "300:\tlearn: 13.3790509\ttest: 20.8159322\tbest: 20.8148630 (296)\ttotal: 467ms\tremaining: 2.63s\n",
      "400:\tlearn: 11.3703100\ttest: 20.7047352\tbest: 20.6839300 (347)\ttotal: 743ms\tremaining: 2.96s\n",
      "500:\tlearn: 9.7567929\ttest: 20.6349183\tbest: 20.5990642 (467)\ttotal: 1.08s\tremaining: 3.24s\n",
      "600:\tlearn: 8.3680528\ttest: 20.5645916\tbest: 20.5528683 (581)\ttotal: 1.37s\tremaining: 3.18s\n",
      "700:\tlearn: 7.2652896\ttest: 20.4913649\tbest: 20.4869385 (696)\ttotal: 1.77s\tremaining: 3.29s\n",
      "800:\tlearn: 6.2667740\ttest: 20.4568282\tbest: 20.4568282 (800)\ttotal: 2.15s\tremaining: 3.22s\n",
      "900:\tlearn: 5.4533397\ttest: 20.4792701\tbest: 20.4492742 (872)\ttotal: 2.35s\tremaining: 2.87s\n",
      "1000:\tlearn: 4.7565012\ttest: 20.5188592\tbest: 20.4492742 (872)\ttotal: 2.69s\tremaining: 2.69s\n",
      "1100:\tlearn: 4.1467262\ttest: 20.4939508\tbest: 20.4492742 (872)\ttotal: 2.82s\tremaining: 2.31s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.44927419\n",
      "bestIteration = 872\n",
      "\n",
      "Shrink model to first 873 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580323\ttest: 29.9242223\tbest: 29.9242223 (0)\ttotal: 1.12ms\tremaining: 2.24s\n",
      "100:\tlearn: 21.2417791\ttest: 22.2011741\tbest: 22.2011741 (100)\ttotal: 94.1ms\tremaining: 1.77s\n",
      "200:\tlearn: 18.2408043\ttest: 21.1924204\tbest: 21.1924204 (200)\ttotal: 297ms\tremaining: 2.66s\n",
      "300:\tlearn: 16.0055069\ttest: 20.6536003\tbest: 20.6536003 (300)\ttotal: 562ms\tremaining: 3.17s\n",
      "400:\tlearn: 14.3172162\ttest: 20.5523090\tbest: 20.5176173 (382)\ttotal: 801ms\tremaining: 3.19s\n",
      "500:\tlearn: 12.9712545\ttest: 20.4789443\tbest: 20.4588421 (497)\ttotal: 1.04s\tremaining: 3.13s\n",
      "600:\tlearn: 11.7844337\ttest: 20.5063213\tbest: 20.4588421 (497)\ttotal: 1.35s\tremaining: 3.15s\n",
      "700:\tlearn: 10.7478605\ttest: 20.4869835\tbest: 20.4549849 (659)\ttotal: 1.56s\tremaining: 2.88s\n",
      "800:\tlearn: 9.8488126\ttest: 20.4325815\tbest: 20.4233328 (796)\ttotal: 1.85s\tremaining: 2.77s\n",
      "900:\tlearn: 9.0471255\ttest: 20.4240802\tbest: 20.4233328 (796)\ttotal: 2.07s\tremaining: 2.53s\n",
      "1000:\tlearn: 8.3072050\ttest: 20.4082788\tbest: 20.4033781 (986)\ttotal: 2.39s\tremaining: 2.38s\n",
      "1100:\tlearn: 7.6549445\ttest: 20.3696325\tbest: 20.3696325 (1100)\ttotal: 2.69s\tremaining: 2.2s\n",
      "1200:\tlearn: 7.0657930\ttest: 20.3807634\tbest: 20.3547110 (1130)\ttotal: 2.93s\tremaining: 1.95s\n",
      "1300:\tlearn: 6.5151635\ttest: 20.3685462\tbest: 20.3547110 (1130)\ttotal: 3.25s\tremaining: 1.75s\n",
      "1400:\tlearn: 6.0005424\ttest: 20.3770749\tbest: 20.3547110 (1130)\ttotal: 3.46s\tremaining: 1.48s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35471095\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925633\ttest: 29.9282335\tbest: 29.9282335 (0)\ttotal: 1.17ms\tremaining: 2.34s\n",
      "100:\tlearn: 22.3677441\ttest: 22.5594353\tbest: 22.5594353 (100)\ttotal: 217ms\tremaining: 4.08s\n",
      "200:\tlearn: 20.1457287\ttest: 21.5587484\tbest: 21.5587484 (200)\ttotal: 382ms\tremaining: 3.42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\tlearn: 18.3624516\ttest: 21.0830587\tbest: 21.0809267 (299)\ttotal: 572ms\tremaining: 3.23s\n",
      "400:\tlearn: 17.1162642\ttest: 20.9829063\tbest: 20.9451865 (373)\ttotal: 730ms\tremaining: 2.91s\n",
      "500:\tlearn: 15.9954950\ttest: 20.8725114\tbest: 20.8587847 (488)\ttotal: 935ms\tremaining: 2.8s\n",
      "600:\tlearn: 15.0977335\ttest: 20.8731369\tbest: 20.8587847 (488)\ttotal: 1.12s\tremaining: 2.61s\n",
      "700:\tlearn: 14.3120654\ttest: 20.7382804\tbest: 20.7382804 (700)\ttotal: 1.25s\tremaining: 2.32s\n",
      "800:\tlearn: 13.5764383\ttest: 20.7026549\tbest: 20.7018521 (795)\ttotal: 1.46s\tremaining: 2.18s\n",
      "900:\tlearn: 12.9223619\ttest: 20.7049902\tbest: 20.6885513 (814)\ttotal: 1.59s\tremaining: 1.94s\n",
      "1000:\tlearn: 12.2617547\ttest: 20.7029721\tbest: 20.6885513 (814)\ttotal: 1.75s\tremaining: 1.75s\n",
      "1100:\tlearn: 11.6680588\ttest: 20.6547612\tbest: 20.6425694 (1087)\ttotal: 1.93s\tremaining: 1.57s\n",
      "1200:\tlearn: 11.1174175\ttest: 20.6467139\tbest: 20.6358995 (1195)\ttotal: 2.11s\tremaining: 1.4s\n",
      "1300:\tlearn: 10.6355013\ttest: 20.6495790\tbest: 20.6268533 (1281)\ttotal: 2.3s\tremaining: 1.24s\n",
      "1400:\tlearn: 10.1495901\ttest: 20.6642180\tbest: 20.6268533 (1281)\ttotal: 2.49s\tremaining: 1.06s\n",
      "1500:\tlearn: 9.7030209\ttest: 20.6709505\tbest: 20.6268533 (1281)\ttotal: 2.68s\tremaining: 892ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.62685331\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980298\ttest: 29.8551290\tbest: 29.8551290 (0)\ttotal: 4.23ms\tremaining: 8.46s\n",
      "100:\tlearn: 19.8959639\ttest: 22.1211359\tbest: 22.1211359 (100)\ttotal: 313ms\tremaining: 5.88s\n",
      "200:\tlearn: 16.1995995\ttest: 21.3561542\tbest: 21.3264662 (192)\ttotal: 468ms\tremaining: 4.19s\n",
      "300:\tlearn: 13.4260791\ttest: 21.0762938\tbest: 21.0462963 (265)\ttotal: 776ms\tremaining: 4.38s\n",
      "400:\tlearn: 11.3162247\ttest: 21.0785095\tbest: 21.0223332 (334)\ttotal: 911ms\tremaining: 3.63s\n",
      "500:\tlearn: 9.7091146\ttest: 21.0116272\tbest: 21.0111672 (499)\ttotal: 1.08s\tremaining: 3.24s\n",
      "600:\tlearn: 8.3246271\ttest: 20.9825230\tbest: 20.9804033 (598)\ttotal: 1.23s\tremaining: 2.86s\n",
      "700:\tlearn: 7.2180573\ttest: 20.9189821\tbest: 20.9167945 (698)\ttotal: 1.36s\tremaining: 2.53s\n",
      "800:\tlearn: 6.2174324\ttest: 20.9235306\tbest: 20.9090858 (751)\ttotal: 1.48s\tremaining: 2.22s\n",
      "900:\tlearn: 5.3895940\ttest: 20.9517058\tbest: 20.9090858 (751)\ttotal: 1.64s\tremaining: 1.99s\n",
      "1000:\tlearn: 4.7043280\ttest: 20.9313491\tbest: 20.9090858 (751)\ttotal: 1.76s\tremaining: 1.76s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90908583\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580304\ttest: 29.9242205\tbest: 29.9242205 (0)\ttotal: 957us\tremaining: 1.91s\n",
      "100:\tlearn: 21.2416601\ttest: 22.2011692\tbest: 22.2011692 (100)\ttotal: 85.7ms\tremaining: 1.61s\n",
      "200:\tlearn: 18.2406169\ttest: 21.1924278\tbest: 21.1924278 (200)\ttotal: 179ms\tremaining: 1.6s\n",
      "300:\tlearn: 16.0052881\ttest: 20.6536148\tbest: 20.6536148 (300)\ttotal: 283ms\tremaining: 1.6s\n",
      "400:\tlearn: 14.3169773\ttest: 20.5523426\tbest: 20.5176469 (382)\ttotal: 369ms\tremaining: 1.47s\n",
      "500:\tlearn: 12.9710055\ttest: 20.4789808\tbest: 20.4588779 (497)\ttotal: 460ms\tremaining: 1.38s\n",
      "600:\tlearn: 11.7841758\ttest: 20.5063584\tbest: 20.4588779 (497)\ttotal: 552ms\tremaining: 1.28s\n",
      "700:\tlearn: 10.7475994\ttest: 20.4870277\tbest: 20.4550250 (659)\ttotal: 637ms\tremaining: 1.18s\n",
      "800:\tlearn: 9.8485536\ttest: 20.4326236\tbest: 20.4233753 (796)\ttotal: 728ms\tremaining: 1.09s\n",
      "900:\tlearn: 9.0468713\ttest: 20.4241244\tbest: 20.4233753 (796)\ttotal: 819ms\tremaining: 999ms\n",
      "1000:\tlearn: 8.3044240\ttest: 20.4064020\tbest: 20.4025208 (986)\ttotal: 904ms\tremaining: 902ms\n",
      "1100:\tlearn: 7.6573356\ttest: 20.3599199\tbest: 20.3599199 (1100)\ttotal: 996ms\tremaining: 813ms\n",
      "1200:\tlearn: 7.0707723\ttest: 20.3594515\tbest: 20.3351580 (1131)\ttotal: 1.09s\tremaining: 723ms\n",
      "1300:\tlearn: 6.5260324\ttest: 20.3200072\tbest: 20.3099295 (1281)\ttotal: 1.17s\tremaining: 629ms\n",
      "1400:\tlearn: 6.0186815\ttest: 20.3379511\tbest: 20.3099295 (1281)\ttotal: 1.26s\tremaining: 540ms\n",
      "1500:\tlearn: 5.5791157\ttest: 20.3703035\tbest: 20.3099295 (1281)\ttotal: 1.35s\tremaining: 451ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992955\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925606\ttest: 29.9282315\tbest: 29.9282315 (0)\ttotal: 706us\tremaining: 1.41s\n",
      "100:\tlearn: 22.3675615\ttest: 22.5593986\tbest: 22.5593986 (100)\ttotal: 63.1ms\tremaining: 1.19s\n",
      "200:\tlearn: 20.1453471\ttest: 21.5587621\tbest: 21.5587621 (200)\ttotal: 125ms\tremaining: 1.11s\n",
      "300:\tlearn: 18.3619407\ttest: 21.0831278\tbest: 21.0809956 (299)\ttotal: 194ms\tremaining: 1.09s\n",
      "400:\tlearn: 17.1157216\ttest: 20.9830102\tbest: 20.9452845 (373)\ttotal: 268ms\tremaining: 1.07s\n",
      "500:\tlearn: 15.9948848\ttest: 20.8726374\tbest: 20.8589123 (488)\ttotal: 332ms\tremaining: 993ms\n",
      "600:\tlearn: 15.0970970\ttest: 20.8733060\tbest: 20.8589123 (488)\ttotal: 400ms\tremaining: 932ms\n",
      "700:\tlearn: 14.3114209\ttest: 20.7384402\tbest: 20.7384402 (700)\ttotal: 464ms\tremaining: 859ms\n",
      "800:\tlearn: 13.5757916\ttest: 20.7028199\tbest: 20.7020176 (795)\ttotal: 532ms\tremaining: 797ms\n",
      "900:\tlearn: 12.9216944\ttest: 20.7051506\tbest: 20.6887221 (814)\ttotal: 594ms\tremaining: 725ms\n",
      "1000:\tlearn: 12.2716139\ttest: 20.7077658\tbest: 20.6887221 (814)\ttotal: 657ms\tremaining: 656ms\n",
      "1100:\tlearn: 11.6849316\ttest: 20.6270134\tbest: 20.6234958 (1097)\ttotal: 790ms\tremaining: 645ms\n",
      "1200:\tlearn: 11.1604285\ttest: 20.6004623\tbest: 20.5951303 (1198)\ttotal: 1.01s\tremaining: 674ms\n",
      "1300:\tlearn: 10.6329310\ttest: 20.5625824\tbest: 20.5461654 (1281)\ttotal: 1.26s\tremaining: 678ms\n",
      "1400:\tlearn: 10.1588472\ttest: 20.5568985\tbest: 20.5461654 (1281)\ttotal: 1.47s\tremaining: 629ms\n",
      "1500:\tlearn: 9.7365435\ttest: 20.5220309\tbest: 20.5203352 (1493)\ttotal: 1.71s\tremaining: 569ms\n",
      "1600:\tlearn: 9.3205636\ttest: 20.5873851\tbest: 20.5203352 (1493)\ttotal: 1.94s\tremaining: 483ms\n",
      "1700:\tlearn: 8.9424389\ttest: 20.5625752\tbest: 20.5203352 (1493)\ttotal: 2.23s\tremaining: 391ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.5203352\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580308\ttest: 29.9242208\tbest: 29.9242208 (0)\ttotal: 1.71ms\tremaining: 3.42s\n",
      "100:\tlearn: 21.2416832\ttest: 22.2011702\tbest: 22.2011702 (100)\ttotal: 90.6ms\tremaining: 1.7s\n",
      "200:\tlearn: 18.2406533\ttest: 21.1924264\tbest: 21.1924264 (200)\ttotal: 176ms\tremaining: 1.57s\n",
      "300:\tlearn: 16.0053306\ttest: 20.6536120\tbest: 20.6536120 (300)\ttotal: 270ms\tremaining: 1.52s\n",
      "400:\tlearn: 14.3170236\ttest: 20.5523361\tbest: 20.5176412 (382)\ttotal: 359ms\tremaining: 1.43s\n",
      "500:\tlearn: 12.9710538\ttest: 20.4789737\tbest: 20.4588709 (497)\ttotal: 453ms\tremaining: 1.35s\n",
      "600:\tlearn: 11.7842258\ttest: 20.5063512\tbest: 20.4588709 (497)\ttotal: 576ms\tremaining: 1.34s\n",
      "700:\tlearn: 10.7476500\ttest: 20.4870191\tbest: 20.4550172 (659)\ttotal: 660ms\tremaining: 1.22s\n",
      "800:\tlearn: 9.8486038\ttest: 20.4326154\tbest: 20.4233671 (796)\ttotal: 744ms\tremaining: 1.11s\n",
      "900:\tlearn: 9.0469206\ttest: 20.4241159\tbest: 20.4233671 (796)\ttotal: 858ms\tremaining: 1.05s\n",
      "1000:\tlearn: 8.3044722\ttest: 20.4063931\tbest: 20.4025119 (986)\ttotal: 942ms\tremaining: 941ms\n",
      "1100:\tlearn: 7.6573826\ttest: 20.3599106\tbest: 20.3599106 (1100)\ttotal: 1.03s\tremaining: 839ms\n",
      "1200:\tlearn: 7.0708179\ttest: 20.3594418\tbest: 20.3351487 (1131)\ttotal: 1.12s\tremaining: 746ms\n",
      "1300:\tlearn: 6.5260768\ttest: 20.3199976\tbest: 20.3099200 (1281)\ttotal: 1.21s\tremaining: 649ms\n",
      "1400:\tlearn: 6.0187242\ttest: 20.3379413\tbest: 20.3099200 (1281)\ttotal: 1.29s\tremaining: 553ms\n",
      "1500:\tlearn: 5.5791568\ttest: 20.3702937\tbest: 20.3099200 (1281)\ttotal: 1.39s\tremaining: 461ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992003\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580547\ttest: 29.9242429\tbest: 29.9242429 (0)\ttotal: 917us\tremaining: 1.83s\n",
      "100:\tlearn: 21.2431827\ttest: 22.2012322\tbest: 22.2012322 (100)\ttotal: 87.3ms\tremaining: 1.64s\n",
      "200:\tlearn: 18.2430153\ttest: 21.1923340\tbest: 21.1923340 (200)\ttotal: 176ms\tremaining: 1.57s\n",
      "300:\tlearn: 16.0080892\ttest: 20.6534311\tbest: 20.6534311 (300)\ttotal: 273ms\tremaining: 1.54s\n",
      "400:\tlearn: 14.3266774\ttest: 20.5605254\tbest: 20.5242235 (382)\ttotal: 357ms\tremaining: 1.42s\n",
      "500:\tlearn: 13.0081314\ttest: 20.4606959\tbest: 20.4517839 (496)\ttotal: 446ms\tremaining: 1.33s\n",
      "600:\tlearn: 11.7893628\ttest: 20.5038377\tbest: 20.4517839 (496)\ttotal: 538ms\tremaining: 1.25s\n",
      "700:\tlearn: 10.7349237\ttest: 20.4260205\tbest: 20.4156610 (683)\ttotal: 622ms\tremaining: 1.15s\n",
      "800:\tlearn: 9.8455273\ttest: 20.3588524\tbest: 20.3588524 (800)\ttotal: 712ms\tremaining: 1.06s\n",
      "900:\tlearn: 9.0572109\ttest: 20.3494392\tbest: 20.3422274 (864)\ttotal: 801ms\tremaining: 977ms\n",
      "1000:\tlearn: 8.3263495\ttest: 20.3183697\tbest: 20.3105610 (988)\ttotal: 886ms\tremaining: 884ms\n",
      "1100:\tlearn: 7.6731802\ttest: 20.2948685\tbest: 20.2883444 (1080)\ttotal: 977ms\tremaining: 798ms\n",
      "1200:\tlearn: 7.0657142\ttest: 20.2865547\tbest: 20.2671122 (1139)\ttotal: 1.07s\tremaining: 710ms\n",
      "1300:\tlearn: 6.5345959\ttest: 20.3264883\tbest: 20.2671122 (1139)\ttotal: 1.15s\tremaining: 619ms\n",
      "1400:\tlearn: 6.0359202\ttest: 20.3266261\tbest: 20.2671122 (1139)\ttotal: 1.26s\tremaining: 541ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.26711223\n",
      "bestIteration = 1139\n",
      "\n",
      "Shrink model to first 1140 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980978\ttest: 29.8551935\tbest: 29.8551935 (0)\ttotal: 1.35ms\tremaining: 2.7s\n",
      "100:\tlearn: 19.8991744\ttest: 22.1213269\tbest: 22.1213269 (100)\ttotal: 128ms\tremaining: 2.4s\n",
      "200:\tlearn: 16.2045044\ttest: 21.3555842\tbest: 21.3260657 (192)\ttotal: 255ms\tremaining: 2.28s\n",
      "300:\tlearn: 13.4149470\ttest: 21.1495625\tbest: 21.1036692 (259)\ttotal: 379ms\tremaining: 2.14s\n",
      "400:\tlearn: 11.3136417\ttest: 21.0423813\tbest: 21.0373850 (398)\ttotal: 503ms\tremaining: 2s\n",
      "500:\tlearn: 9.6858996\ttest: 21.0001002\tbest: 20.9983421 (495)\ttotal: 627ms\tremaining: 1.88s\n",
      "600:\tlearn: 8.3009222\ttest: 20.9843686\tbest: 20.9799146 (598)\ttotal: 751ms\tremaining: 1.75s\n",
      "700:\tlearn: 7.1849108\ttest: 20.9732388\tbest: 20.9612064 (611)\ttotal: 875ms\tremaining: 1.62s\n",
      "800:\tlearn: 6.1972193\ttest: 20.9667885\tbest: 20.9474915 (768)\ttotal: 1s\tremaining: 1.5s\n",
      "900:\tlearn: 5.3683261\ttest: 20.9907538\tbest: 20.9474915 (768)\ttotal: 1.13s\tremaining: 1.37s\n",
      "1000:\tlearn: 4.6708601\ttest: 20.9729505\tbest: 20.9474915 (768)\ttotal: 1.25s\tremaining: 1.25s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.94749151\n",
      "bestIteration = 768\n",
      "\n",
      "Shrink model to first 769 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2998853\ttest: 29.8568834\tbest: 29.8568834 (0)\ttotal: 1.45ms\tremaining: 2.89s\n",
      "100:\tlearn: 19.9089245\ttest: 22.1046654\tbest: 22.1046654 (100)\ttotal: 126ms\tremaining: 2.38s\n",
      "200:\tlearn: 16.2955682\ttest: 21.2795125\tbest: 21.2747843 (199)\ttotal: 249ms\tremaining: 2.23s\n",
      "300:\tlearn: 13.5787309\ttest: 20.9510530\tbest: 20.9510530 (300)\ttotal: 373ms\tremaining: 2.1s\n",
      "400:\tlearn: 11.5003832\ttest: 20.9045920\tbest: 20.8932835 (341)\ttotal: 496ms\tremaining: 1.98s\n",
      "500:\tlearn: 9.8593595\ttest: 20.8255927\tbest: 20.8255927 (500)\ttotal: 621ms\tremaining: 1.86s\n",
      "600:\tlearn: 8.4909163\ttest: 20.7495829\tbest: 20.7460648 (599)\ttotal: 745ms\tremaining: 1.73s\n",
      "700:\tlearn: 7.3426023\ttest: 20.6979927\tbest: 20.6827703 (682)\ttotal: 895ms\tremaining: 1.66s\n",
      "800:\tlearn: 6.4130876\ttest: 20.6798232\tbest: 20.6576744 (791)\ttotal: 1.02s\tremaining: 1.52s\n",
      "900:\tlearn: 5.5957366\ttest: 20.6667973\tbest: 20.6549930 (873)\ttotal: 1.17s\tremaining: 1.42s\n",
      "1000:\tlearn: 4.8518769\ttest: 20.6957098\tbest: 20.6549930 (873)\ttotal: 1.32s\tremaining: 1.32s\n",
      "1100:\tlearn: 4.2383604\ttest: 20.6724112\tbest: 20.6549930 (873)\ttotal: 1.44s\tremaining: 1.18s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.65499302\n",
      "bestIteration = 873\n",
      "\n",
      "Shrink model to first 874 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3629095\ttest: 29.9285615\tbest: 29.9285615 (0)\ttotal: 997us\tremaining: 1.99s\n",
      "100:\tlearn: 21.4211062\ttest: 22.2649338\tbest: 22.2649338 (100)\ttotal: 93.2ms\tremaining: 1.75s\n",
      "200:\tlearn: 18.6042171\ttest: 21.2751788\tbest: 21.2751788 (200)\ttotal: 182ms\tremaining: 1.63s\n",
      "300:\tlearn: 16.4942589\ttest: 20.8202496\tbest: 20.8189566 (299)\ttotal: 272ms\tremaining: 1.53s\n",
      "400:\tlearn: 14.9151823\ttest: 20.7527417\tbest: 20.7152975 (371)\ttotal: 401ms\tremaining: 1.6s\n",
      "500:\tlearn: 13.5765833\ttest: 20.6479937\tbest: 20.6441892 (499)\ttotal: 497ms\tremaining: 1.49s\n",
      "600:\tlearn: 12.4157590\ttest: 20.6364865\tbest: 20.6267285 (584)\ttotal: 581ms\tremaining: 1.35s\n",
      "700:\tlearn: 11.3738873\ttest: 20.5639399\tbest: 20.5400807 (680)\ttotal: 671ms\tremaining: 1.24s\n",
      "800:\tlearn: 10.4882895\ttest: 20.5462157\tbest: 20.5293941 (756)\ttotal: 764ms\tremaining: 1.14s\n",
      "900:\tlearn: 9.6579895\ttest: 20.5738108\tbest: 20.5293941 (756)\ttotal: 849ms\tremaining: 1.03s\n",
      "1000:\tlearn: 8.9312760\ttest: 20.6091425\tbest: 20.5293941 (756)\ttotal: 939ms\tremaining: 937ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52939411\n",
      "bestIteration = 756\n",
      "\n",
      "Shrink model to first 757 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925603\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 881us\tremaining: 1.76s\n",
      "100:\tlearn: 22.3675408\ttest: 22.5593944\tbest: 22.5593944 (100)\ttotal: 71.6ms\tremaining: 1.35s\n",
      "200:\tlearn: 20.1453037\ttest: 21.5587637\tbest: 21.5587637 (200)\ttotal: 134ms\tremaining: 1.2s\n",
      "300:\tlearn: 18.3618826\ttest: 21.0831356\tbest: 21.0810035 (299)\ttotal: 201ms\tremaining: 1.14s\n",
      "400:\tlearn: 17.1156600\ttest: 20.9830220\tbest: 20.9452956 (373)\ttotal: 268ms\tremaining: 1.07s\n",
      "500:\tlearn: 15.9948155\ttest: 20.8726517\tbest: 20.8589268 (488)\ttotal: 338ms\tremaining: 1.01s\n",
      "600:\tlearn: 15.0970247\ttest: 20.8733252\tbest: 20.8589268 (488)\ttotal: 400ms\tremaining: 931ms\n",
      "700:\tlearn: 14.3113477\ttest: 20.7384584\tbest: 20.7384584 (700)\ttotal: 465ms\tremaining: 862ms\n",
      "800:\tlearn: 13.5757181\ttest: 20.7028386\tbest: 20.7020364 (795)\ttotal: 526ms\tremaining: 788ms\n",
      "900:\tlearn: 12.9216186\ttest: 20.7051688\tbest: 20.6887415 (814)\ttotal: 593ms\tremaining: 724ms\n",
      "1000:\tlearn: 12.2715390\ttest: 20.7077842\tbest: 20.6887415 (814)\ttotal: 661ms\tremaining: 660ms\n",
      "1100:\tlearn: 11.6848566\ttest: 20.6270322\tbest: 20.6235146 (1097)\ttotal: 723ms\tremaining: 590ms\n",
      "1200:\tlearn: 11.1603546\ttest: 20.6004807\tbest: 20.5951487 (1198)\ttotal: 784ms\tremaining: 522ms\n",
      "1300:\tlearn: 10.6328574\ttest: 20.5625998\tbest: 20.5461829 (1281)\ttotal: 851ms\tremaining: 457ms\n",
      "1400:\tlearn: 10.1587748\ttest: 20.5569165\tbest: 20.5461829 (1281)\ttotal: 919ms\tremaining: 393ms\n",
      "1500:\tlearn: 9.7364708\ttest: 20.5220490\tbest: 20.5203531 (1493)\ttotal: 980ms\tremaining: 326ms\n",
      "1600:\tlearn: 9.3204923\ttest: 20.5874032\tbest: 20.5203531 (1493)\ttotal: 1.04s\tremaining: 260ms\n",
      "1700:\tlearn: 8.9423686\ttest: 20.5625942\tbest: 20.5203531 (1493)\ttotal: 1.11s\tremaining: 195ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52035309\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3581262\ttest: 29.9243086\tbest: 29.9243086 (0)\ttotal: 1.14ms\tremaining: 2.29s\n",
      "100:\tlearn: 21.2476212\ttest: 22.2014245\tbest: 22.2014245 (100)\ttotal: 93.6ms\tremaining: 1.76s\n",
      "200:\tlearn: 18.2623734\ttest: 21.1948998\tbest: 21.1948998 (200)\ttotal: 182ms\tremaining: 1.63s\n",
      "300:\tlearn: 16.0844798\ttest: 20.7445696\tbest: 20.7445696 (300)\ttotal: 276ms\tremaining: 1.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400:\tlearn: 14.3928057\ttest: 20.6244725\tbest: 20.6123489 (393)\ttotal: 372ms\tremaining: 1.48s\n",
      "500:\tlearn: 13.0458553\ttest: 20.5586207\tbest: 20.5479479 (497)\ttotal: 462ms\tremaining: 1.38s\n",
      "600:\tlearn: 11.8391498\ttest: 20.5883436\tbest: 20.5479479 (497)\ttotal: 551ms\tremaining: 1.28s\n",
      "700:\tlearn: 10.8125316\ttest: 20.5578219\tbest: 20.5479479 (497)\ttotal: 640ms\tremaining: 1.19s\n",
      "800:\tlearn: 9.8924807\ttest: 20.4560395\tbest: 20.4551217 (797)\ttotal: 730ms\tremaining: 1.09s\n",
      "900:\tlearn: 9.0973394\ttest: 20.4540122\tbest: 20.4236680 (831)\ttotal: 829ms\tremaining: 1.01s\n",
      "1000:\tlearn: 8.3621717\ttest: 20.4276832\tbest: 20.4236680 (831)\ttotal: 947ms\tremaining: 945ms\n",
      "1100:\tlearn: 7.7055225\ttest: 20.4638955\tbest: 20.4236680 (831)\ttotal: 1.03s\tremaining: 844ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.42366797\n",
      "bestIteration = 831\n",
      "\n",
      "Shrink model to first 832 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980296\ttest: 29.8551288\tbest: 29.8551288 (0)\ttotal: 1.95ms\tremaining: 3.89s\n",
      "100:\tlearn: 19.8959540\ttest: 22.1211353\tbest: 22.1211353 (100)\ttotal: 125ms\tremaining: 2.36s\n",
      "200:\tlearn: 16.1995843\ttest: 21.3561560\tbest: 21.3264674 (192)\ttotal: 276ms\tremaining: 2.47s\n",
      "300:\tlearn: 13.4260622\ttest: 21.0762965\tbest: 21.0462983 (265)\ttotal: 394ms\tremaining: 2.23s\n",
      "400:\tlearn: 11.3162067\ttest: 21.0785128\tbest: 21.0223360 (334)\ttotal: 517ms\tremaining: 2.06s\n",
      "500:\tlearn: 9.7090965\ttest: 21.0116303\tbest: 21.0111703 (499)\ttotal: 635ms\tremaining: 1.9s\n",
      "600:\tlearn: 8.3246095\ttest: 20.9825265\tbest: 20.9804068 (598)\ttotal: 784ms\tremaining: 1.82s\n",
      "700:\tlearn: 7.2180403\ttest: 20.9189855\tbest: 20.9167980 (698)\ttotal: 902ms\tremaining: 1.67s\n",
      "800:\tlearn: 6.2174164\ttest: 20.9235342\tbest: 20.9090893 (751)\ttotal: 1.05s\tremaining: 1.58s\n",
      "900:\tlearn: 5.3895792\ttest: 20.9517094\tbest: 20.9090893 (751)\ttotal: 1.17s\tremaining: 1.43s\n",
      "1000:\tlearn: 4.7043142\ttest: 20.9313527\tbest: 20.9090893 (751)\ttotal: 1.29s\tremaining: 1.29s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90908934\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925653\ttest: 29.9282351\tbest: 29.9282351 (0)\ttotal: 758us\tremaining: 1.52s\n",
      "100:\tlearn: 22.3678793\ttest: 22.5594624\tbest: 22.5594624 (100)\ttotal: 62.6ms\tremaining: 1.18s\n",
      "200:\tlearn: 20.1460113\ttest: 21.5587383\tbest: 21.5587383 (200)\ttotal: 127ms\tremaining: 1.14s\n",
      "300:\tlearn: 18.3628300\ttest: 21.0830077\tbest: 21.0808758 (299)\ttotal: 188ms\tremaining: 1.06s\n",
      "400:\tlearn: 17.1166661\ttest: 20.9828294\tbest: 20.9451140 (373)\ttotal: 260ms\tremaining: 1.04s\n",
      "500:\tlearn: 15.9959470\ttest: 20.8724181\tbest: 20.8586902 (488)\ttotal: 326ms\tremaining: 976ms\n",
      "600:\tlearn: 15.0999110\ttest: 20.8834381\tbest: 20.8586902 (488)\ttotal: 424ms\tremaining: 987ms\n",
      "700:\tlearn: 14.3074468\ttest: 20.7731571\tbest: 20.7731571 (700)\ttotal: 489ms\tremaining: 906ms\n",
      "800:\tlearn: 13.5618465\ttest: 20.7525192\tbest: 20.7525192 (800)\ttotal: 556ms\tremaining: 832ms\n",
      "900:\tlearn: 12.9205922\ttest: 20.7122991\tbest: 20.7122991 (900)\ttotal: 618ms\tremaining: 754ms\n",
      "1000:\tlearn: 12.2486694\ttest: 20.7164290\tbest: 20.6965714 (943)\ttotal: 679ms\tremaining: 678ms\n",
      "1100:\tlearn: 11.6689539\ttest: 20.8015165\tbest: 20.6965714 (943)\ttotal: 745ms\tremaining: 609ms\n",
      "1200:\tlearn: 11.1391323\ttest: 20.8017257\tbest: 20.6965714 (943)\ttotal: 812ms\tremaining: 540ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.69657139\n",
      "bestIteration = 943\n",
      "\n",
      "Shrink model to first 944 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3582559\ttest: 29.9244276\tbest: 29.9244276 (0)\ttotal: 956us\tremaining: 1.91s\n",
      "100:\tlearn: 21.2555284\ttest: 22.2017986\tbest: 22.2017986 (100)\ttotal: 102ms\tremaining: 1.92s\n",
      "200:\tlearn: 18.2748405\ttest: 21.1944010\tbest: 21.1944010 (200)\ttotal: 191ms\tremaining: 1.71s\n",
      "300:\tlearn: 16.0523070\ttest: 20.7421497\tbest: 20.7421497 (300)\ttotal: 281ms\tremaining: 1.59s\n",
      "400:\tlearn: 14.3608510\ttest: 20.7070893\tbest: 20.6706938 (325)\ttotal: 371ms\tremaining: 1.48s\n",
      "500:\tlearn: 13.0175159\ttest: 20.6688252\tbest: 20.6405611 (457)\ttotal: 462ms\tremaining: 1.38s\n",
      "600:\tlearn: 11.8403444\ttest: 20.6906128\tbest: 20.6405611 (457)\ttotal: 553ms\tremaining: 1.29s\n",
      "700:\tlearn: 10.7966944\ttest: 20.6509017\tbest: 20.6405611 (457)\ttotal: 646ms\tremaining: 1.2s\n",
      "800:\tlearn: 9.9067471\ttest: 20.6489805\tbest: 20.6302615 (737)\ttotal: 752ms\tremaining: 1.12s\n",
      "900:\tlearn: 9.1193867\ttest: 20.6310853\tbest: 20.6246163 (897)\ttotal: 839ms\tremaining: 1.02s\n",
      "1000:\tlearn: 8.4068949\ttest: 20.5914467\tbest: 20.5877529 (995)\ttotal: 930ms\tremaining: 928ms\n",
      "1100:\tlearn: 7.7572901\ttest: 20.5865811\tbest: 20.5658749 (1073)\ttotal: 1.02s\tremaining: 833ms\n",
      "1200:\tlearn: 7.1534984\ttest: 20.5772729\tbest: 20.5658749 (1073)\ttotal: 1.1s\tremaining: 735ms\n",
      "1300:\tlearn: 6.6078593\ttest: 20.5624279\tbest: 20.5472833 (1283)\ttotal: 1.2s\tremaining: 642ms\n",
      "1400:\tlearn: 6.1043767\ttest: 20.5862450\tbest: 20.5472833 (1283)\ttotal: 1.29s\tremaining: 554ms\n",
      "1500:\tlearn: 5.6387482\ttest: 20.5976743\tbest: 20.5472833 (1283)\ttotal: 1.41s\tremaining: 468ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.54728329\n",
      "bestIteration = 1283\n",
      "\n",
      "Shrink model to first 1284 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580307\ttest: 29.9242208\tbest: 29.9242208 (0)\ttotal: 1.16ms\tremaining: 2.32s\n",
      "100:\tlearn: 21.2416769\ttest: 22.2011699\tbest: 22.2011699 (100)\ttotal: 91ms\tremaining: 1.71s\n",
      "200:\tlearn: 18.2406434\ttest: 21.1924268\tbest: 21.1924268 (200)\ttotal: 183ms\tremaining: 1.63s\n",
      "300:\tlearn: 16.0053190\ttest: 20.6536127\tbest: 20.6536127 (300)\ttotal: 272ms\tremaining: 1.54s\n",
      "400:\tlearn: 14.3170110\ttest: 20.5523378\tbest: 20.5176427 (382)\ttotal: 363ms\tremaining: 1.45s\n",
      "500:\tlearn: 12.9710407\ttest: 20.4789757\tbest: 20.4588728 (497)\ttotal: 453ms\tremaining: 1.36s\n",
      "600:\tlearn: 11.7842122\ttest: 20.5063532\tbest: 20.4588728 (497)\ttotal: 580ms\tremaining: 1.35s\n",
      "700:\tlearn: 10.7476363\ttest: 20.4870215\tbest: 20.4550193 (659)\ttotal: 671ms\tremaining: 1.24s\n",
      "800:\tlearn: 9.8485901\ttest: 20.4326177\tbest: 20.4233693 (796)\ttotal: 892ms\tremaining: 1.33s\n",
      "900:\tlearn: 9.0469072\ttest: 20.4241182\tbest: 20.4233693 (796)\ttotal: 1.05s\tremaining: 1.28s\n",
      "1000:\tlearn: 8.3044591\ttest: 20.4063955\tbest: 20.4025143 (986)\ttotal: 1.34s\tremaining: 1.33s\n",
      "1100:\tlearn: 7.6573698\ttest: 20.3599131\tbest: 20.3599131 (1100)\ttotal: 1.42s\tremaining: 1.16s\n",
      "1200:\tlearn: 7.0708055\ttest: 20.3594444\tbest: 20.3351512 (1131)\ttotal: 1.51s\tremaining: 1s\n",
      "1300:\tlearn: 6.5260647\ttest: 20.3200002\tbest: 20.3099226 (1281)\ttotal: 1.74s\tremaining: 934ms\n",
      "1400:\tlearn: 6.0187126\ttest: 20.3379440\tbest: 20.3099226 (1281)\ttotal: 1.83s\tremaining: 782ms\n",
      "1500:\tlearn: 5.5791456\ttest: 20.3702964\tbest: 20.3099226 (1281)\ttotal: 2.01s\tremaining: 670ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992262\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580304\ttest: 29.9242206\tbest: 29.9242206 (0)\ttotal: 1.92ms\tremaining: 3.84s\n",
      "100:\tlearn: 21.2416632\ttest: 22.2011694\tbest: 22.2011694 (100)\ttotal: 206ms\tremaining: 3.86s\n",
      "200:\tlearn: 18.2406217\ttest: 21.1924276\tbest: 21.1924276 (200)\ttotal: 455ms\tremaining: 4.07s\n",
      "300:\tlearn: 16.0052937\ttest: 20.6536144\tbest: 20.6536144 (300)\ttotal: 730ms\tremaining: 4.12s\n",
      "400:\tlearn: 14.3169834\ttest: 20.5523417\tbest: 20.5176461 (382)\ttotal: 1.02s\tremaining: 4.07s\n",
      "500:\tlearn: 12.9710118\ttest: 20.4789799\tbest: 20.4588770 (497)\ttotal: 1.21s\tremaining: 3.62s\n",
      "600:\tlearn: 11.7841824\ttest: 20.5063575\tbest: 20.4588770 (497)\ttotal: 1.33s\tremaining: 3.1s\n",
      "700:\tlearn: 10.7476060\ttest: 20.4870266\tbest: 20.4550240 (659)\ttotal: 1.42s\tremaining: 2.62s\n",
      "800:\tlearn: 9.8485602\ttest: 20.4326225\tbest: 20.4233742 (796)\ttotal: 1.5s\tremaining: 2.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\tlearn: 9.0468778\ttest: 20.4241233\tbest: 20.4233742 (796)\ttotal: 1.62s\tremaining: 1.98s\n",
      "1000:\tlearn: 8.3044303\ttest: 20.4064008\tbest: 20.4025196 (986)\ttotal: 1.71s\tremaining: 1.7s\n",
      "1100:\tlearn: 7.6573417\ttest: 20.3599186\tbest: 20.3599186 (1100)\ttotal: 1.81s\tremaining: 1.48s\n",
      "1200:\tlearn: 7.0707783\ttest: 20.3594503\tbest: 20.3351568 (1131)\ttotal: 1.98s\tremaining: 1.32s\n",
      "1300:\tlearn: 6.5260382\ttest: 20.3200059\tbest: 20.3099283 (1281)\ttotal: 2.21s\tremaining: 1.19s\n",
      "1400:\tlearn: 6.0186871\ttest: 20.3379498\tbest: 20.3099283 (1281)\ttotal: 2.4s\tremaining: 1.03s\n",
      "1500:\tlearn: 5.5791211\ttest: 20.3703022\tbest: 20.3099283 (1281)\ttotal: 2.64s\tremaining: 879ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.3099283\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580315\ttest: 29.9242215\tbest: 29.9242215 (0)\ttotal: 3.33ms\tremaining: 6.66s\n",
      "100:\tlearn: 21.2417294\ttest: 22.2011721\tbest: 22.2011721 (100)\ttotal: 215ms\tremaining: 4.04s\n",
      "200:\tlearn: 18.2407260\ttest: 21.1924235\tbest: 21.1924235 (200)\ttotal: 453ms\tremaining: 4.06s\n",
      "300:\tlearn: 16.0054155\ttest: 20.6536064\tbest: 20.6536064 (300)\ttotal: 714ms\tremaining: 4.03s\n",
      "400:\tlearn: 14.3171164\ttest: 20.5523230\tbest: 20.5176297 (382)\ttotal: 946ms\tremaining: 3.77s\n",
      "500:\tlearn: 12.9711505\ttest: 20.4789596\tbest: 20.4588571 (497)\ttotal: 1.23s\tremaining: 3.68s\n",
      "600:\tlearn: 11.7843260\ttest: 20.5063368\tbest: 20.4588571 (497)\ttotal: 1.38s\tremaining: 3.22s\n",
      "700:\tlearn: 10.7477514\ttest: 20.4870020\tbest: 20.4550017 (659)\ttotal: 1.53s\tremaining: 2.83s\n",
      "800:\tlearn: 9.8487044\ttest: 20.4325991\tbest: 20.4233506 (796)\ttotal: 1.62s\tremaining: 2.42s\n",
      "900:\tlearn: 9.0470193\ttest: 20.4240987\tbest: 20.4233506 (796)\ttotal: 1.7s\tremaining: 2.08s\n",
      "1000:\tlearn: 8.3071012\ttest: 20.4082981\tbest: 20.4033972 (986)\ttotal: 1.9s\tremaining: 1.89s\n",
      "1100:\tlearn: 7.6548438\ttest: 20.3696523\tbest: 20.3696523 (1100)\ttotal: 2.21s\tremaining: 1.8s\n",
      "1200:\tlearn: 7.0656949\ttest: 20.3807836\tbest: 20.3547314 (1130)\ttotal: 2.67s\tremaining: 1.77s\n",
      "1300:\tlearn: 6.5097583\ttest: 20.3738065\tbest: 20.3547314 (1130)\ttotal: 2.94s\tremaining: 1.58s\n",
      "1400:\tlearn: 6.0131967\ttest: 20.3719250\tbest: 20.3547314 (1130)\ttotal: 3.16s\tremaining: 1.35s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35473139\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980371\ttest: 29.8551359\tbest: 29.8551359 (0)\ttotal: 1.96ms\tremaining: 3.92s\n",
      "100:\tlearn: 19.8963094\ttest: 22.1211563\tbest: 22.1211563 (100)\ttotal: 413ms\tremaining: 7.76s\n",
      "200:\tlearn: 16.2001271\ttest: 21.3560926\tbest: 21.3264229 (192)\ttotal: 780ms\tremaining: 6.98s\n",
      "300:\tlearn: 13.4162248\ttest: 21.1418634\tbest: 21.1042801 (259)\ttotal: 1.16s\tremaining: 6.53s\n",
      "400:\tlearn: 11.3001775\ttest: 21.0557023\tbest: 21.0477352 (393)\ttotal: 1.34s\tremaining: 5.35s\n",
      "500:\tlearn: 9.6764459\ttest: 21.0155103\tbest: 21.0063758 (464)\ttotal: 1.5s\tremaining: 4.48s\n",
      "600:\tlearn: 8.3289674\ttest: 20.9792939\tbest: 20.9593549 (545)\ttotal: 1.62s\tremaining: 3.77s\n",
      "700:\tlearn: 7.2204624\ttest: 20.9415668\tbest: 20.9230464 (685)\ttotal: 1.75s\tremaining: 3.24s\n",
      "800:\tlearn: 6.2537358\ttest: 20.9402060\tbest: 20.9080787 (782)\ttotal: 1.87s\tremaining: 2.79s\n",
      "900:\tlearn: 5.4228219\ttest: 20.9235301\tbest: 20.9080787 (782)\ttotal: 2.02s\tremaining: 2.46s\n",
      "1000:\tlearn: 4.7224630\ttest: 20.9383703\tbest: 20.9080787 (782)\ttotal: 2.14s\tremaining: 2.14s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90807866\n",
      "bestIteration = 782\n",
      "\n",
      "Shrink model to first 783 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580305\ttest: 29.9242206\tbest: 29.9242206 (0)\ttotal: 932us\tremaining: 1.86s\n",
      "100:\tlearn: 21.2416644\ttest: 22.2011694\tbest: 22.2011694 (100)\ttotal: 237ms\tremaining: 4.46s\n",
      "200:\tlearn: 18.2406237\ttest: 21.1924276\tbest: 21.1924276 (200)\ttotal: 586ms\tremaining: 5.25s\n",
      "300:\tlearn: 16.0052960\ttest: 20.6536143\tbest: 20.6536143 (300)\ttotal: 1.02s\tremaining: 5.74s\n",
      "400:\tlearn: 14.3169859\ttest: 20.5523414\tbest: 20.5176458 (382)\ttotal: 1.41s\tremaining: 5.62s\n",
      "500:\tlearn: 12.9710145\ttest: 20.4789795\tbest: 20.4588766 (497)\ttotal: 1.5s\tremaining: 4.48s\n",
      "600:\tlearn: 11.7841851\ttest: 20.5063571\tbest: 20.4588766 (497)\ttotal: 1.65s\tremaining: 3.84s\n",
      "700:\tlearn: 10.7476088\ttest: 20.4870261\tbest: 20.4550236 (659)\ttotal: 1.93s\tremaining: 3.58s\n",
      "800:\tlearn: 9.8485629\ttest: 20.4326221\tbest: 20.4233738 (796)\ttotal: 2.24s\tremaining: 3.35s\n",
      "900:\tlearn: 9.0468805\ttest: 20.4241229\tbest: 20.4233738 (796)\ttotal: 2.45s\tremaining: 2.99s\n",
      "1000:\tlearn: 8.3044329\ttest: 20.4064003\tbest: 20.4025191 (986)\ttotal: 2.84s\tremaining: 2.84s\n",
      "1100:\tlearn: 7.6573443\ttest: 20.3599181\tbest: 20.3599181 (1100)\ttotal: 3.17s\tremaining: 2.59s\n",
      "1200:\tlearn: 7.0707807\ttest: 20.3594497\tbest: 20.3351563 (1131)\ttotal: 3.49s\tremaining: 2.32s\n",
      "1300:\tlearn: 6.5260406\ttest: 20.3200054\tbest: 20.3099278 (1281)\ttotal: 3.7s\tremaining: 1.99s\n",
      "1400:\tlearn: 6.0186894\ttest: 20.3379493\tbest: 20.3099278 (1281)\ttotal: 4.01s\tremaining: 1.71s\n",
      "1500:\tlearn: 5.5791233\ttest: 20.3703017\tbest: 20.3099278 (1281)\ttotal: 4.26s\tremaining: 1.42s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992779\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925603\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 906us\tremaining: 1.81s\n",
      "100:\tlearn: 22.3675410\ttest: 22.5593945\tbest: 22.5593945 (100)\ttotal: 67.2ms\tremaining: 1.26s\n",
      "200:\tlearn: 20.1453041\ttest: 21.5587637\tbest: 21.5587637 (200)\ttotal: 135ms\tremaining: 1.21s\n",
      "300:\tlearn: 18.3618832\ttest: 21.0831355\tbest: 21.0810034 (299)\ttotal: 260ms\tremaining: 1.47s\n",
      "400:\tlearn: 17.1156605\ttest: 20.9830219\tbest: 20.9452955 (373)\ttotal: 329ms\tremaining: 1.31s\n",
      "500:\tlearn: 15.9948161\ttest: 20.8726516\tbest: 20.8589267 (488)\ttotal: 420ms\tremaining: 1.26s\n",
      "600:\tlearn: 15.0970254\ttest: 20.8733251\tbest: 20.8589267 (488)\ttotal: 523ms\tremaining: 1.22s\n",
      "700:\tlearn: 14.3113483\ttest: 20.7384582\tbest: 20.7384582 (700)\ttotal: 680ms\tremaining: 1.26s\n",
      "800:\tlearn: 13.5757188\ttest: 20.7028385\tbest: 20.7020362 (795)\ttotal: 875ms\tremaining: 1.31s\n",
      "900:\tlearn: 12.9216192\ttest: 20.7051686\tbest: 20.6887413 (814)\ttotal: 1.07s\tremaining: 1.3s\n",
      "1000:\tlearn: 12.2715396\ttest: 20.7077840\tbest: 20.6887413 (814)\ttotal: 1.28s\tremaining: 1.28s\n",
      "1100:\tlearn: 11.6848573\ttest: 20.6270320\tbest: 20.6235145 (1097)\ttotal: 1.5s\tremaining: 1.23s\n",
      "1200:\tlearn: 11.1603552\ttest: 20.6004806\tbest: 20.5951485 (1198)\ttotal: 1.74s\tremaining: 1.15s\n",
      "1300:\tlearn: 10.6328581\ttest: 20.5625997\tbest: 20.5461827 (1281)\ttotal: 1.89s\tremaining: 1.01s\n",
      "1400:\tlearn: 10.1587755\ttest: 20.5569164\tbest: 20.5461827 (1281)\ttotal: 1.98s\tremaining: 844ms\n",
      "1500:\tlearn: 9.7364715\ttest: 20.5220488\tbest: 20.5203529 (1493)\ttotal: 2.04s\tremaining: 680ms\n",
      "1600:\tlearn: 9.3204929\ttest: 20.5874031\tbest: 20.5203529 (1493)\ttotal: 2.11s\tremaining: 525ms\n",
      "1700:\tlearn: 8.9423692\ttest: 20.5625941\tbest: 20.5203529 (1493)\ttotal: 2.17s\tremaining: 381ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52035293\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2786427\ttest: 29.8766792\tbest: 29.8766792 (0)\ttotal: 1.83ms\tremaining: 3.67s\n",
      "100:\tlearn: 18.0446549\ttest: 22.0327576\tbest: 22.0327576 (100)\ttotal: 212ms\tremaining: 3.99s\n",
      "200:\tlearn: 13.6670978\ttest: 21.0770597\tbest: 21.0770597 (200)\ttotal: 387ms\tremaining: 3.46s\n",
      "300:\tlearn: 10.4226345\ttest: 20.8034012\tbest: 20.8034012 (300)\ttotal: 578ms\tremaining: 3.26s\n",
      "400:\tlearn: 8.1103634\ttest: 20.6589650\tbest: 20.6589650 (400)\ttotal: 753ms\tremaining: 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500:\tlearn: 6.3496552\ttest: 20.6569917\tbest: 20.6306513 (428)\ttotal: 963ms\tremaining: 2.88s\n",
      "600:\tlearn: 4.9842417\ttest: 20.5811464\tbest: 20.5784611 (597)\ttotal: 1.15s\tremaining: 2.67s\n",
      "700:\tlearn: 3.9610343\ttest: 20.6067847\tbest: 20.5635633 (611)\ttotal: 1.35s\tremaining: 2.5s\n",
      "800:\tlearn: 3.1327333\ttest: 20.5934448\tbest: 20.5635633 (611)\ttotal: 1.52s\tremaining: 2.28s\n",
      "900:\tlearn: 2.5087935\ttest: 20.5718248\tbest: 20.5635633 (611)\ttotal: 1.71s\tremaining: 2.08s\n",
      "1000:\tlearn: 1.9875604\ttest: 20.5489712\tbest: 20.5460853 (998)\ttotal: 1.88s\tremaining: 1.87s\n",
      "1100:\tlearn: 1.5962355\ttest: 20.5403162\tbest: 20.5399287 (1092)\ttotal: 2.07s\tremaining: 1.69s\n",
      "1200:\tlearn: 1.2704613\ttest: 20.5371131\tbest: 20.5348560 (1134)\ttotal: 2.24s\tremaining: 1.49s\n",
      "1300:\tlearn: 1.0166161\ttest: 20.5350196\tbest: 20.5332698 (1290)\ttotal: 2.47s\tremaining: 1.33s\n",
      "1400:\tlearn: 0.8233849\ttest: 20.5351510\tbest: 20.5308834 (1343)\ttotal: 2.64s\tremaining: 1.13s\n",
      "1500:\tlearn: 0.6646164\ttest: 20.5351856\tbest: 20.5308834 (1343)\ttotal: 2.82s\tremaining: 938ms\n",
      "1600:\tlearn: 0.5352394\ttest: 20.5308363\tbest: 20.5291542 (1589)\ttotal: 3s\tremaining: 747ms\n",
      "1700:\tlearn: 0.4328113\ttest: 20.5313949\tbest: 20.5291542 (1589)\ttotal: 3.23s\tremaining: 568ms\n",
      "1800:\tlearn: 0.3489399\ttest: 20.5313936\tbest: 20.5291542 (1589)\ttotal: 3.59s\tremaining: 396ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52915417\n",
      "bestIteration = 1589\n",
      "\n",
      "Shrink model to first 1590 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580311\ttest: 29.9242211\tbest: 29.9242211 (0)\ttotal: 2.95ms\tremaining: 5.89s\n",
      "100:\tlearn: 21.2417017\ttest: 22.2011709\tbest: 22.2011709 (100)\ttotal: 285ms\tremaining: 5.36s\n",
      "200:\tlearn: 18.2406824\ttest: 21.1924252\tbest: 21.1924252 (200)\ttotal: 648ms\tremaining: 5.8s\n",
      "300:\tlearn: 16.0053646\ttest: 20.6536097\tbest: 20.6536097 (300)\ttotal: 1.26s\tremaining: 7.1s\n",
      "400:\tlearn: 14.3170608\ttest: 20.5523309\tbest: 20.5176365 (382)\ttotal: 1.37s\tremaining: 5.48s\n",
      "500:\tlearn: 12.9710925\ttest: 20.4789681\tbest: 20.4588654 (497)\ttotal: 1.59s\tremaining: 4.76s\n",
      "600:\tlearn: 11.7842659\ttest: 20.5063455\tbest: 20.4588654 (497)\ttotal: 2s\tremaining: 4.64s\n",
      "700:\tlearn: 10.7476907\ttest: 20.4870123\tbest: 20.4550110 (659)\ttotal: 2.33s\tremaining: 4.32s\n",
      "800:\tlearn: 9.8486441\ttest: 20.4326089\tbest: 20.4233605 (796)\ttotal: 2.63s\tremaining: 3.94s\n",
      "900:\tlearn: 9.0469602\ttest: 20.4241090\tbest: 20.4233605 (796)\ttotal: 2.94s\tremaining: 3.58s\n",
      "1000:\tlearn: 8.3070433\ttest: 20.4083088\tbest: 20.4034079 (986)\ttotal: 3.28s\tremaining: 3.27s\n",
      "1100:\tlearn: 7.6547877\ttest: 20.3696634\tbest: 20.3696634 (1100)\ttotal: 3.55s\tremaining: 2.9s\n",
      "1200:\tlearn: 7.0656403\ttest: 20.3807949\tbest: 20.3547428 (1130)\ttotal: 3.71s\tremaining: 2.47s\n",
      "1300:\tlearn: 6.5097062\ttest: 20.3738172\tbest: 20.3547428 (1130)\ttotal: 3.83s\tremaining: 2.06s\n",
      "1400:\tlearn: 6.0131466\ttest: 20.3719356\tbest: 20.3547428 (1130)\ttotal: 3.92s\tremaining: 1.67s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35474277\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580304\ttest: 29.9242205\tbest: 29.9242205 (0)\ttotal: 968us\tremaining: 1.94s\n",
      "100:\tlearn: 21.2416614\ttest: 22.2011693\tbest: 22.2011693 (100)\ttotal: 85.5ms\tremaining: 1.61s\n",
      "200:\tlearn: 18.2406189\ttest: 21.1924278\tbest: 21.1924278 (200)\ttotal: 176ms\tremaining: 1.58s\n",
      "300:\tlearn: 16.0052904\ttest: 20.6536146\tbest: 20.6536146 (300)\ttotal: 269ms\tremaining: 1.52s\n",
      "400:\tlearn: 14.3169798\ttest: 20.5523422\tbest: 20.5176466 (382)\ttotal: 360ms\tremaining: 1.44s\n",
      "500:\tlearn: 12.9710081\ttest: 20.4789804\tbest: 20.4588775 (497)\ttotal: 624ms\tremaining: 1.87s\n",
      "600:\tlearn: 11.7841785\ttest: 20.5063580\tbest: 20.4588775 (497)\ttotal: 818ms\tremaining: 1.9s\n",
      "700:\tlearn: 10.7476022\ttest: 20.4870272\tbest: 20.4550246 (659)\ttotal: 954ms\tremaining: 1.77s\n",
      "800:\tlearn: 9.8485563\ttest: 20.4326232\tbest: 20.4233749 (796)\ttotal: 1.24s\tremaining: 1.85s\n",
      "900:\tlearn: 9.0468740\ttest: 20.4241240\tbest: 20.4233749 (796)\ttotal: 1.46s\tremaining: 1.78s\n",
      "1000:\tlearn: 8.3044266\ttest: 20.4064015\tbest: 20.4025203 (986)\ttotal: 1.56s\tremaining: 1.56s\n",
      "1100:\tlearn: 7.6573381\ttest: 20.3599193\tbest: 20.3599193 (1100)\ttotal: 1.65s\tremaining: 1.34s\n",
      "1200:\tlearn: 7.0707748\ttest: 20.3594510\tbest: 20.3351575 (1131)\ttotal: 1.74s\tremaining: 1.16s\n",
      "1300:\tlearn: 6.5260348\ttest: 20.3200066\tbest: 20.3099290 (1281)\ttotal: 1.82s\tremaining: 980ms\n",
      "1400:\tlearn: 6.0186838\ttest: 20.3379506\tbest: 20.3099290 (1281)\ttotal: 1.92s\tremaining: 819ms\n",
      "1500:\tlearn: 5.5791180\ttest: 20.3703030\tbest: 20.3099290 (1281)\ttotal: 2.01s\tremaining: 667ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992903\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580357\ttest: 29.9242254\tbest: 29.9242254 (0)\ttotal: 1.46ms\tremaining: 2.92s\n",
      "100:\tlearn: 21.2419944\ttest: 22.2011829\tbest: 22.2011829 (100)\ttotal: 418ms\tremaining: 7.86s\n",
      "200:\tlearn: 18.2411433\ttest: 21.1924071\tbest: 21.1924071 (200)\ttotal: 709ms\tremaining: 6.34s\n",
      "300:\tlearn: 16.0059028\ttest: 20.6535743\tbest: 20.6535743 (300)\ttotal: 1.15s\tremaining: 6.47s\n",
      "400:\tlearn: 14.3176484\ttest: 20.5522483\tbest: 20.5175638 (382)\ttotal: 1.44s\tremaining: 5.72s\n",
      "500:\tlearn: 12.9717050\ttest: 20.4788783\tbest: 20.4587775 (497)\ttotal: 1.52s\tremaining: 4.55s\n",
      "600:\tlearn: 11.7849003\ttest: 20.5062541\tbest: 20.4587775 (497)\ttotal: 1.61s\tremaining: 3.74s\n",
      "700:\tlearn: 10.7483330\ttest: 20.4869037\tbest: 20.4549125 (659)\ttotal: 1.73s\tremaining: 3.21s\n",
      "800:\tlearn: 9.8492813\ttest: 20.4325054\tbest: 20.4232559 (796)\ttotal: 1.84s\tremaining: 2.76s\n",
      "900:\tlearn: 9.0358207\ttest: 20.4435566\tbest: 20.4232559 (796)\ttotal: 1.97s\tremaining: 2.4s\n",
      "1000:\tlearn: 8.3084152\ttest: 20.4407125\tbest: 20.4232559 (796)\ttotal: 2.27s\tremaining: 2.27s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.42325592\n",
      "bestIteration = 796\n",
      "\n",
      "Shrink model to first 797 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580307\ttest: 29.9242208\tbest: 29.9242208 (0)\ttotal: 968us\tremaining: 1.94s\n",
      "100:\tlearn: 21.2416773\ttest: 22.2011699\tbest: 22.2011699 (100)\ttotal: 166ms\tremaining: 3.12s\n",
      "200:\tlearn: 18.2406440\ttest: 21.1924268\tbest: 21.1924268 (200)\ttotal: 410ms\tremaining: 3.67s\n",
      "300:\tlearn: 16.0053197\ttest: 20.6536127\tbest: 20.6536127 (300)\ttotal: 687ms\tremaining: 3.88s\n",
      "400:\tlearn: 14.3170118\ttest: 20.5523377\tbest: 20.5176426 (382)\ttotal: 850ms\tremaining: 3.39s\n",
      "500:\tlearn: 12.9710415\ttest: 20.4789755\tbest: 20.4588727 (497)\ttotal: 940ms\tremaining: 2.81s\n",
      "600:\tlearn: 11.7842131\ttest: 20.5063531\tbest: 20.4588727 (497)\ttotal: 1.02s\tremaining: 2.38s\n",
      "700:\tlearn: 10.7476371\ttest: 20.4870213\tbest: 20.4550192 (659)\ttotal: 1.11s\tremaining: 2.06s\n",
      "800:\tlearn: 9.8485910\ttest: 20.4326175\tbest: 20.4233692 (796)\ttotal: 1.23s\tremaining: 1.84s\n",
      "900:\tlearn: 9.0469080\ttest: 20.4241181\tbest: 20.4233692 (796)\ttotal: 1.31s\tremaining: 1.6s\n",
      "1000:\tlearn: 8.3044599\ttest: 20.4063953\tbest: 20.4025142 (986)\ttotal: 1.4s\tremaining: 1.4s\n",
      "1100:\tlearn: 7.6573706\ttest: 20.3599129\tbest: 20.3599129 (1100)\ttotal: 1.49s\tremaining: 1.22s\n",
      "1200:\tlearn: 7.0708063\ttest: 20.3594443\tbest: 20.3351511 (1131)\ttotal: 1.58s\tremaining: 1.05s\n",
      "1300:\tlearn: 6.5260654\ttest: 20.3200001\tbest: 20.3099225 (1281)\ttotal: 1.76s\tremaining: 949ms\n",
      "1400:\tlearn: 6.0187133\ttest: 20.3379438\tbest: 20.3099225 (1281)\ttotal: 1.94s\tremaining: 831ms\n",
      "1500:\tlearn: 5.5791463\ttest: 20.3702962\tbest: 20.3099225 (1281)\ttotal: 2.25s\tremaining: 749ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992246\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580307\ttest: 29.9242208\tbest: 29.9242208 (0)\ttotal: 3.21ms\tremaining: 6.42s\n",
      "100:\tlearn: 21.2416787\ttest: 22.2011700\tbest: 22.2011700 (100)\ttotal: 260ms\tremaining: 4.88s\n",
      "200:\tlearn: 18.2406462\ttest: 21.1924267\tbest: 21.1924267 (200)\ttotal: 344ms\tremaining: 3.08s\n",
      "300:\tlearn: 16.0053222\ttest: 20.6536125\tbest: 20.6536125 (300)\ttotal: 428ms\tremaining: 2.42s\n",
      "400:\tlearn: 14.3170145\ttest: 20.5523374\tbest: 20.5176423 (382)\ttotal: 522ms\tremaining: 2.08s\n",
      "500:\tlearn: 12.9710443\ttest: 20.4789751\tbest: 20.4588723 (497)\ttotal: 607ms\tremaining: 1.81s\n",
      "600:\tlearn: 11.7842160\ttest: 20.5063526\tbest: 20.4588723 (497)\ttotal: 692ms\tremaining: 1.61s\n",
      "700:\tlearn: 10.7476401\ttest: 20.4870208\tbest: 20.4550188 (659)\ttotal: 782ms\tremaining: 1.45s\n",
      "800:\tlearn: 9.8485939\ttest: 20.4326170\tbest: 20.4233687 (796)\ttotal: 868ms\tremaining: 1.3s\n",
      "900:\tlearn: 9.0469110\ttest: 20.4241175\tbest: 20.4233687 (796)\ttotal: 952ms\tremaining: 1.16s\n",
      "1000:\tlearn: 8.3044628\ttest: 20.4063948\tbest: 20.4025136 (986)\ttotal: 1.04s\tremaining: 1.04s\n",
      "1100:\tlearn: 7.6573734\ttest: 20.3599124\tbest: 20.3599124 (1100)\ttotal: 1.13s\tremaining: 923ms\n",
      "1200:\tlearn: 7.0708090\ttest: 20.3594437\tbest: 20.3351505 (1131)\ttotal: 1.22s\tremaining: 810ms\n",
      "1300:\tlearn: 6.5260680\ttest: 20.3199995\tbest: 20.3099219 (1281)\ttotal: 1.31s\tremaining: 703ms\n",
      "1400:\tlearn: 6.0187158\ttest: 20.3379432\tbest: 20.3099219 (1281)\ttotal: 1.4s\tremaining: 597ms\n",
      "1500:\tlearn: 5.5791487\ttest: 20.3702956\tbest: 20.3099219 (1281)\ttotal: 1.48s\tremaining: 492ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992189\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980332\ttest: 29.8551323\tbest: 29.8551323 (0)\ttotal: 1.61ms\tremaining: 3.22s\n",
      "100:\tlearn: 19.8961253\ttest: 22.1211454\tbest: 22.1211454 (100)\ttotal: 140ms\tremaining: 2.63s\n",
      "200:\tlearn: 16.1998460\ttest: 21.3561254\tbest: 21.3264459 (192)\ttotal: 262ms\tremaining: 2.34s\n",
      "300:\tlearn: 13.4159108\ttest: 21.1419098\tbest: 21.1043195 (259)\ttotal: 384ms\tremaining: 2.17s\n",
      "400:\tlearn: 11.2998425\ttest: 21.0557634\tbest: 21.0477936 (393)\ttotal: 509ms\tremaining: 2.03s\n",
      "500:\tlearn: 9.6761061\ttest: 21.0155657\tbest: 21.0064311 (464)\ttotal: 636ms\tremaining: 1.9s\n",
      "600:\tlearn: 8.3286380\ttest: 20.9793560\tbest: 20.9594154 (545)\ttotal: 761ms\tremaining: 1.77s\n",
      "700:\tlearn: 7.2201492\ttest: 20.9416319\tbest: 20.9231093 (685)\ttotal: 888ms\tremaining: 1.65s\n",
      "800:\tlearn: 6.2534372\ttest: 20.9402754\tbest: 20.9081467 (782)\ttotal: 1.13s\tremaining: 1.69s\n",
      "900:\tlearn: 5.4225451\ttest: 20.9236057\tbest: 20.9081467 (782)\ttotal: 1.38s\tremaining: 1.68s\n",
      "1000:\tlearn: 4.7222081\ttest: 20.9384450\tbest: 20.9081467 (782)\ttotal: 1.75s\tremaining: 1.75s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90814666\n",
      "bestIteration = 782\n",
      "\n",
      "Shrink model to first 783 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580308\ttest: 29.9242209\tbest: 29.9242209 (0)\ttotal: 1.16ms\tremaining: 2.32s\n",
      "100:\tlearn: 21.2416851\ttest: 22.2011703\tbest: 22.2011703 (100)\ttotal: 98.2ms\tremaining: 1.84s\n",
      "200:\tlearn: 18.2406563\ttest: 21.1924263\tbest: 21.1924263 (200)\ttotal: 191ms\tremaining: 1.71s\n",
      "300:\tlearn: 16.0053341\ttest: 20.6536117\tbest: 20.6536117 (300)\ttotal: 282ms\tremaining: 1.59s\n",
      "400:\tlearn: 14.3170275\ttest: 20.5523355\tbest: 20.5176407 (382)\ttotal: 367ms\tremaining: 1.46s\n",
      "500:\tlearn: 12.9710578\ttest: 20.4789731\tbest: 20.4588704 (497)\ttotal: 456ms\tremaining: 1.36s\n",
      "600:\tlearn: 11.7842300\ttest: 20.5063506\tbest: 20.4588704 (497)\ttotal: 546ms\tremaining: 1.27s\n",
      "700:\tlearn: 10.7476543\ttest: 20.4870184\tbest: 20.4550166 (659)\ttotal: 632ms\tremaining: 1.17s\n",
      "800:\tlearn: 9.8486080\ttest: 20.4326148\tbest: 20.4233664 (796)\ttotal: 722ms\tremaining: 1.08s\n",
      "900:\tlearn: 9.0469247\ttest: 20.4241151\tbest: 20.4233664 (796)\ttotal: 813ms\tremaining: 991ms\n",
      "1000:\tlearn: 8.3044763\ttest: 20.4063923\tbest: 20.4025112 (986)\ttotal: 898ms\tremaining: 896ms\n",
      "1100:\tlearn: 7.6573865\ttest: 20.3599098\tbest: 20.3599098 (1100)\ttotal: 991ms\tremaining: 809ms\n",
      "1200:\tlearn: 7.0708217\ttest: 20.3594410\tbest: 20.3351480 (1131)\ttotal: 1.12s\tremaining: 748ms\n",
      "1300:\tlearn: 6.5260804\ttest: 20.3199968\tbest: 20.3099192 (1281)\ttotal: 1.22s\tremaining: 657ms\n",
      "1400:\tlearn: 6.0187277\ttest: 20.3379405\tbest: 20.3099192 (1281)\ttotal: 1.35s\tremaining: 576ms\n",
      "1500:\tlearn: 5.5791602\ttest: 20.3702929\tbest: 20.3099192 (1281)\ttotal: 1.49s\tremaining: 496ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30991923\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580304\ttest: 29.9242205\tbest: 29.9242205 (0)\ttotal: 1ms\tremaining: 2s\n",
      "100:\tlearn: 21.2416623\ttest: 22.2011693\tbest: 22.2011693 (100)\ttotal: 91.7ms\tremaining: 1.72s\n",
      "200:\tlearn: 18.2406203\ttest: 21.1924277\tbest: 21.1924277 (200)\ttotal: 193ms\tremaining: 1.73s\n",
      "300:\tlearn: 16.0052920\ttest: 20.6536145\tbest: 20.6536145 (300)\ttotal: 295ms\tremaining: 1.66s\n",
      "400:\tlearn: 14.3169816\ttest: 20.5523420\tbest: 20.5176464 (382)\ttotal: 380ms\tremaining: 1.52s\n",
      "500:\tlearn: 12.9710100\ttest: 20.4789802\tbest: 20.4588772 (497)\ttotal: 680ms\tremaining: 2.03s\n",
      "600:\tlearn: 11.7841804\ttest: 20.5063578\tbest: 20.4588772 (497)\ttotal: 1.03s\tremaining: 2.39s\n",
      "700:\tlearn: 10.7476041\ttest: 20.4870269\tbest: 20.4550243 (659)\ttotal: 1.37s\tremaining: 2.54s\n",
      "800:\tlearn: 9.8485582\ttest: 20.4326228\tbest: 20.4233746 (796)\ttotal: 1.59s\tremaining: 2.38s\n",
      "900:\tlearn: 9.0468759\ttest: 20.4241236\tbest: 20.4233746 (796)\ttotal: 1.81s\tremaining: 2.21s\n",
      "1000:\tlearn: 8.3044284\ttest: 20.4064012\tbest: 20.4025199 (986)\ttotal: 2.06s\tremaining: 2.06s\n",
      "1100:\tlearn: 7.6573399\ttest: 20.3599190\tbest: 20.3599190 (1100)\ttotal: 2.32s\tremaining: 1.9s\n",
      "1200:\tlearn: 7.0707765\ttest: 20.3594506\tbest: 20.3351571 (1131)\ttotal: 2.52s\tremaining: 1.67s\n",
      "1300:\tlearn: 6.5260365\ttest: 20.3200063\tbest: 20.3099287 (1281)\ttotal: 2.68s\tremaining: 1.44s\n",
      "1400:\tlearn: 6.0186855\ttest: 20.3379502\tbest: 20.3099287 (1281)\ttotal: 2.78s\tremaining: 1.19s\n",
      "1500:\tlearn: 5.5791195\ttest: 20.3703026\tbest: 20.3099287 (1281)\ttotal: 2.86s\tremaining: 951ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992867\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925603\ttest: 29.9282313\tbest: 29.9282313 (0)\ttotal: 797us\tremaining: 1.59s\n",
      "100:\tlearn: 22.3675434\ttest: 22.5593950\tbest: 22.5593950 (100)\ttotal: 72.5ms\tremaining: 1.36s\n",
      "200:\tlearn: 20.1453091\ttest: 21.5587635\tbest: 21.5587635 (200)\ttotal: 142ms\tremaining: 1.27s\n",
      "300:\tlearn: 18.3618899\ttest: 21.0831346\tbest: 21.0810025 (299)\ttotal: 204ms\tremaining: 1.15s\n",
      "400:\tlearn: 17.1156676\ttest: 20.9830205\tbest: 20.9452942 (373)\ttotal: 273ms\tremaining: 1.09s\n",
      "500:\tlearn: 15.9948241\ttest: 20.8726499\tbest: 20.8589250 (488)\ttotal: 341ms\tremaining: 1.02s\n",
      "600:\tlearn: 15.0970337\ttest: 20.8733228\tbest: 20.8589250 (488)\ttotal: 410ms\tremaining: 955ms\n",
      "700:\tlearn: 14.3113567\ttest: 20.7384561\tbest: 20.7384561 (700)\ttotal: 479ms\tremaining: 887ms\n",
      "800:\tlearn: 13.5757273\ttest: 20.7028363\tbest: 20.7020341 (795)\ttotal: 548ms\tremaining: 821ms\n",
      "900:\tlearn: 12.9216280\ttest: 20.7051665\tbest: 20.6887391 (814)\ttotal: 620ms\tremaining: 756ms\n",
      "1000:\tlearn: 12.2715483\ttest: 20.7077819\tbest: 20.6887391 (814)\ttotal: 725ms\tremaining: 724ms\n",
      "1100:\tlearn: 11.6848659\ttest: 20.6270299\tbest: 20.6235123 (1097)\ttotal: 797ms\tremaining: 651ms\n",
      "1200:\tlearn: 11.1603637\ttest: 20.6004784\tbest: 20.5951464 (1198)\ttotal: 868ms\tremaining: 578ms\n",
      "1300:\tlearn: 10.6328666\ttest: 20.5625977\tbest: 20.5461807 (1281)\ttotal: 933ms\tremaining: 501ms\n",
      "1400:\tlearn: 10.1587838\ttest: 20.5569143\tbest: 20.5461807 (1281)\ttotal: 1s\tremaining: 428ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500:\tlearn: 9.7364799\ttest: 20.5220467\tbest: 20.5203509 (1493)\ttotal: 1.07s\tremaining: 357ms\n",
      "1600:\tlearn: 9.3205011\ttest: 20.5874010\tbest: 20.5203509 (1493)\ttotal: 1.15s\tremaining: 286ms\n",
      "1700:\tlearn: 8.9423773\ttest: 20.5625919\tbest: 20.5203509 (1493)\ttotal: 1.22s\tremaining: 214ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.52035087\n",
      "bestIteration = 1493\n",
      "\n",
      "Shrink model to first 1494 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580431\ttest: 29.9242322\tbest: 29.9242322 (0)\ttotal: 1.02ms\tremaining: 2.05s\n",
      "100:\tlearn: 21.2424568\ttest: 22.2012020\tbest: 22.2012020 (100)\ttotal: 92.3ms\tremaining: 1.74s\n",
      "200:\tlearn: 18.2418715\ttest: 21.1923785\tbest: 21.1923785 (200)\ttotal: 186ms\tremaining: 1.67s\n",
      "300:\tlearn: 16.0067531\ttest: 20.6535184\tbest: 20.6535184 (300)\ttotal: 283ms\tremaining: 1.59s\n",
      "400:\tlearn: 14.3185771\ttest: 20.5521182\tbest: 20.5174490 (382)\ttotal: 372ms\tremaining: 1.48s\n",
      "500:\tlearn: 12.9726730\ttest: 20.4787367\tbest: 20.4586390 (497)\ttotal: 463ms\tremaining: 1.38s\n",
      "600:\tlearn: 11.7859029\ttest: 20.5061099\tbest: 20.4586390 (497)\ttotal: 559ms\tremaining: 1.3s\n",
      "700:\tlearn: 10.7493482\ttest: 20.4867323\tbest: 20.4547570 (659)\ttotal: 657ms\tremaining: 1.22s\n",
      "800:\tlearn: 9.8477739\ttest: 20.4400577\tbest: 20.4354649 (796)\ttotal: 747ms\tremaining: 1.12s\n",
      "900:\tlearn: 9.0272367\ttest: 20.4194532\tbest: 20.4194532 (900)\ttotal: 860ms\tremaining: 1.05s\n",
      "1000:\tlearn: 8.2981129\ttest: 20.3994994\tbest: 20.3942647 (998)\ttotal: 944ms\tremaining: 942ms\n",
      "1100:\tlearn: 7.6360007\ttest: 20.3892441\tbest: 20.3790515 (1030)\ttotal: 1.03s\tremaining: 844ms\n",
      "1200:\tlearn: 7.0409703\ttest: 20.4012940\tbest: 20.3676743 (1131)\ttotal: 1.12s\tremaining: 747ms\n",
      "1300:\tlearn: 6.4919153\ttest: 20.4051106\tbest: 20.3676743 (1131)\ttotal: 1.21s\tremaining: 651ms\n",
      "1400:\tlearn: 5.9959453\ttest: 20.3989098\tbest: 20.3676743 (1131)\ttotal: 1.33s\tremaining: 569ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.36767434\n",
      "bestIteration = 1131\n",
      "\n",
      "Shrink model to first 1132 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2201120\ttest: 29.8807787\tbest: 29.8807787 (0)\ttotal: 3.52ms\tremaining: 7.03s\n",
      "100:\tlearn: 15.7007700\ttest: 21.8320809\tbest: 21.8320809 (100)\ttotal: 373ms\tremaining: 7.01s\n",
      "200:\tlearn: 10.5612842\ttest: 20.9639820\tbest: 20.9599216 (197)\ttotal: 689ms\tremaining: 6.16s\n",
      "300:\tlearn: 7.0641148\ttest: 20.7947103\tbest: 20.7835364 (291)\ttotal: 1.02s\tremaining: 5.79s\n",
      "400:\tlearn: 4.7971781\ttest: 20.7339695\tbest: 20.7271971 (389)\ttotal: 1.37s\tremaining: 5.45s\n",
      "500:\tlearn: 3.2816448\ttest: 20.6683685\tbest: 20.6648393 (495)\ttotal: 2.22s\tremaining: 6.64s\n",
      "600:\tlearn: 2.2433504\ttest: 20.6356239\tbest: 20.6310904 (570)\ttotal: 2.88s\tremaining: 6.71s\n",
      "700:\tlearn: 1.5677067\ttest: 20.6186392\tbest: 20.6166606 (687)\ttotal: 3.21s\tremaining: 5.96s\n",
      "800:\tlearn: 1.0860589\ttest: 20.6180581\tbest: 20.6161185 (711)\ttotal: 3.73s\tremaining: 5.58s\n",
      "900:\tlearn: 0.7587816\ttest: 20.6188281\tbest: 20.6161185 (711)\ttotal: 4.36s\tremaining: 5.32s\n",
      "1000:\tlearn: 0.5244643\ttest: 20.6183247\tbest: 20.6161185 (711)\ttotal: 4.7s\tremaining: 4.69s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.61611852\n",
      "bestIteration = 711\n",
      "\n",
      "Shrink model to first 712 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3925818\ttest: 29.9282474\tbest: 29.9282474 (0)\ttotal: 900us\tremaining: 1.8s\n",
      "100:\tlearn: 22.3689760\ttest: 22.5596830\tbest: 22.5596830 (100)\ttotal: 65ms\tremaining: 1.22s\n",
      "200:\tlearn: 20.1483049\ttest: 21.5586569\tbest: 21.5586569 (200)\ttotal: 154ms\tremaining: 1.37s\n",
      "300:\tlearn: 18.3659006\ttest: 21.0825951\tbest: 21.0804640 (299)\ttotal: 242ms\tremaining: 1.37s\n",
      "400:\tlearn: 17.1199286\ttest: 20.9822069\tbest: 20.9445271 (373)\ttotal: 313ms\tremaining: 1.25s\n",
      "500:\tlearn: 15.9997716\ttest: 20.8615887\tbest: 20.8475629 (488)\ttotal: 404ms\tremaining: 1.21s\n",
      "600:\tlearn: 15.1312772\ttest: 20.8588054\tbest: 20.8360126 (538)\ttotal: 499ms\tremaining: 1.16s\n",
      "700:\tlearn: 14.3389301\ttest: 20.7191223\tbest: 20.7143646 (699)\ttotal: 561ms\tremaining: 1.04s\n",
      "800:\tlearn: 13.6013290\ttest: 20.7063056\tbest: 20.7063056 (800)\ttotal: 626ms\tremaining: 937ms\n",
      "900:\tlearn: 12.9301052\ttest: 20.6795685\tbest: 20.6795685 (900)\ttotal: 742ms\tremaining: 905ms\n",
      "1000:\tlearn: 12.2855566\ttest: 20.6675768\tbest: 20.6516223 (980)\ttotal: 810ms\tremaining: 808ms\n",
      "1100:\tlearn: 11.6819420\ttest: 20.6911820\tbest: 20.6516223 (980)\ttotal: 899ms\tremaining: 734ms\n",
      "1200:\tlearn: 11.1401943\ttest: 20.7000761\tbest: 20.6516223 (980)\ttotal: 965ms\tremaining: 642ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.65162234\n",
      "bestIteration = 980\n",
      "\n",
      "Shrink model to first 981 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580321\ttest: 29.9242221\tbest: 29.9242221 (0)\ttotal: 1.05ms\tremaining: 2.09s\n",
      "100:\tlearn: 21.2417656\ttest: 22.2011736\tbest: 22.2011736 (100)\ttotal: 101ms\tremaining: 1.91s\n",
      "200:\tlearn: 18.2407830\ttest: 21.1924213\tbest: 21.1924213 (200)\ttotal: 193ms\tremaining: 1.72s\n",
      "300:\tlearn: 16.0054820\ttest: 20.6536020\tbest: 20.6536020 (300)\ttotal: 284ms\tremaining: 1.6s\n",
      "400:\tlearn: 14.3171890\ttest: 20.5523128\tbest: 20.5176207 (382)\ttotal: 503ms\tremaining: 2s\n",
      "500:\tlearn: 12.9712262\ttest: 20.4789485\tbest: 20.4588462 (497)\ttotal: 788ms\tremaining: 2.36s\n",
      "600:\tlearn: 11.7844044\ttest: 20.5063255\tbest: 20.4588462 (497)\ttotal: 1.04s\tremaining: 2.43s\n",
      "700:\tlearn: 10.7478308\ttest: 20.4869885\tbest: 20.4549895 (659)\ttotal: 1.32s\tremaining: 2.45s\n",
      "800:\tlearn: 9.8487831\ttest: 20.4325863\tbest: 20.4233376 (796)\ttotal: 1.59s\tremaining: 2.38s\n",
      "900:\tlearn: 9.0470966\ttest: 20.4240852\tbest: 20.4233376 (796)\ttotal: 1.75s\tremaining: 2.13s\n",
      "1000:\tlearn: 8.3071767\ttest: 20.4082840\tbest: 20.4033833 (986)\ttotal: 1.84s\tremaining: 1.83s\n",
      "1100:\tlearn: 7.6549171\ttest: 20.3696379\tbest: 20.3696379 (1100)\ttotal: 1.92s\tremaining: 1.57s\n",
      "1200:\tlearn: 7.0657663\ttest: 20.3807689\tbest: 20.3547165 (1130)\ttotal: 2.01s\tremaining: 1.34s\n",
      "1300:\tlearn: 6.5151380\ttest: 20.3685516\tbest: 20.3547165 (1130)\ttotal: 2.1s\tremaining: 1.13s\n",
      "1400:\tlearn: 6.0005179\ttest: 20.3770801\tbest: 20.3547165 (1130)\ttotal: 2.18s\tremaining: 934ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35471651\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580306\ttest: 29.9242207\tbest: 29.9242207 (0)\ttotal: 980us\tremaining: 1.96s\n",
      "100:\tlearn: 21.2416741\ttest: 22.2011698\tbest: 22.2011698 (100)\ttotal: 85.5ms\tremaining: 1.61s\n",
      "200:\tlearn: 18.2406388\ttest: 21.1924270\tbest: 21.1924270 (200)\ttotal: 178ms\tremaining: 1.59s\n",
      "300:\tlearn: 16.0053137\ttest: 20.6536131\tbest: 20.6536131 (300)\ttotal: 270ms\tremaining: 1.52s\n",
      "400:\tlearn: 14.3170052\ttest: 20.5523387\tbest: 20.5176434 (382)\ttotal: 355ms\tremaining: 1.42s\n",
      "500:\tlearn: 12.9710346\ttest: 20.4789765\tbest: 20.4588737 (497)\ttotal: 449ms\tremaining: 1.34s\n",
      "600:\tlearn: 11.7842060\ttest: 20.5063541\tbest: 20.4588737 (497)\ttotal: 540ms\tremaining: 1.26s\n",
      "700:\tlearn: 10.7476299\ttest: 20.4870225\tbest: 20.4550203 (659)\ttotal: 625ms\tremaining: 1.16s\n",
      "800:\tlearn: 9.8485838\ttest: 20.4326187\tbest: 20.4233703 (796)\ttotal: 717ms\tremaining: 1.07s\n",
      "900:\tlearn: 9.0469011\ttest: 20.4241193\tbest: 20.4233703 (796)\ttotal: 809ms\tremaining: 986ms\n",
      "1000:\tlearn: 8.3044531\ttest: 20.4063966\tbest: 20.4025154 (986)\ttotal: 893ms\tremaining: 892ms\n",
      "1100:\tlearn: 7.6573639\ttest: 20.3599143\tbest: 20.3599143 (1100)\ttotal: 986ms\tremaining: 805ms\n",
      "1200:\tlearn: 7.0707998\ttest: 20.3594457\tbest: 20.3351524 (1131)\ttotal: 1.09s\tremaining: 729ms\n",
      "1300:\tlearn: 6.5260591\ttest: 20.3200014\tbest: 20.3099238 (1281)\ttotal: 1.19s\tremaining: 637ms\n",
      "1400:\tlearn: 6.0187072\ttest: 20.3379452\tbest: 20.3099238 (1281)\ttotal: 1.28s\tremaining: 547ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500:\tlearn: 5.5791405\ttest: 20.3702976\tbest: 20.3099238 (1281)\ttotal: 1.38s\tremaining: 457ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30992381\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580309\ttest: 29.9242209\tbest: 29.9242209 (0)\ttotal: 920us\tremaining: 1.84s\n",
      "100:\tlearn: 21.2416899\ttest: 22.2011705\tbest: 22.2011705 (100)\ttotal: 114ms\tremaining: 2.14s\n",
      "200:\tlearn: 18.2406638\ttest: 21.1924260\tbest: 21.1924260 (200)\ttotal: 203ms\tremaining: 1.82s\n",
      "300:\tlearn: 16.0053428\ttest: 20.6536112\tbest: 20.6536112 (300)\ttotal: 287ms\tremaining: 1.62s\n",
      "400:\tlearn: 14.3170370\ttest: 20.5523342\tbest: 20.5176395 (382)\ttotal: 376ms\tremaining: 1.5s\n",
      "500:\tlearn: 12.9710678\ttest: 20.4789717\tbest: 20.4588689 (497)\ttotal: 466ms\tremaining: 1.39s\n",
      "600:\tlearn: 11.7842403\ttest: 20.5063492\tbest: 20.4588689 (497)\ttotal: 553ms\tremaining: 1.29s\n",
      "700:\tlearn: 10.7476647\ttest: 20.4870166\tbest: 20.4550150 (659)\ttotal: 642ms\tremaining: 1.19s\n",
      "800:\tlearn: 9.8486183\ttest: 20.4326131\tbest: 20.4233647 (796)\ttotal: 734ms\tremaining: 1.1s\n",
      "900:\tlearn: 9.0469349\ttest: 20.4241134\tbest: 20.4233647 (796)\ttotal: 818ms\tremaining: 998ms\n",
      "1000:\tlearn: 8.3044862\ttest: 20.4063905\tbest: 20.4025093 (986)\ttotal: 907ms\tremaining: 905ms\n",
      "1100:\tlearn: 7.6573962\ttest: 20.3599079\tbest: 20.3599079 (1100)\ttotal: 997ms\tremaining: 814ms\n",
      "1200:\tlearn: 7.0708311\ttest: 20.3594390\tbest: 20.3351461 (1131)\ttotal: 1.08s\tremaining: 720ms\n",
      "1300:\tlearn: 6.5260896\ttest: 20.3199949\tbest: 20.3099173 (1281)\ttotal: 1.2s\tremaining: 646ms\n",
      "1400:\tlearn: 6.0187365\ttest: 20.3379385\tbest: 20.3099173 (1281)\ttotal: 1.29s\tremaining: 553ms\n",
      "1500:\tlearn: 5.5791686\ttest: 20.3702909\tbest: 20.3099173 (1281)\ttotal: 1.38s\tremaining: 460ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.30991727\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980307\ttest: 29.8551299\tbest: 29.8551299 (0)\ttotal: 2.32ms\tremaining: 4.64s\n",
      "100:\tlearn: 19.8960083\ttest: 22.1211385\tbest: 22.1211385 (100)\ttotal: 396ms\tremaining: 7.45s\n",
      "200:\tlearn: 16.1996673\ttest: 21.3561463\tbest: 21.3264606 (192)\ttotal: 827ms\tremaining: 7.4s\n",
      "300:\tlearn: 13.4261547\ttest: 21.0762820\tbest: 21.0462871 (265)\ttotal: 1.23s\tremaining: 6.92s\n",
      "400:\tlearn: 11.3163052\ttest: 21.0784947\tbest: 21.0223203 (334)\ttotal: 1.35s\tremaining: 5.37s\n",
      "500:\tlearn: 9.7091952\ttest: 21.0116133\tbest: 21.0111533 (499)\ttotal: 1.5s\tremaining: 4.48s\n",
      "600:\tlearn: 8.3247059\ttest: 20.9825071\tbest: 20.9803874 (598)\ttotal: 1.64s\tremaining: 3.83s\n",
      "700:\tlearn: 7.2181332\ttest: 20.9189668\tbest: 20.9167792 (698)\ttotal: 1.8s\tremaining: 3.33s\n",
      "800:\tlearn: 6.2175040\ttest: 20.9235144\tbest: 20.9090701 (751)\ttotal: 1.92s\tremaining: 2.87s\n",
      "900:\tlearn: 5.3896607\ttest: 20.9516896\tbest: 20.9090701 (751)\ttotal: 2.04s\tremaining: 2.49s\n",
      "1000:\tlearn: 4.7043897\ttest: 20.9313330\tbest: 20.9090701 (751)\ttotal: 2.16s\tremaining: 2.15s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90907009\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3582296\ttest: 29.9244035\tbest: 29.9244035 (0)\ttotal: 957us\tremaining: 1.91s\n",
      "100:\tlearn: 21.2539406\ttest: 22.2017202\tbest: 22.2017202 (100)\ttotal: 92.4ms\tremaining: 1.74s\n",
      "200:\tlearn: 18.2723330\ttest: 21.1944979\tbest: 21.1944979 (200)\ttotal: 190ms\tremaining: 1.7s\n",
      "300:\tlearn: 16.0561287\ttest: 20.7930664\tbest: 20.7930664 (300)\ttotal: 288ms\tremaining: 1.63s\n",
      "400:\tlearn: 14.4144174\ttest: 20.6820345\tbest: 20.6527550 (387)\ttotal: 379ms\tremaining: 1.51s\n",
      "500:\tlearn: 13.0506962\ttest: 20.6551909\tbest: 20.6262424 (447)\ttotal: 529ms\tremaining: 1.58s\n",
      "600:\tlearn: 11.8906585\ttest: 20.6513087\tbest: 20.6226523 (549)\ttotal: 622ms\tremaining: 1.45s\n",
      "700:\tlearn: 10.8227276\ttest: 20.5420665\tbest: 20.5279522 (684)\ttotal: 706ms\tremaining: 1.31s\n",
      "800:\tlearn: 9.9298343\ttest: 20.4711441\tbest: 20.4711441 (800)\ttotal: 796ms\tremaining: 1.19s\n",
      "900:\tlearn: 9.1364440\ttest: 20.4183835\tbest: 20.4059843 (895)\ttotal: 881ms\tremaining: 1.07s\n",
      "1000:\tlearn: 8.3972102\ttest: 20.4082294\tbest: 20.4059843 (895)\ttotal: 1.08s\tremaining: 1.08s\n",
      "1100:\tlearn: 7.7284990\ttest: 20.3738841\tbest: 20.3705709 (1071)\ttotal: 1.32s\tremaining: 1.08s\n",
      "1200:\tlearn: 7.1122536\ttest: 20.3623827\tbest: 20.3505537 (1140)\ttotal: 1.47s\tremaining: 980ms\n",
      "1300:\tlearn: 6.5603006\ttest: 20.3976938\tbest: 20.3466657 (1212)\ttotal: 1.56s\tremaining: 841ms\n",
      "1400:\tlearn: 6.0701141\ttest: 20.4064676\tbest: 20.3466657 (1212)\ttotal: 1.68s\tremaining: 720ms\n",
      "1500:\tlearn: 5.6066504\ttest: 20.4441081\tbest: 20.3466657 (1212)\ttotal: 1.78s\tremaining: 594ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.3466657\n",
      "bestIteration = 1212\n",
      "\n",
      "Shrink model to first 1213 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580315\ttest: 29.9242215\tbest: 29.9242215 (0)\ttotal: 967us\tremaining: 1.93s\n",
      "100:\tlearn: 21.2417268\ttest: 22.2011720\tbest: 22.2011720 (100)\ttotal: 92.9ms\tremaining: 1.75s\n",
      "200:\tlearn: 18.2407220\ttest: 21.1924237\tbest: 21.1924237 (200)\ttotal: 184ms\tremaining: 1.64s\n",
      "300:\tlearn: 16.0054107\ttest: 20.6536067\tbest: 20.6536067 (300)\ttotal: 296ms\tremaining: 1.67s\n",
      "400:\tlearn: 14.3171112\ttest: 20.5523238\tbest: 20.5176303 (382)\ttotal: 422ms\tremaining: 1.68s\n",
      "500:\tlearn: 12.9711451\ttest: 20.4789604\tbest: 20.4588579 (497)\ttotal: 637ms\tremaining: 1.91s\n",
      "600:\tlearn: 11.7843203\ttest: 20.5063376\tbest: 20.4588579 (497)\ttotal: 765ms\tremaining: 1.78s\n",
      "700:\tlearn: 10.7477457\ttest: 20.4870029\tbest: 20.4550025 (659)\ttotal: 856ms\tremaining: 1.58s\n",
      "800:\tlearn: 9.8486987\ttest: 20.4326000\tbest: 20.4233515 (796)\ttotal: 962ms\tremaining: 1.44s\n",
      "900:\tlearn: 9.0470138\ttest: 20.4240997\tbest: 20.4233515 (796)\ttotal: 1.05s\tremaining: 1.28s\n",
      "1000:\tlearn: 8.3070958\ttest: 20.4082991\tbest: 20.4033982 (986)\ttotal: 1.18s\tremaining: 1.18s\n",
      "1100:\tlearn: 7.6548385\ttest: 20.3696534\tbest: 20.3696534 (1100)\ttotal: 1.26s\tremaining: 1.03s\n",
      "1200:\tlearn: 7.0656898\ttest: 20.3807847\tbest: 20.3547325 (1130)\ttotal: 1.35s\tremaining: 899ms\n",
      "1300:\tlearn: 6.5097535\ttest: 20.3738075\tbest: 20.3547325 (1130)\ttotal: 1.47s\tremaining: 791ms\n",
      "1400:\tlearn: 6.0131920\ttest: 20.3719260\tbest: 20.3547325 (1130)\ttotal: 1.56s\tremaining: 666ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.35473245\n",
      "bestIteration = 1130\n",
      "\n",
      "Shrink model to first 1131 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580305\ttest: 29.9242206\tbest: 29.9242206 (0)\ttotal: 940us\tremaining: 1.88s\n",
      "100:\tlearn: 21.2416683\ttest: 22.2011696\tbest: 22.2011696 (100)\ttotal: 122ms\tremaining: 2.29s\n",
      "200:\tlearn: 18.2406297\ttest: 21.1924273\tbest: 21.1924273 (200)\ttotal: 289ms\tremaining: 2.59s\n",
      "300:\tlearn: 16.0053030\ttest: 20.6536138\tbest: 20.6536138 (300)\ttotal: 383ms\tremaining: 2.16s\n",
      "400:\tlearn: 14.3169936\ttest: 20.5523403\tbest: 20.5176449 (382)\ttotal: 471ms\tremaining: 1.88s\n",
      "500:\tlearn: 12.9710225\ttest: 20.4789783\tbest: 20.4588754 (497)\ttotal: 588ms\tremaining: 1.76s\n",
      "600:\tlearn: 11.7841934\ttest: 20.5063559\tbest: 20.4588754 (497)\ttotal: 700ms\tremaining: 1.63s\n",
      "700:\tlearn: 10.7476172\ttest: 20.4870247\tbest: 20.4550223 (659)\ttotal: 785ms\tremaining: 1.46s\n",
      "800:\tlearn: 9.8485712\ttest: 20.4326207\tbest: 20.4233724 (796)\ttotal: 874ms\tremaining: 1.31s\n",
      "900:\tlearn: 9.0468887\ttest: 20.4241214\tbest: 20.4233724 (796)\ttotal: 959ms\tremaining: 1.17s\n",
      "1000:\tlearn: 8.3044409\ttest: 20.4063988\tbest: 20.4025177 (986)\ttotal: 1.07s\tremaining: 1.07s\n",
      "1100:\tlearn: 7.6573521\ttest: 20.3599166\tbest: 20.3599166 (1100)\ttotal: 1.16s\tremaining: 945ms\n",
      "1200:\tlearn: 7.0707883\ttest: 20.3594481\tbest: 20.3351547 (1131)\ttotal: 1.24s\tremaining: 826ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300:\tlearn: 6.5260480\ttest: 20.3200038\tbest: 20.3099262 (1281)\ttotal: 1.35s\tremaining: 725ms\n",
      "1400:\tlearn: 6.0186965\ttest: 20.3379477\tbest: 20.3099262 (1281)\ttotal: 1.44s\tremaining: 614ms\n",
      "1500:\tlearn: 5.5791302\ttest: 20.3703001\tbest: 20.3099262 (1281)\ttotal: 1.52s\tremaining: 506ms\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.3099262\n",
      "bestIteration = 1281\n",
      "\n",
      "Shrink model to first 1282 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.2980296\ttest: 29.8551288\tbest: 29.8551288 (0)\ttotal: 1.58ms\tremaining: 3.15s\n",
      "100:\tlearn: 19.8959548\ttest: 22.1211353\tbest: 22.1211353 (100)\ttotal: 268ms\tremaining: 5.04s\n",
      "200:\tlearn: 16.1995855\ttest: 21.3561558\tbest: 21.3264673 (192)\ttotal: 504ms\tremaining: 4.51s\n",
      "300:\tlearn: 13.4260636\ttest: 21.0762962\tbest: 21.0462981 (265)\ttotal: 623ms\tremaining: 3.52s\n",
      "400:\tlearn: 11.3162082\ttest: 21.0785126\tbest: 21.0223358 (334)\ttotal: 753ms\tremaining: 3s\n",
      "500:\tlearn: 9.7090980\ttest: 21.0116300\tbest: 21.0111701 (499)\ttotal: 907ms\tremaining: 2.71s\n",
      "600:\tlearn: 8.3246109\ttest: 20.9825262\tbest: 20.9804065 (598)\ttotal: 1.09s\tremaining: 2.54s\n",
      "700:\tlearn: 7.2180417\ttest: 20.9189852\tbest: 20.9167977 (698)\ttotal: 1.22s\tremaining: 2.26s\n",
      "800:\tlearn: 6.2174177\ttest: 20.9235339\tbest: 20.9090891 (751)\ttotal: 1.38s\tremaining: 2.06s\n",
      "900:\tlearn: 5.3895804\ttest: 20.9517091\tbest: 20.9090891 (751)\ttotal: 1.54s\tremaining: 1.88s\n",
      "1000:\tlearn: 4.7043153\ttest: 20.9313524\tbest: 20.9090891 (751)\ttotal: 1.66s\tremaining: 1.66s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.90908906\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.3580374\ttest: 29.9242270\tbest: 29.9242270 (0)\ttotal: 1.04ms\tremaining: 2.08s\n",
      "100:\tlearn: 21.2421022\ttest: 22.2011874\tbest: 22.2011874 (100)\ttotal: 86.1ms\tremaining: 1.62s\n",
      "200:\tlearn: 18.2413131\ttest: 21.1924004\tbest: 21.1924004 (200)\ttotal: 173ms\tremaining: 1.55s\n",
      "300:\tlearn: 16.0061010\ttest: 20.6535612\tbest: 20.6535612 (300)\ttotal: 432ms\tremaining: 2.44s\n",
      "400:\tlearn: 14.3178649\ttest: 20.5522180\tbest: 20.5175370 (382)\ttotal: 590ms\tremaining: 2.35s\n",
      "500:\tlearn: 12.9719307\ttest: 20.4788453\tbest: 20.4587452 (497)\ttotal: 707ms\tremaining: 2.12s\n",
      "600:\tlearn: 11.7851341\ttest: 20.5062205\tbest: 20.4587452 (497)\ttotal: 792ms\tremaining: 1.84s\n",
      "700:\tlearn: 10.7485697\ttest: 20.4868637\tbest: 20.4548762 (659)\ttotal: 877ms\tremaining: 1.63s\n",
      "800:\tlearn: 9.8495161\ttest: 20.4324674\tbest: 20.4232174 (796)\ttotal: 965ms\tremaining: 1.44s\n",
      "900:\tlearn: 9.0360550\ttest: 20.4435175\tbest: 20.4232174 (796)\ttotal: 1.05s\tremaining: 1.28s\n",
      "1000:\tlearn: 8.3086436\ttest: 20.4406722\tbest: 20.4232174 (796)\ttotal: 1.13s\tremaining: 1.13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 20.42321743\n",
      "bestIteration = 796\n",
      "\n",
      "Shrink model to first 797 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.5162290\ttest: 30.0762602\tbest: 30.0762602 (0)\ttotal: 1.22ms\tremaining: 3.65s\n",
      "100:\tlearn: 22.8088507\ttest: 22.9643456\tbest: 22.9643456 (100)\ttotal: 92.7ms\tremaining: 2.66s\n",
      "200:\tlearn: 20.6256599\ttest: 21.9080023\tbest: 21.9080023 (200)\ttotal: 181ms\tremaining: 2.52s\n",
      "300:\tlearn: 18.8944392\ttest: 21.2860846\tbest: 21.2860846 (300)\ttotal: 269ms\tremaining: 2.41s\n",
      "400:\tlearn: 17.4016364\ttest: 20.9903205\tbest: 20.9903205 (400)\ttotal: 354ms\tremaining: 2.29s\n",
      "500:\tlearn: 16.1464460\ttest: 20.7923880\tbest: 20.7923880 (500)\ttotal: 475ms\tremaining: 2.37s\n",
      "600:\tlearn: 15.0538150\ttest: 20.7746618\tbest: 20.7746618 (600)\ttotal: 560ms\tremaining: 2.24s\n",
      "700:\tlearn: 14.0838803\ttest: 20.6907946\tbest: 20.6844113 (694)\ttotal: 646ms\tremaining: 2.12s\n",
      "800:\tlearn: 13.2146273\ttest: 20.5535074\tbest: 20.5535074 (800)\ttotal: 736ms\tremaining: 2.02s\n",
      "900:\tlearn: 12.4582193\ttest: 20.5164798\tbest: 20.5133777 (878)\ttotal: 823ms\tremaining: 1.92s\n",
      "1000:\tlearn: 11.7736212\ttest: 20.5024024\tbest: 20.4870871 (960)\ttotal: 909ms\tremaining: 1.81s\n",
      "1100:\tlearn: 11.1572183\ttest: 20.5018997\tbest: 20.4849212 (1055)\ttotal: 997ms\tremaining: 1.72s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.48492115\n",
      "bestIteration = 1055\n",
      "\n",
      "Shrink model to first 1056 iterations.\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.5171770\ttest: 30.0682526\tbest: 30.0682526 (0)\ttotal: 1.27ms\tremaining: 3.83s\n",
      "100:\tlearn: 22.7269077\ttest: 23.6502218\tbest: 23.6502218 (100)\ttotal: 89.7ms\tremaining: 2.57s\n",
      "200:\tlearn: 20.7310710\ttest: 22.6643332\tbest: 22.6643332 (200)\ttotal: 176ms\tremaining: 2.46s\n",
      "300:\tlearn: 19.0239177\ttest: 22.0369686\tbest: 22.0369686 (300)\ttotal: 264ms\tremaining: 2.37s\n",
      "400:\tlearn: 17.4606446\ttest: 21.7434357\tbest: 21.7305507 (396)\ttotal: 352ms\tremaining: 2.28s\n",
      "500:\tlearn: 16.1576429\ttest: 21.5966779\tbest: 21.5936500 (499)\ttotal: 438ms\tremaining: 2.18s\n",
      "600:\tlearn: 15.0582063\ttest: 21.5445928\tbest: 21.5327574 (598)\ttotal: 526ms\tremaining: 2.1s\n",
      "700:\tlearn: 14.1101604\ttest: 21.4109227\tbest: 21.4109227 (700)\ttotal: 614ms\tremaining: 2.02s\n",
      "800:\tlearn: 13.2409373\ttest: 21.3693014\tbest: 21.3616370 (799)\ttotal: 700ms\tremaining: 1.92s\n",
      "900:\tlearn: 12.4899416\ttest: 21.3405800\tbest: 21.3391180 (899)\ttotal: 788ms\tremaining: 1.84s\n",
      "1000:\tlearn: 11.8157470\ttest: 21.3258073\tbest: 21.3225057 (997)\ttotal: 877ms\tremaining: 1.75s\n",
      "1100:\tlearn: 11.1763615\ttest: 21.3098672\tbest: 21.2952666 (1093)\ttotal: 1.01s\tremaining: 1.74s\n",
      "1200:\tlearn: 10.5966336\ttest: 21.2947752\tbest: 21.2840289 (1193)\ttotal: 1.09s\tremaining: 1.64s\n",
      "1300:\tlearn: 10.0516810\ttest: 21.2622758\tbest: 21.2621223 (1299)\ttotal: 1.18s\tremaining: 1.54s\n",
      "1400:\tlearn: 9.5388796\ttest: 21.2281899\tbest: 21.2281899 (1400)\ttotal: 1.27s\tremaining: 1.45s\n",
      "1500:\tlearn: 9.0840069\ttest: 21.2159349\tbest: 21.2117505 (1494)\ttotal: 1.39s\tremaining: 1.39s\n",
      "1600:\tlearn: 8.6379381\ttest: 21.2092504\tbest: 21.2041011 (1546)\ttotal: 1.48s\tremaining: 1.3s\n",
      "1700:\tlearn: 8.2118426\ttest: 21.1888806\tbest: 21.1867222 (1697)\ttotal: 1.57s\tremaining: 1.2s\n",
      "1800:\tlearn: 7.8041283\ttest: 21.1771533\tbest: 21.1746882 (1755)\ttotal: 1.66s\tremaining: 1.1s\n",
      "1900:\tlearn: 7.4242300\ttest: 21.1580848\tbest: 21.1503758 (1860)\ttotal: 1.75s\tremaining: 1.01s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 21.1503758\n",
      "bestIteration = 1860\n",
      "\n",
      "Shrink model to first 1861 iterations.\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.7337910\ttest: 29.2123302\tbest: 29.2123302 (0)\ttotal: 980us\tremaining: 2.94s\n",
      "100:\tlearn: 22.6285656\ttest: 22.8672506\tbest: 22.8672506 (100)\ttotal: 90.8ms\tremaining: 2.6s\n",
      "200:\tlearn: 20.4305725\ttest: 21.9856892\tbest: 21.9856892 (200)\ttotal: 176ms\tremaining: 2.45s\n",
      "300:\tlearn: 18.7430493\ttest: 21.5638956\tbest: 21.5638956 (300)\ttotal: 265ms\tremaining: 2.38s\n",
      "400:\tlearn: 17.1649831\ttest: 21.2941657\tbest: 21.2872933 (397)\ttotal: 354ms\tremaining: 2.29s\n",
      "500:\tlearn: 15.9893713\ttest: 21.2399901\tbest: 21.2149538 (474)\ttotal: 439ms\tremaining: 2.19s\n",
      "600:\tlearn: 14.9454776\ttest: 21.1873085\tbest: 21.1744981 (597)\ttotal: 527ms\tremaining: 2.1s\n",
      "700:\tlearn: 14.0353762\ttest: 21.0998604\tbest: 21.0867091 (682)\ttotal: 616ms\tremaining: 2.02s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 21.08670906\n",
      "bestIteration = 682\n",
      "\n",
      "Shrink model to first 683 iterations.\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.1251420\ttest: 31.5459501\tbest: 31.5459501 (0)\ttotal: 985us\tremaining: 2.96s\n",
      "100:\tlearn: 22.1362091\ttest: 26.0986301\tbest: 26.0948534 (99)\ttotal: 89.3ms\tremaining: 2.56s\n",
      "200:\tlearn: 20.1566147\ttest: 25.2865003\tbest: 25.2865003 (200)\ttotal: 175ms\tremaining: 2.44s\n",
      "300:\tlearn: 18.4981814\ttest: 24.7187910\tbest: 24.7187910 (300)\ttotal: 263ms\tremaining: 2.35s\n",
      "400:\tlearn: 16.9646641\ttest: 24.3589529\tbest: 24.3586569 (399)\ttotal: 353ms\tremaining: 2.29s\n",
      "500:\tlearn: 15.6986867\ttest: 24.1247134\tbest: 24.1247134 (500)\ttotal: 439ms\tremaining: 2.19s\n",
      "600:\tlearn: 14.6876430\ttest: 24.0066760\tbest: 24.0026940 (598)\ttotal: 528ms\tremaining: 2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700:\tlearn: 13.7748768\ttest: 23.9463634\tbest: 23.9463634 (700)\ttotal: 619ms\tremaining: 2.03s\n",
      "800:\tlearn: 12.9533314\ttest: 23.9201034\tbest: 23.9091257 (776)\ttotal: 704ms\tremaining: 1.93s\n",
      "900:\tlearn: 12.2336338\ttest: 23.8845009\tbest: 23.8702684 (862)\ttotal: 792ms\tremaining: 1.84s\n",
      "1000:\tlearn: 11.5363322\ttest: 23.8682782\tbest: 23.8590612 (992)\ttotal: 881ms\tremaining: 1.76s\n",
      "1100:\tlearn: 10.9364979\ttest: 23.8481187\tbest: 23.8360548 (1085)\ttotal: 967ms\tremaining: 1.67s\n",
      "1200:\tlearn: 10.3585317\ttest: 23.8647320\tbest: 23.8319123 (1148)\ttotal: 1.05s\tremaining: 1.58s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 23.83191231\n",
      "bestIteration = 1148\n",
      "\n",
      "Shrink model to first 1149 iterations.\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 30.1949400\ttest: 31.3221686\tbest: 31.3221686 (0)\ttotal: 1.01ms\tremaining: 3.03s\n",
      "100:\tlearn: 22.7107264\ttest: 23.4762932\tbest: 23.4762932 (100)\ttotal: 90.9ms\tremaining: 2.61s\n",
      "200:\tlearn: 20.5133284\ttest: 22.2637316\tbest: 22.2637316 (200)\ttotal: 215ms\tremaining: 3s\n",
      "300:\tlearn: 18.8121899\ttest: 21.6897862\tbest: 21.6817045 (298)\ttotal: 302ms\tremaining: 2.71s\n",
      "400:\tlearn: 17.2543517\ttest: 21.2692579\tbest: 21.2692579 (400)\ttotal: 389ms\tremaining: 2.52s\n",
      "500:\tlearn: 16.0476032\ttest: 21.0698341\tbest: 21.0698341 (500)\ttotal: 477ms\tremaining: 2.38s\n",
      "600:\tlearn: 15.0122629\ttest: 20.9693897\tbest: 20.9558062 (589)\ttotal: 566ms\tremaining: 2.26s\n",
      "700:\tlearn: 14.1149057\ttest: 20.9119769\tbest: 20.9007149 (691)\ttotal: 680ms\tremaining: 2.23s\n",
      "800:\tlearn: 13.2456414\ttest: 20.8748023\tbest: 20.8744299 (797)\ttotal: 798ms\tremaining: 2.19s\n",
      "900:\tlearn: 12.5142975\ttest: 20.8270337\tbest: 20.8148954 (863)\ttotal: 886ms\tremaining: 2.06s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.81489541\n",
      "bestIteration = 863\n",
      "\n",
      "Shrink model to first 864 iterations.\n",
      "Lvl_0_Pipe_1_Mod_3_CatBoost fitting and predicting completed\n",
      "Time left 68.31584072113037\n",
      "Blending: Optimization starts with equal weights and score -452.2469520298877\n",
      "Blending, iter 0: score = -450.9762321967977, weights = [0.11230431 0.33086696 0.21887694 0.05879693 0.2791549 ]\n",
      "Blending, iter 1: score = -450.89131037136093, weights = [0.13367741 0.3172925  0.22585346 0.         0.32317662]\n",
      "Blending, iter 2: score = -450.89082620291816, weights = [0.13198258 0.31527266 0.22933853 0.         0.32340622]\n",
      "Blending, iter 3: score = -450.89082620291816, weights = [0.13198258 0.31527266 0.22933853 0.         0.32340622]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 231.76 seconds.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "kf = KFold(n_splits = N_FOLDS)\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)\n",
    "task = Task('reg', loss='mse', metric='mse', greater_is_better=False)\n",
    "automl = TabularAutoML(task = task, timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       reader_params = {'random_state': RANDOM_STATE})\n",
    "oof_pred = automl.fit_predict(train,  roles = {'target': 'TST', 'weights':'weight'})\n",
    "test_pred = automl.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(test_pred.data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Numpy dataset support only np.ndarray features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mshow_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.show_dimensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m         self.to_string(\n\u001b[0m\u001b[1;32m   1466\u001b[0m             \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows, min_rows)\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         )\n\u001b[0;32m-> 1534\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;31m# catch contract violations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mfmt_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhave_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated_vertically\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_formatted_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mleading_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" {_format(v)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                 \u001b[0;31m# object dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36mpprint_thing\u001b[0;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.pprint_nest_depth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         result = _pprint_seq(\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0m_nest_lvl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m_pprint_seq\u001b[0;34m(seq, _nest_lvl, max_seq_items, **kwds)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     r = [\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     r = [\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     ]\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36mpprint_thing\u001b[0;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.pprint_nest_depth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         result = _pprint_seq(\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0m_nest_lvl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m_pprint_seq\u001b[0;34m(seq, _nest_lvl, max_seq_items, **kwds)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     r = [\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     r = [\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     ]\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightautoml/dataset/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightautoml/dataset/np_pd_dataset.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, data, features, roles)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Numpy dataset support only np.ndarray features'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numpy dataset support only np.ndarray features"
     ]
    }
   ],
   "source": [
    "sample[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'NumpyDataset' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-c121de054433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(self, lower, upper, axis, inplace, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5407\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5408\u001b[0m     ) -> Series | None:\n\u001b[0;32m-> 5409\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5411\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"method\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(self, lower, upper, axis, inplace, *args, **kwargs)\u001b[0m\n\u001b[1;32m   7428\u001b[0m             \u001b[0mupper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7429\u001b[0m         ):\n\u001b[0;32m-> 7430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clip_with_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7432\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_clip_with_scalar\u001b[0;34m(self, lower, upper, inplace)\u001b[0m\n\u001b[1;32m   7237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7239\u001b[0;31m                 \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7240\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__le__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__le__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__le__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__gt__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'NumpyDataset' and 'int'"
     ]
    }
   ],
   "source": [
    "sample[\"C\"] = sample[\"C\"].clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_saved = test_pred.data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"TST\"] = test_pred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPLV</th>\n",
       "      <th>TST</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512324</td>\n",
       "      <td>1656.837402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>512327</td>\n",
       "      <td>1660.210938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512328</td>\n",
       "      <td>1660.346558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512331</td>\n",
       "      <td>1645.360840</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512333</td>\n",
       "      <td>1664.917603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>513369</td>\n",
       "      <td>1648.688965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>513370</td>\n",
       "      <td>1658.745850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>513371</td>\n",
       "      <td>1657.646729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>513372</td>\n",
       "      <td>1667.255371</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>513374</td>\n",
       "      <td>1655.939209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NPLV          TST    C\n",
       "0    512324  1656.837402  0.0\n",
       "1    512327  1660.210938  0.0\n",
       "2    512328  1660.346558  0.0\n",
       "3    512331  1645.360840  0.0\n",
       "4    512333  1664.917603  0.0\n",
       "..      ...          ...  ...\n",
       "775  513369  1648.688965  0.0\n",
       "776  513370  1658.745850  0.0\n",
       "777  513371  1657.646729  0.0\n",
       "778  513372  1667.255371  0.0\n",
       "779  513374  1655.939209  0.0\n",
       "\n",
       "[780 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"C\"] = c_saved.clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"AAAutoML.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='C', ylabel='Count'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y[\"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уэаээааяаяаяаяыыы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = pd.read_csv(\"train_mean.csv\").set_index(\"NPLV\")\n",
    "test_mean = pd.read_csv(\"test_mean.csv\").set_index(\"NPLV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_mean.loc[y.index]\n",
    "test_mean = test_mean.loc[sample[\"NPLV\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c266661eb9f0457bbabcfef95f14994f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon score: 0.728404761904762 ± 0.08971879411884998\n",
      "Temperature score: 0.6801904761904761 ± 0.09678322787176975\n",
      "Overall score: 0.7042976190476192 ± 0.07338277071230663\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import NuSVR\n",
    "\n",
    "model_c = XGBRegressor(n_estimators=30)\n",
    "model_tst = XGBRegressor(n_estimators=30)\n",
    "\n",
    "res = pipeline(model_c, model_tst, train.values, test.values, train.values, test.values, y, sample, n_splits=100,\n",
    "              pwc=pwrC, pwt=pwrT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'NPLV'}>,\n",
       "        <AxesSubplot:title={'center':'TST'}>],\n",
       "       [<AxesSubplot:title={'center':'C'}>, <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"xgboost_new2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.113169126, 'O2_опер_0'),\n",
       " (0.066921264, 'total_operations_опер_0'),\n",
       " (0.05491306, 'plavka_NAPR_ZAD'),\n",
       " (0.050681137, 'bow_Ст3'),\n",
       " (0.03952316, 'gas_std_volume_H2'),\n",
       " (0.02207011, 'durationproduv_'),\n",
       " (0.01753978, 'w2v_7'),\n",
       " (0.016271645, 'w2v_0'),\n",
       " (0.01495365, 'unique_count'),\n",
       " (0.014425828, 'RAS_mean'),\n",
       " (0.013933238, 'gas_mean_volume_CO2'),\n",
       " (0.013611314, 'gas_std_volume_CO2'),\n",
       " (0.012184505, 'truncated_NMZ'),\n",
       " (0.011110511, '1'),\n",
       " (0.010784369, '7'),\n",
       " (0.010361643, 'w2v_8'),\n",
       " (0.010298041, 'st_diff_is_zero'),\n",
       " (0.010218833, 'w2v_1'),\n",
       " (0.0101285055, 'MN'),\n",
       " (0.010123135, 'gas_sum_volume_H2'),\n",
       " (0.009731754, 'gas_std_CO2'),\n",
       " (0.009391666, 'POL_mean'),\n",
       " (0.009325557, '5'),\n",
       " (0.009195856, 's_portion'),\n",
       " (0.0089969095, 'gas_std_H2'),\n",
       " (0.008892464, 'total_duration_межпл.прост._1'),\n",
       " (0.008748604, 'gas_std_volume_AR'),\n",
       " (0.0084321285, 'gas_mean_volume_N2'),\n",
       " (0.007987205, 'w2v_2'),\n",
       " (0.0078849625, 'total_duration_опер_0'),\n",
       " (0.007490053, 'gas_std_O2_pressure'),\n",
       " (0.0072476836, 'T'),\n",
       " (0.0071615, 'max_duration_опер_0'),\n",
       " (0.007070634, 'dayofweek'),\n",
       " (0.0070472667, '3'),\n",
       " (0.0069958777, 'total_count'),\n",
       " (0.006911431, 'V'),\n",
       " (0.0068581435, 'max_duration_вн.пл.прост._0'),\n",
       " (0.006785019, 'gas_mean_volume_CO'),\n",
       " (0.0065898127, 'ves_loma/ves_chuguna')]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model_tst.feature_importances_, train.columns), reverse=True)[:40]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
